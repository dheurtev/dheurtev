# 2000s

**In short:**
- [Inventions](#inventions) : 
- [Electronics](#electronics) :
- [Energy](#energy) : 
- [Telecommunications](#telecommunications) : 
- [Networking](#networking) : 
- [Cryptography](#cryptography) : 
- [Computers](#computers) :
  * [Form factor](#form-factor) : 
  * [OS](#os) : 
  * [Peripherals](#peripherals) : 
  * [Storage](#storage) :  
  * [Uses](#uses) :
- [Consumer Electronics](#consumer-electronics) :
  * [Gadgets](#gadgets) :
  * [Multimedia](#multimedia) : 
  * [Screens](#screens) : 
  * [Broadcast](#broadcast) :
  * [Video games](#video-games) :
- [Standards and protocols](#standards-and-protocols) : 
- [Programming languages and frameworks](#programming-languages-and-frameworks): Microsoft .Net Framework, Nvidia CUDA  
- [Navigation](#navigation) : GPS for civilians in smartphone, Europe's Galileo, aging GPS infrastructure

## Inventions
**[`^        back to top        ^`](#)**
## Electronics
**[`^        back to top        ^`](#)**
## Energy
**[`^        back to top        ^`](#)**
## Telecommunications
**[`^        back to top        ^`](#)**
## Networking
**[`^        back to top        ^`](#)**
## Cryptography
**[`^        back to top        ^`](#)**
## Computers
**[`^        back to top        ^`](#)**
### Form factor
**[`^        back to top        ^`](#)**
### OS
**[`^        back to top        ^`](#)**
### Peripherals
**[`^        back to top        ^`](#)**
### Storage
**[`^        back to top        ^`](#)**
### Uses
**[`^        back to top        ^`](#)**

## Consumer Electronics
**[`^        back to top        ^`](#)**
### Gadgets
**[`^        back to top        ^`](#)**
### Multimedia
**[`^        back to top        ^`](#)**
### Screens
**[`^        back to top        ^`](#)**
### Broadcast
**[`^        back to top        ^`](#)**
### Video games
**[`^        back to top        ^`](#)**


## Standards and protocols
**[`^        back to top        ^`](#)**

### Hardware layers

- **L2TP/IPSE - Layer 2 Tunneling Protocol (2000-2005)**

In computer networking, Layer 2 Tunneling Protocol (L2TP) is a tunneling protocol used to support virtual private networks (VPNs) or as part of the delivery of services by ISPs. It uses encryption ('hiding') only for its own control messages (using an optional pre-shared secret), and does not provide any encryption or confidentiality of content by itself. Rather, it provides a tunnel for Layer 2 (which may be encrypted), and the tunnel itself may be passed over a Layer 3 encryption protocol such as IPsec.[1]

Published in 2000 as proposed standard RFC 2661, L2TP has its origins primarily in two older tunneling protocols for point-to-point communication: Cisco's Layer 2 Forwarding Protocol (L2F) and Microsoft's[2] Point-to-Point Tunneling Protocol (PPTP). A new version of this protocol, L2TPv3, appeared as proposed standard RFC 3931 in 2005. L2TPv3 provides additional security features, improved encapsulation, and the ability to carry data links other than simply Point-to-Point Protocol (PPP) over an IP network (for example: Frame Relay, Ethernet, ATM, etc.).

https://en.wikipedia.org/wiki/Layer_2_Tunneling_Protocol

Because of the lack of confidentiality inherent in the L2TP protocol, it is often implemented along with IPsec. This is referred to as L2TP/IPsec, and is standardized in IETF RFC 3193. The process of setting up an L2TP/IPsec VPN is as follows:

Negotiation of IPsec security association (SA), typically through Internet key exchange (IKE). This is carried out over UDP port 500, and commonly uses either a shared password (so-called "pre-shared keys"), public keys, or X.509 certificates on both ends, although other keying methods exist.
Establishment of Encapsulating Security Payload (ESP) communication in transport mode. The IP protocol number for ESP is 50 (compare TCP's 6 and UDP's 17). At this point, a secure channel has been established, but no tunneling is taking place.
Negotiation and establishment of L2TP tunnel between the SA endpoints. The actual negotiation of parameters takes place over the SA's secure channel, within the IPsec encryption. L2TP uses UDP port 1701.

RFC 3193 Securing L2TP using IPsec

https://datatracker.ietf.org/doc/html/rfc3193

- **Link aggregation : 802.3ad (2000), 802.1AX (2008)**

In computer networking, link aggregation is the combining (aggregating) of multiple network connections in parallel by any of several methods, in order to increase throughput beyond what a single connection could sustain, to provide redundancy in case one of the links should fail, or both. A link aggregation group (LAG) is the combined collection of physical ports.

Other umbrella terms used to describe the concept include trunking,[1] bundling,[2] bonding,[1] channeling[3] or teaming.

Implementation may follow vendor-independent standards such as Link Aggregation Control Protocol (LACP) for Ethernet, defined in IEEE 802.1AX or the previous IEEE 802.3ad, but also proprietary protocols.

Standardization process

By the mid-1990s, most network switch manufacturers had included aggregation capability as a proprietary extension to increase bandwidth between their switches. Each manufacturer developed its own method, which led to compatibility problems. The IEEE 802.3 working group took up a study group to create an interoperable link layer standard (i.e. encompassing the physical and data-link layers both) in a November 1997 meeting.[4] The group quickly agreed to include an automatic configuration feature which would add in redundancy as well. This became known as Link Aggregation Control Protocol (LACP).

802.3ad

As of 2000, most gigabit channel-bonding schemes use the IEEE standard of Link Aggregation which was formerly clause 43 of the IEEE 802.3 standard added in March 2000 by the IEEE 802.3ad task force.[5] Nearly every network equipment manufacturer quickly adopted this joint standard over their proprietary standards.

802.1AX

The 802.3 maintenance task force report for the 9th revision project in November 2006 noted that certain 802.1 layers (such as 802.1X security) were positioned in the protocol stack below Link Aggregation which was defined as an 802.3 sublayer.[6] To resolve this discrepancy, the 802.3ax (802.1AX) task force was formed,[7] resulting in the formal transfer of the protocol to the 802.1 group with the publication of IEEE 802.1AX-2008 on 3 November 2008.[8]

https://en.wikipedia.org/wiki/Link_aggregation#802.1AX

- **RFC 3031 - Multiprotocol Label Switching Architecture (2001)**

Specifies the architecture for Multiprotocol Label Switching (MPLS).

https://en.wikipedia.org/wiki/Multiprotocol_Label_Switching

https://datatracker.ietf.org/doc/html/rfc3031

- **G.709 Interfaces for the Optical Transport Network (OTN) (2001)**

ITU-T Recommendation G.709 Interfaces for the Optical Transport Network (OTN) describes a means of communicating data over an optical network.[1] It is a standardized method for transparent transport of services over optical wavelengths in DWDM systems. It is also known as Optical Transport Hierarchy (OTH) standard. The first edition of this protocol was approved in 2001.[2]

https://en.wikipedia.org/wiki/G.709

- **G.984 GPON - gigabit-capable passive optical network (2003)**

G.984,[1] commonly known as GPON (gigabit-capable passive optical network), is a standard for passive optical networks (PON) published by the ITU-T. It is commonly used to implement the outermost link to the customer (last kilometre or last mile) of fibre-to-the-premises (FTTP) services.[2][3]

GPON puts requirements on the optical medium and the hardware used to access it, and defines the manner in which ethernet frames are converted to an optical signal, as well as the parameters of that signal. The bandwidth of the single connection between the OLT (optical line termination) and the ONTs (optical network terminals) is 2.4 Gbit/s down, 1.2 Gbit/s up, or rarely symmetric 2.4 Gbit/s,[1] shared between up to 128 ONTs using a time-division multiple access (TDMA) protocol, which the standard defines.[4] GPON specifies protocols for error correction (Reed–Solomon) and encryption (AES), and defines a protocol for line control (OMCI) which includes authentication.

https://en.wikipedia.org/wiki/G.984

- **802.3ad - 10 Gigabit Ethernet (2002)**

10 Gigabit Ethernet (10GE, 10GbE, or 10 GigE) is a group of computer networking technologies for transmitting Ethernet frames at a rate of 10 gigabits per second. It was first defined by the IEEE 802.3ae-2002 standard. Unlike previous Ethernet standards, 10 Gigabit Ethernet defines only full-duplex point-to-point links which are generally connected by network switches; shared-medium CSMA/CD operation has not been carried over from the previous generations Ethernet standards[1] so half-duplex operation and repeater hubs do not exist in 10GbE.[2]

The 10 Gigabit Ethernet standard encompasses a number of different physical layer (PHY) standards. A networking device, such as a switch or a network interface controller may have different PHY types through pluggable PHY modules, such as those based on SFP+.[3] Like previous versions of Ethernet, 10GbE can use either copper or fiber cabling. Maximum distance over copper cable is 100 meters but because of its bandwidth requirements, higher-grade cables are required.[a]

The adoption of 10 Gigabit Ethernet has been more gradual than previous revisions of Ethernet: in 2007, one million 10GbE ports were shipped, in 2009 two million ports were shipped, and in 2010 over three million ports were shipped,[4][5] with an estimated nine million ports in 2011.[6] As of 2012, although the price per gigabit of bandwidth for 10 Gigabit Ethernet was about one-third compared to Gigabit Ethernet, the price per port of 10 Gigabit Ethernet still hindered more widespread adoption.[7][8]

https://en.wikipedia.org/wiki/10_Gigabit_Ethernet

- **Power over Ethernet, or PoE (2003)**

Describes any of several standards or ad hoc systems that pass electric power along with data on twisted-pair Ethernet cabling. This allows a single cable to provide both data connection and electric power to devices such as wireless access points (WAPs), Internet Protocol (IP) cameras, and voice over Internet Protocol (VoIP) phones.

There are several common techniques for transmitting power over Ethernet cabling. Three of them have been standardized by Institute of Electrical and Electronics Engineers (IEEE) standard IEEE 802.3 since 2003.

https://en.wikipedia.org/wiki/Power_over_Ethernet

- **IEEE 802.3ah - Ethernet in the first mile, Ethernet to Home (2004)**

With wide, metro, and local area networks using various forms of Ethernet, the goal was to eliminate non-native transport such as Ethernet over Asynchronous Transfer Mode (ATM) from access networks.

One early effort was the EtherLoop technology invented at Nortel Networks in 1996, and then spun off into the company Elastic Networks in 1998.[1][2] Its principal inventor was Jack Terry. The hope was to combine the packet-based nature of Ethernet with the ability of digital subscriber line (DSL) technology to work over existing telephone access wires.[3] The name comes from local loop, which traditionally describes the wires from a telephone company office to a subscriber. The protocol was half-duplex with control from the provider side of the loop. It adapted to line conditions with a peak of 10 Mbit/s advertised, but 4-6 Mbit/s more typical, at a distance of about 12,000 feet (3,700 m). Symbol rates were 1 megabaud or 1.67 megabaud, with 2, 4, or 6 bits per symbol.[1] The EtherLoop product name was registered as a trademark in the US and Canada.[4] The EtherLoop technology was eventually purchased by Paradyne Networks in 2002,[5] which was in turn purchased by Zhone Technologies in 2005.[6]

Another effort was the concept promoted by Michael Silverton of using Ethernet variants that used fiber optic communication to residential as well as business customers. This was an example of what has become known as fiber to the home (FTTH). The Fiberhood Networks company provided this service from 1999 to 2001.[7][8]

Some early products around the year 2000, were marketed as 10BaseS by Infineon Technologies, although they did not technically use baseband signalling, but rather passband as in very-high-bit-rate digital subscriber line (VDSL) technology.[9] A patent was filed in 1997 by Peleg Shimon, Porat Boaz, Noam Alroy, Rubinstain Avinoam and Sfadya Yackow.[10] Long Reach Ethernet was the product name used by Cisco Systems starting in 2001.[11] It supported modes of 5 Mbit/s, 10 Mbit/s, and 15 Mbit/s depending on distance.[12][13]

In October 2000 Howard Frazier issued a call for interest on "Ethernet in the Last Mile".[14] At the November 2000 meeting, IEEE 802.3 created the "Ethernet in the First Mile" study group, and on July 16, 2001 the 802.3ah working group. In parallel participating vendors formed the Ethernet in the First Mile Alliance (EFMA) in December 2001 to promote Ethernet subscriber access technology and support the IEEE standard efforts.[15] At an early meeting, the EtherLoop technology was called 100BASE-CU and another technology called EoVDSL for Ethernet over VDSL.[16]

The working group's EFM standard was approved on June 24, 2004 and published on September 7, 2004 as IEEE 802.3ah-2004. In 2005 it was included into the base IEEE 802.3 standard. In 2005, the EFMA was absorbed by the Metro Ethernet Forum.[17]

https://en.wikipedia.org/wiki/Ethernet_in_the_first_mile

- **G.651.1 - multi-mode optical fiber (MMF) cable (2007)**

an international standard developed by the Standardization Sector of the International Telecommunication Union (ITU-T) that specifies multi-mode optical fiber (MMF) cable.

https://en.wikipedia.org/wiki/G.651.1

- **G.983 - Broadband Passive Optical Networks (BPON) (2007)**

ITU-T Recommendation G.983 is a family of recommendations that defines broadband passive optical network (BPON) for telecommunications Access networks. It originally comprised ten recommendations, G.983.1 through G.983.10, but recommendations .6–.10 were withdrawn when their content was incorporated into G.983.2.

https://en.wikipedia.org/wiki/G.983

- **IEEE 1675-2008 (2008), IEEE 1901 (2011) - broadband over power lines** 

was a standard for broadband over power lines developed by the IEEE Standards Association. It provided electric utility companies with a comprehensive standard for safely installing hardware required for Internet access capabilities over their power lines.
The standard was published 7 January 2008. The IEEE 1901 standard was another related attempt published in 2011.

https://en.wikipedia.org/wiki/IEEE_1675-2008

- **G.hn - 2 Gbit/s over legacy wires (2009)**

Specification for home networking with data rates up to 2 Gbit/s and operation over four types of legacy wires: telephone wiring, coaxial cables, power lines and plastic optical fiber. 
G.hn was developed under the International Telecommunication Union's Telecommunication Standardization sector (the ITU-T) and promoted by the HomeGrid Forum and several other organizations. ITU-T Recommendation (the ITU's term for standard) G.9960, which received approval on October 9, 2009,[2] specified the physical layers and the architecture of G.hn. The Data Link Layer (Recommendation G.9961) was approved on June 11, 2010.[3]

https://en.wikipedia.org/wiki/G.hn

#### Industrial Ethernet

- **Fieldbus - IEC 61784/61158 (2000)**

Fieldbus is the name of a family of industrial computer networks[1] used for real-time distributed control. Fieldbus profiles are standardized by the International Electrotechnical Commission (IEC) as IEC 61784/61158.

A complex automated industrial system is typically structured in hierarchical levels as a distributed control system (DCS). In this hierarchy the upper levels for production managements are linked to the direct control level of programmable logic controllers (PLC) via a non-time-critical communications system (e.g. Ethernet). The fieldbus[2] links the PLCs of the direct control level to the components in the plant of the field level such as sensors, actuators, electric motors, console lights, switches, valves and contactors and replaces the direct connections via current loops or digital I/O signals. The requirement for a fieldbus are therefore time-critical and cost sensitive. Since the new millennium a number of fieldbuses based on Real-time Ethernet have been established. These have the potential to replace traditional fieldbuses in the long term.

In June 1999 the IEC's Committee of Action (CA) decided to take a new structure for the fieldbus standards beginning with a first edition valid at the January 1, 2000, in time for the new millennium: There is a large IEC 61158 standard, where all fieldbuses find their place.[23] The experts have decided that the structure of IEC 61158 is maintained according to different layers, divided into services and protocols. The individual fieldbuses are incorporated into this structure as different types.

https://en.wikipedia.org/wiki/Fieldbus#IEC_61158:_Industrial_communication_networks_-_Fieldbus_specification

- **EtherNet/IP (2000-2009)**

EtherNet/IP (IP = Industrial Protocol)[1] is an industrial network protocol that adapts the Common Industrial Protocol (CIP) to standard Ethernet.[2] EtherNet/IP is one of the leading industrial protocols in the United States and is widely used in a range of industries including factory, hybrid and process. The EtherNet/IP and CIP technologies are managed by ODVA, Inc., a global trade and standards development organization founded in 1995 with over 300 corporate members.

EtherNet/IP uses both of the most widely deployed collections of Ethernet standards –the Internet Protocol suite and IEEE 802.3 – to define the features and functions for its transport, network, data link and physical layers. EtherNet/IP performs at level session and above (level 5, 6 and 7) of the OSI model. CIP uses its object-oriented design to provide EtherNet/IP with the services and device profiles needed for real-time control applications and to promote consistent implementation of automation functions across a diverse ecosystem of products. In addition, EtherNet/IP adapts key elements of Ethernet’s standard capabilities and services to the CIP object model framework, such as the User Datagram Protocol (UDP), which EtherNet/IP uses to transport I/O messages.

Ethernet/IP was estimated to have about 30% share of the industrial ethernet market in 2010[3] and 2018.[4]

Development of EtherNet/IP began in the 1990s within a technical working group of ControlNet International, Ltd.(CI), another trade and standards development organization, In 2000, ODVA and CI formed a joint technology agreement (JTA) for the development of EtherNet/IP. In 2009, the JTA was terminated and EtherNet/IP became under the sole control of ODVA and its members. Today, EtherNet/IP is one of four networks that adapt CIP to an industrial network along with DeviceNet, ControlNet and CompoNet. All of these networks are managed by ODVA, Inc.

https://en.wikipedia.org/wiki/EtherNet/IP

### Application layer

- **Ethernet Powerlink (2001)**

Ethernet Powerlink is a real-time protocol for standard Ethernet. It is an open protocol managed by the Ethernet POWERLINK Standardization Group (EPSG). It was introduced by Austrian automation company B&R in 2001.

https://en.wikipedia.org/wiki/Ethernet_Powerlink

- **RDP - Remote Desktop Protocol (2001)**

Microsoft proprietary protocol to connect to the windows desktop. Released with Windows XP.

https://en.wikipedia.org/wiki/Remote_Desktop_Protocol

- **SSH protocol architecture (2006)**

Includes SCP (superseded by SFTP).

https://www.rfc-editor.org/rfc/rfc4251

### Data layer

#### Web

- **HTML5 (2008)**

HTML5 is a markup language used for structuring and presenting content on the World Wide Web. It is the fifth and final[3] major HTML version that is a World Wide Web Consortium (W3C) recommendation. The current specification is known as the HTML Living Standard. It is maintained by the Web Hypertext Application Technology Working Group (WHATWG), a consortium of the major browser vendors (Apple, Google, Mozilla, and Microsoft).

HTML5 was first released in a public-facing form on 22 January 2008,[2] with a major update and "W3C Recommendation" status in October 2014.[4][5] Its goals were to improve the language with support for the latest multimedia and other new features; to keep the language both easily readable by humans and consistently understood by computers and devices such as web browsers, parsers, etc., without XHTML's rigidity; and to remain backward-compatible with older software. HTML5 is intended to subsume not only HTML 4 but also XHTML 1 and DOM Level 2 HTML.[6]

HTML5 includes detailed processing models to encourage more interoperable implementations; it extends, improves, and rationalizes the markup available for documents and introduces markup and application programming interfaces (APIs) for complex web applications.[7] For the same reasons, HTML5 is also a candidate for cross-platform mobile applications because it includes features designed with low-powered devices in mind.

https://en.wikipedia.org/wiki/HTML5

#### Binary data
- **ISO image (2000s)**

An optical disc image (or ISO image, from the ISO 9660 file system used with CD-ROM media) is a disk image that contains everything that would be written to an optical disc, disk sector by disc sector, including the optical disc file system.[2] ISO images are expected to contain the binary image of an optical media file system (usually ISO 9660 and its extensions or UDF), including the data in its files in binary format, copied exactly as they were stored on the disc. The data inside the ISO image will be structured according to the file system that was used on the optical disc from which it was created.

ISO images can be created from optical discs by disk imaging software, or from a collection of files by optical disc authoring software, or from a different disk image file by means of conversion. Software distributed on bootable discs is often available for download in ISO image format. And like any other ISO image, it may be written to an optical disc such as CD, DVD and Blu-Ray.

https://en.wikipedia.org/wiki/Optical_disc_image

- **ISOBMFF - ISO base media file format (2004)**

The ISO base media file format (ISOBMFF) is a container file format that defines a general structure for files that contain time-based multimedia data such as video and audio.[2][3] It is standardized in ISO/IEC 14496-12, a.k.a. MPEG-4 Part 12, and was formerly also published as ISO/IEC 15444-12, a.k.a. JPEG 2000 Part 12.

It is designed as a flexible, extensible format that facilitates interchange, management, editing and presentation of the media. The presentation may be local, or via a network or other stream delivery mechanism. The file format is designed to be independent of any particular network protocol while enabling support for them in general.[3]

The format has become very widely used for media file storage and as the basis for various other media file formats (e.g. the MP4 and 3GP container formats), and its widespread was recognized by a Technology & Engineering Emmy Award presented on 4 November 2021 by the National Academy of Television Arts and Sciences.[4][5][6]

https://en.wikipedia.org/wiki/ISO_base_media_file_format

#### Images

- **SVG - Scalable Vector Graphics - supersedes WMF (2001)**

Scalable Vector Graphics (SVG) is an XML-based vector image format for defining two-dimensional graphics, having support for interactivity and animation. The SVG specification is an open standard developed by the World Wide Web Consortium (W3C) since 1999.

https://en.wikipedia.org/wiki/Scalable_Vector_Graphics

#### Video

- **DivX Codec (1998-2007)**

DivX ;-) (not DivX) 3.11 Alpha and later 3.xx versions refers to a hacked version of the Microsoft MPEG-4 Version 3 video codec (not to be confused with MPEG-4 Part 3) from Windows Media Tools 4 codecs.[4][5] The video codec, which was actually not MPEG-4 compliant, was extracted around 1998 by French hacker Jerome Rota (also known as Gej) at Montpellier. The Microsoft codec originally required that the compressed output be put in an ASF file. It was altered to allow other containers such as Audio Video Interleave (AVI).[6] Rota hacked the Microsoft codec because newer versions of the Windows Media Player would not play his video portfolio and résumé that were encoded with it. Instead of re-encoding his portfolio, Rota and German hacker Max Morice decided to reverse engineer the codec, which "took about a week".[7]
In early 2000, Jordan Greenhall recruited Rota to form a company (originally called DivXNetworks, Inc., renamed to DivX, Inc. in 2005) to develop an MPEG-4 codec, from scratch, that would still be backward-compatible with the Microsoft MPEG-4 Version 3 format. This effort resulted first in the release of the "OpenDivX" codec and source code on 15 January 2001. OpenDivX was hosted as an open-source project on the Project Mayo web site hosted at projectmayo.com[8] (the name comes from "mayonnaise", because, according to Rota, DivX and mayonnaise are both "French and very hard to make."[7]). The company's internal developers and some external developers worked jointly on OpenDivX for the next several months, but the project eventually stagnated.
In early 2001, DivX employee "Sparky" wrote a new and improved version of the codec's encoding algorithm known as "encore2". This code was included in the OpenDivX public source repository for a brief time, but then was abruptly removed. The explanation from DivX at the time was that "the community really wants a Winamp, not a Linux." It was at this point that the project forked. That summer, Rota left the French Riviera and moved to San Diego "with nothing but a pack of cigarettes"[9] where he and Greenhall founded what would eventually become DivX, Inc.[7]
On 4 December 2007, native MPEG-4 ASP playback support was added to the Xbox 360,[27] allowing it to play video encoded with DivX and other MPEG-4 ASP codecs.[28]
On 17 December 2007, firmware upgrade 2.10 was released for the Sony PlayStation 3, which included official DivX Certification. Firmware version 2.50 (released on 15 October 2008) included support for the DivX Video on Demand (DivX VOD) service, and firmware version 2.60 (released on 20 January 2009) included official DivX Certification and updated Profile support to version 3.11.[29]

https://en.wikipedia.org/wiki/DivX

- **MPEG-4 file format (2001)**

On February 11, 1998, the ISO approved the QuickTime file format as the basis of the MPEG‑4 file format.[16] The MPEG-4 file format specification was created on the basis of the QuickTime format specification published in 2001.[17] The MP4 (.mp4) file format was published in 2001 as the revision of the MPEG-4 Part 1: Systems specification published in 1999 (ISO/IEC 14496-1:2001).[18][19][20] In 2003, the first version of MP4 format was revised and replaced by MPEG-4 Part 14: MP4 file format (ISO/IEC 14496-14:2003).[21] The MP4 file format was generalized into the ISO Base Media File Format ISO/IEC 14496-12:2004, which defines a general structure for time-based media files. It in turn is used as the basis for other multimedia file formats (for example 3GP, Motion JPEG 2000).[22][23][24][25][26] A list of all registered extensions for ISO Base Media File Format is published on the official registration authority website www.mp4ra.org. This registration authority for code-points in "MP4 Family" files is Apple Computer Inc. and it is named in Annex D (informative) in MPEG-4 Part 12.[25]

By 2000, MPEG-4 formats became industry standards, first appearing with support in QuickTime 6 in 2002. Accordingly, the MPEG-4 container is designed to capture, edit, archive, and distribute media, unlike the simple file-as-stream approach of MPEG-1 and MPEG-2.[27]

https://en.wikipedia.org/wiki/QuickTime

- **Advanced Video Coding (AVC) - H.264 - MPEG-4 Part 10 (2003)**

Advanced Video Coding (AVC), also referred to as H.264 or MPEG-4 Part 10, is a video compression standard based on block-oriented, motion-compensated coding.[2] It is by far the most commonly used format for the recording, compression, and distribution of video content, used by 91% of video industry developers as of September 2019.[3][4] It supports resolutions up to and including 8K UHD.[5][6]
The intent of the H.264/AVC project was to create a standard capable of providing good video quality at substantially lower bit rates than previous standards (i.e., half or less the bit rate of MPEG-2, H.263, or MPEG-4 Part 2), without increasing the complexity of design so much that it would be impractical or excessively expensive to implement. This was achieved with features such as a reduced-complexity integer discrete cosine transform (integer DCT),[6][7][8][9] variable block-size segmentation, and multi-picture inter-picture prediction. An additional goal was to provide enough flexibility to allow the standard to be applied to a wide variety of applications on a wide variety of networks and systems, including low and high bit rates, low and high resolution video, broadcast, DVD storage, RTP/IP packet networks, and ITU-T multimedia telephony system
H.264 was standardized by the ITU-T Video Coding Experts Group (VCEG) of Study Group 16 together with the ISO/IEC JTC1 Moving Picture Experts Group (MPEG). The project partnership effort is known as the Joint Video Team (JVT). The ITU-T H.264 standard and the ISO/IEC MPEG-4 AVC standard (formally, ISO/IEC 14496-10 – MPEG-4 Part 10, Advanced Video Coding) are jointly maintained so that they have identical technical content. The final drafting work on the first version of the standard was completed in May 2003, and various extensions of its capabilities have been added in subsequent editions. High Efficiency Video Coding (HEVC), a.k.a. H.265 and MPEG-H Part 2 is a successor to H.264/MPEG-4 AVC developed by the same organizations, while earlier standards are still in common use.
H.264 is perhaps best known as being the most commonly used video encoding format on Blu-ray Discs. It is also widely used by streaming Internet sources, such as videos from Netflix, Hulu, Amazon Prime Video, Vimeo, YouTube, and the iTunes Store, Web software such as the Adobe Flash Player and Microsoft Silverlight, and also various HDTV broadcasts over terrestrial (ATSC, ISDB-T, DVB-T or DVB-T2), cable (DVB-C), and satellite (DVB-S and DVB-S2) systems.

https://en.wikipedia.org/wiki/Advanced_Video_Coding

#### File sharing

- **SMB 2.0 (2006) - Microsoft**

Microsoft introduced a new version of the protocol (**SMB 2.0 or SMB2**) in 2006 with Windows Vista and Windows Server 2008.[26] Although the protocol is proprietary, its specification has been published to allow other systems to interoperate with Microsoft operating systems that use the new protocol.[27]

https://en.wikipedia.org/wiki/Server_Message_Block#SMB_2.0

#### Machine-to-Machine
- **JSON - JavaScript Object Notation - simplifies data interchange compared to XML (2001)**
 
open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values). First message sent in 2001.

Widely used. Later standardized.

https://en.wikipedia.org/wiki/JSON

#### TV

- **DVB-T2 - Digital Video Broadcasting — Second Generation Terrestrial (2007)**

DVB-T2 is an abbreviation for "Digital Video Broadcasting — Second Generation Terrestrial"; it is the extension of the television standard DVB-T, issued by the consortium DVB, devised for the broadcast transmission of digital terrestrial television. DVB has been standardized by ETSI.
This system transmits compressed digital audio, video, and other data in "physical layer pipes" (PLPs), using OFDM modulation with concatenated channel coding and interleaving. The higher offered bit rate, with respect to its predecessor DVB-T, makes it a system suited for carrying HDTV signals on the terrestrial TV channel (though many broadcasters still use plain DVB-T for this purpose). As of 2019, it was implemented in broadcasts in the United Kingdom (Freeview HD, eight channels across two multiplexes, plus an extra multiplex in Northern Ireland carrying three SD channels), Italy (Europa 7 HD, twelve channels), Finland (21 channels, five in HD), Germany (six HD (1080p50) channels, with 40 in planning),[1] the Netherlands (Digitenne, 30 HD (1080p50) channels), Sweden (five channels),[2][3] Thailand (41 SD, 9 HD channels),[4] Flanders (18 SD channels), Serbia (eight channels),[5] Ukraine (32 SD and HD channels in four nationwide multiplexes), Croatia (all national, local and pay-TV channels), Denmark (two pay-TV multiplexes with 20 channels), Romania (8 SD channels, 1 HD channel), and some other countries.
In March 2006 DVB decided to study options for an upgraded DVB-T standard. In June 2006, a formal study group named TM-T2 (Technical Module on Next Generation DVB-T) was established by the DVB Group to develop an advanced modulation scheme that could be adopted by a second generation digital terrestrial television standard, to be named DVB-T2.[6]
According to the commercial requirements and call for technologies[7] issued in April 2007, the first phase of DVB-T2 would be devoted to provide optimum reception for stationary (fixed) and portable receivers (i.e., units which can be nomadic, but not fully mobile) using existing aerials, whereas a second and third phase would study methods to deliver higher payloads (with new aerials) and the mobile reception issue. The novel system should provide a minimum 30% increase in payload, under similar channel conditions already used for DVB-T.
The BBC, ITV, Channel 4 and Channel 5 agreed with the regulator Ofcom to convert one UK multiplex (B, or PSB3) to DVB-T2 to increase capacity for HDTV via DTT.[8] They expected the first TV region to use the new standard would be Granada in November 2009 (with existing switched over regions being changed at the same time). It was expected that over time there would be enough DVB-T2 receivers sold to switch all DTT transmissions to DVB-T2, and H.264.
Ofcom published its final decision on 3 April 2008, for HDTV using DVB-T2 and H.264:[9] BBC HD would have one HD slot after digital switchover (DSO) at Granada. ITV and C4 had, as expected, applied to Ofcom for the 2 additional HD slots available from 2009 to 2012.[10]
Ofcom indicated that it found an unused channel covering 3.7 million households in London, which could be used to broadcast the DVB-T2 HD multiplex from 2010, i.e., before DSO in London. Ofcom indicated that they would look for more unused UHF channels in other parts of the UK, that can be used for the DVB-T2 HD multiplex from 2010 until DSO.[11]

https://en.wikipedia.org/wiki/DVB-T2

#### Automation

- **CC-Link Open Automation Networks (1996-2000+)**

The CC-Link Open Automation Networks Family are a group of open industrial networks that enable devices from numerous manufacturers to communicate. They are used in a wide variety of industrial automation applications at the machine, cell and line levels.

The CC-Link Partner Association (CLPA) offers a family of open-architecture networks. These originated with the CC-Link (Control & Communication) fieldbus in 1996,[1] developed by Mitsubishi Electric Corporation. In 2000,[2] this was released as an “Open” network so that independent automation equipment manufacturers could incorporate CLPA network compatibility into their products. In the same year, the CC-Link Partner Association (CLPA) was formed to manage and oversee the network technology and support manufacturer members. In 2007,[3] the CLPA was the first organisation to introduce open gigabit Ethernet for automation with CC-Link IE (Industrial Ethernet). In 2018,[4] the CLPA was the first organisation to combine open gigabit Ethernet with Time-Sensitive Networking (TSN) as CC-Link IE TSN. As of May 2020, over 2,100 CLPA compatible products from more than 340 automation manufacturers were available. CLPA offers a variety of open automation network technologies. These are the CC-Link fieldbus, CC-Link Safety fieldbus, CC-Link IE and CC-Link IE TSN. Compatible products include industrial PCs, PLCs, robots, servos, drives, valve manifolds, digital & analogue I/O modules, temperature controllers, mass flow controllers and others. As of May 2020, there was approximately 30 million devices installed worldwide.

https://en.wikipedia.org/wiki/CC-Link_Open_Automation_Networks

- **EtherCAT (2003+)**

EtherCAT (Ethernet for Control Automation Technology) is an Ethernet-based fieldbus system invented by Beckhoff Automation. The protocol is standardized in IEC 61158 and is suitable for both hard and soft real-time computing requirements in automation technology.

The goal during development of EtherCAT was to apply Ethernet for automation applications requiring short data update times (also called cycle times; ≤ 100 μs) with low communication jitter (for precise synchronization purposes; ≤ 1 μs) and reduced hardware costs.

The EtherCAT Technology Group (ETG) was established in 2003, and is the industrial Ethernet user organization with the most members in the world today

The EtherCAT Technology Group (ETG) is an official liaison partner of the IEC (International Electrotechnical Commission) working groups for digital communication. The EtherCAT specification was published as IEC/PAS 62407[8] in 2005, which was removed end of 2007 since EtherCAT had been integrated into the international fieldbus standards IEC 61158[9][10] and IEC 61784-2[11] as well as into the drive profile standard IEC 61800-7.[12] These IEC standards have been approved unanimously in September and October 2007 and were published as IS (International Standards) later that year. In IEC 61800-7

https://en.wikipedia.org/wiki/EtherCAT

- **PROFINET (2003+)**

Profinet (usually styled as PROFINET, as a portmanteau for Process Field Net) is an industry technical standard for data communication over Industrial Ethernet, designed for collecting data from, and controlling equipment in industrial systems, with a particular strength in delivering data under tight time constraints. The standard is maintained and supported by Profibus and Profinet International, an umbrella organization headquartered in Karlsruhe, Germany.

At the general meeting of the Profibus user organisation in 2000, the first concrete discussions for a successor to Profibus based on Ethernet took place. Just one year later, the first specification of Component Based Automation (CBA) was published and presented at the Hanover Fair. In 2002, the Profinet CBA became part of the international standard IEC 61158 / IEC 61784-1.

A Profinet CBA system [27] consists of different automation components. One component comprises all mechanical, electrical and information technology variables. The component may have been created with the usual programming tools. To describe a component, a Profinet Component Description (PCD) file is created in XML. A planning tool loads these descriptions and allows the logical connections between the individual components to be created to implement a plant.

The basic idea behind Profinet CBA was that in many cases it is possible to divide an entire automation system into autonomously operating - and thus manageable - subsystems. The structure and functionality may well be found in several plants in identical or slightly modified form. Such so-called Profinet components are normally controlled by a manageable number of input signals. Within the component, a control program written by the user executes the required functionality and sends the corresponding output signals to another controller. The communication of a component-based system is planned instead of programmed. Communication with Profinet CBA was suitable for bus cycle times of approx. 50 to 100 ms.

Individual systems show how these concepts can be successfully implemented in the application. However, Profinet CBA does not find the expected acceptance in the market and will no longer be listed in the IEC 61784-1 standard from the 4th edition of 2014.

In 2003 the first specification of Profinet IO (IO = Input Output) was published. The application interface of the Profibus DP (DP = Decentralized Periphery), which was successful on the market, was adopted and supplemented with current protocols from the Internet. In the following year, the extension with isochronous transmission follows, which makes Profinet IO suitable for motion control applications. Profisafe is adapted so that it can also be used via Profinet. With the clear commitment of AIDA[28] to Profinet in 2004, acceptance in the market is given. In 2006 Profinet IO becomes part of the international standard IEC 61158 / IEC 61784-2.

In 2007, according to the neutral count, 1 million Profinet devices have already been installed, in the following year this number doubles to 2 million. By 2019, a total of 26 million[29] devices sold by the various manufacturers are reported.

In 2019, the specification for Profinet was completed with Time-Sensitive Networking (TSN),[30] thus introducing the CC-D conformance class.

https://en.wikipedia.org/wiki/Profinet

- **SERCOS (2003-2005)**

Sercos III is the third generation of the Sercos interface, a standardized open digital interface for the communication between industrial controls, motion devices, input/output devices (I/O), and Ethernet nodes, such as PCs. Sercos III applies the hard real-time features of the Sercos interface to Ethernet. It is based upon and conforms to the Ethernet standard (IEEE 802.3 & ISO/IEC 8802-3). Work began on Sercos III in 2003,[1] with vendors releasing first products supporting it in 2005.[2]

https://en.wikipedia.org/wiki/SERCOS_III

## Programming languages and frameworks
**[`^        back to top        ^`](#)**

- **.NET Framework (2000-2019) - Microsoft**

The .NET Framework (pronounced as "dot net") is a proprietary software framework developed by Microsoft that runs primarily on Microsoft Windows. It was the predominant implementation of the Common Language Infrastructure (CLI) until being superseded by the cross-platform .NET project. It includes a large class library called Framework Class Library (FCL) and provides language interoperability (each language can use code written in other languages) across several programming languages. Programs written for .NET Framework execute in a software environment (in contrast to a hardware environment) named the Common Language Runtime (CLR). The CLR is an application virtual machine that provides services such as security, memory management, and exception handling. As such, computer code written using .NET Framework is called "managed code". FCL and CLR together constitute the .NET Framework.

FCL provides the user interface, data access, database connectivity, cryptography, web application development, numeric algorithms, and network communications. Programmers produce software by combining their source code with .NET Framework and other libraries. The framework is intended to be used by most new applications created for the Windows platform. Microsoft also produces an integrated development environment for .NET software called Visual Studio.

.NET Framework began as proprietary software, although the firm worked to standardize the software stack almost immediately, even before its first release. Despite the standardization efforts, developers, mainly those in the free and open-source software communities, expressed their unease with the selected terms and the prospects of any free and open-source implementation, especially regarding software patents. Since then, Microsoft has changed .NET development to more closely follow a contemporary model of a community-developed software project, including issuing an update to its patent promising to address the concerns.[2]

Microsoft began developing .NET Framework in the late 1990s, originally under the name of Next Generation Windows Services (NGWS), as part of the .NET strategy. By early 2000, the first beta versions of .NET 1.0 were released.

In August 2000, Microsoft, and Intel worked to standardize Common Language Infrastructure (CLI) and C#. By December 2001, both were ratified Ecma International (ECMA) standards.[4][5] International Organization for Standardization (ISO) followed in April 2003. The current version of ISO standards are ISO/IEC 23271:2012 and ISO/IEC 23270:2006.[6][7]

While Microsoft and their partners hold patents for CLI and C#, ECMA and ISO require that all patents essential to implementation be made available under "reasonable and non-discriminatory terms". The firms agreed to meet these terms, and to make the patents available royalty-free. However, this did not apply to the part of the .NET Framework not covered by ECMA-ISO standards, which included Windows Forms, ADO.NET, and ASP.NET. Patents that Microsoft holds in these areas may have deterred non-Microsoft implementations of the full framework.[8]

On October 3, 2007, Microsoft announced that the source code for .NET Framework 3.5 libraries was to become available under the Microsoft Reference Source License (Ms-RSL[a]).[9] The source code repository became available online on January 16, 2008, and included BCL, ASP.NET, ADO.NET, Windows Forms, WPF, and XML. Scott Guthrie of Microsoft promised that LINQ, WCF, and WF libraries were being added.[10]

The .NET Compact Framework and .NET Micro Framework variants of the .NET Framework provided support for other Microsoft platforms such as Windows Mobile, Windows CE and other resource-constrained embedded devices. Silverlight provided support for web browsers via plug-ins.

https://en.wikipedia.org/wiki/.NET_Framework

- **CUDA (2007) - Nvidia**

CUDA (or Compute Unified Device Architecture) is a parallel computing platform and application programming interface (API) that allows software to use certain types of graphics processing units (GPUs) for general purpose processing, an approach called general-purpose computing on GPUs (GPGPU). CUDA is a software layer that gives direct access to the GPU's virtual instruction set and parallel computational elements, for the execution of compute kernels.[1]

CUDA is designed to work with programming languages such as C, C++, and Fortran. This accessibility makes it easier for specialists in parallel programming to use GPU resources, in contrast to prior APIs like Direct3D and OpenGL, which required advanced skills in graphics programming.[2] CUDA-powered GPUs also support programming frameworks such as OpenMP, OpenACC and OpenCL;[3][1] and HIP by compiling such code to CUDA.

CUDA was created by Nvidia.[4] When it was first introduced, the name was an acronym for Compute Unified Device Architecture,[5] but Nvidia later dropped the common use of the acronym.

https://en.wikipedia.org/wiki/CUDA

## Navigation
**[`^        back to top        ^`](#)**

- **Civilian GPS use with non-degraded signal (2000)**

On May 2, 2000 "Selective Availability" was discontinued as a result of the 1996 executive order, allowing civilian users to receive a non-degraded signal globally.

- **Europe Galileo (2004)**
In 2004, the United States government signed an agreement with the European Community establishing cooperation related to GPS and Europe's Galileo system.

In 2004, United States President George W. Bush updated the national policy and replaced the executive board with the National Executive Committee for Space-Based Positioning, Navigation, and Timing.[61]

- **GPS for mobile phones (2004)**

November 2004, Qualcomm announced successful tests of assisted GPS for mobile phones.[62]

- **GPS aging infrastructure, modernized GPS satellite**

In 2005, the first modernized GPS satellite was launched and began transmitting a second civilian signal (L2C) for enhanced user performance.[63]

On September 14, 2007, the aging mainframe-based Ground Segment Control System was transferred to the new Architecture Evolution Plan.[64]

On May 19, 2009, the United States Government Accountability Office issued a report warning that some GPS satellites could fail as soon as 2010.[65]

On May 21, 2009, the Air Force Space Command allayed fears of GPS failure, saying "There's only a small risk we will not continue to exceed our performance standard."
[66]

https://en.wikipedia.org/wiki/Global_Positioning_System



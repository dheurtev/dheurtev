# 1980s 

**In short:**
- [Inventions](#inventions) : Color inkjet printer, STN passive matrix LCD screens invention, First RFID patent, Passive Optical Networks (PON) (1987) proposal, first practical organic LED (OLED) device, FinFET, Larger (14") TFT screens
- [Electronics](#electronics) : From published schematic diagrams to motherboards, first commercial flash memory, first commercial blue LED based on the indirect bandgap semiconductor
- [Energy](#energy) : 
- [Telecommunications](#telecommunications) : T3 circuits, breakup of the Bell system, birth of ILECs (1984), artificial division between long distance and local calls in the U.S. (1985) (1985), single-mode optical fibre and cable, ISDN, , ISPs
- [Networking](#networking) : OSI Model vs. TCP/IP War - TCP/IP Emergence (IPv4), Remote Procedure Call (RPC), Ethernet (IEEE 802.3), multiprotocol router (Cisco IOS), original standard for Ethernet over fiber (FOIRL), BBS, NSFNET and first internet access
- [Cryptography](#cryptography) : Age of RSA - RSA patent granted, X.509
- [Computers](#computers) :
  * [Form factor](#form-factor) : 
  * [OS](#os) : 
    
    *Client* : IBM DOS (Microsft MS DOS), Apple MacOS, Microsoft Windows 2.0, 
  
  * [Peripherals](#peripherals) : Laser printing to mass markets
  * [Storage](#storage) : Internal HDD (10 MB), 3"1/2 Floppy Disk, external drive
  * [Uses](#uses) :
    
    *Server*: DNS (Bind), Bulletin Board System (BBS)
    
    *CGI*: Pixar early history, first Academy Award for a computer-generated film (Tin Toy)
- [Consumer Electronics](#consumer-electronics) :
  * [Gadgets](#gadgets) : Symbolic computing and graphing calculators
  * [Multimedia](#multimedia) : Infrared LED remote controls (Starcom Cable TV Converter), pocket LCV TVs, audio compact disk player
  * [Screens](#screens) : Orange-on-black plasma screen for laptops, Flat screen CRT TV, SVGA Graphics Cards
  * [Broadcast](#broadcast) : TVRO/C-band satellite era, HD-MAC - last analog HDTV system 
  * [Video games](#video-games) : Golden age - third generation of video games consoles (Nintendo NES, Sega Master), crash of 1983 (ET Game), fourth generation of video games consoles generations (NEC Home Electronics, Nintendo Gameboy), recovery and decline of arcade games
- [Standards and protocols](#standards-and-protocols) : Compact Disc Digital Audio (CD), WWW, BMP, GIF, email protocols, IRC, Zip (PKZIP), ISO 9660 file system, EDI (EFIFACT, ODETTE/OFTP), Netbios, SMB, Modems speeds (V22, V22bis, V32)
- [Programming languages and frameworks](#programming-languages-and-frameworks) :
- [Navigation](#navigation) : Decision to open GPS to civilian use and deployment of modern GPS satellites

## Inventions
**[`^        back to top        ^`](#)**

- **Color inkjet printer (1982) - Robert Howard**

In 1982, Robert Howard came up with the idea to produce a small color printing system that used piezos to spit drops of ink. He formed the company, R.H. (Robert Howard) Research (named Howtek, Inc. in Feb 1984), and developed the revolutionary technology that led to the Pixelmaster color printer with solid ink[6] using Thermojet technology. This technology consists of a tubular single nozzle acoustical wave drop generator invented originally by Steven Zoltan in 1972 with a glass nozzle and improved by the Howtek inkjet engineer in 1984 with a Tefzel molded nozzle to remove unwanted fluid frequencies.

https://en.wikipedia.org/wiki/Inkjet_printing

- **STN passive matrix LCD screens invention (1983) - Brown, Boveri & Cie (BBC) Research Center**

In 1983, researchers at Brown, Boveri & Cie (BBC) Research Center, Switzerland, invented the super-twisted nematic (STN) structure for passive matrix-addressed LCDs. H. Amstutz et al. were listed as inventors in the corresponding patent applications filed in Switzerland on July 7, 1983, and October 28, 1983. Patents were granted in Switzerland CH 665491, Europe EP 0131216,[68] U.S. Patent 4,634,229 and many more countries. In 1980, Brown Boveri started a 50/50 joint venture with the Dutch Philips company, called Videlec.[69] Philips had the required know-how to design and build integrated circuits for the control of large LCD panels. In addition, Philips had better access to markets for electronic components and intended to use LCDs in new product generations of hi-fi, video equipment and telephones. In 1984, Philips researchers Theodorus Welzen and Adrianus de Vaan invented a video speed-drive scheme that solved the slow response time of STN-LCDs, enabling high-resolution, high-quality, and smooth-moving video images on STN-LCDs.[70] In 1985, Philips inventors Theodorus Welzen and Adrianus de Vaan solved the problem of driving high-resolution STN-LCDs using low-voltage (CMOS-based) drive electronics, allowing the application of high-quality (high resolution and video speed) LCD panels in battery-operated portable products like notebook computers and mobile phones.[71] In 1985, Philips acquired 100% of the Videlec AG company based in Switzerland. Afterwards, Philips moved the Videlec production lines to the Netherlands. Years later, Philips successfully produced and marketed complete modules (consisting of the LCD screen, microphone, speakers etc.) in high-volume production for the booming mobile phone industry.

https://en.wikipedia.org/wiki/Liquid-crystal_display

- **First RFID patent (1983)**

May 17, 1983: The first patent to be associated with the abbreviation "RFID" was granted to Charles Walton.[16]

https://en.wikipedia.org/wiki/Near-field_communication

- **Passive Optical Networks (PON) proposed (1987) - British Telecommunication**

A passive optical network (PON) is a fiber-optic telecommunications technology for delivering broadband network access to end-customers. Its architecture implements a point-to-multipoint topology in which a single optical fiber serves multiple endpoints by using unpowered (passive) fiber optic splitters to divide the fiber bandwidth among the endpoints. Passive optical networks are often referred to as the last mile between an Internet service provider (ISP) and its customers.[1]

Passive optical networks were first proposed by British Telecommunications in 1987.

https://en.wikipedia.org/wiki/Passive_optical_network

- **first practical organic LED (OLED) device (1987) - Eastman Kodak**

Chemists Ching Wan Tang and Steven Van Slyke at Eastman Kodak built the first practical OLED device in 1987.[28] This device used a two-layer structure with separate hole transporting and electron transporting layers such that recombination and light emission occurred in the middle of the organic layer; this resulted in a reduction in operating voltage and improvements in efficiency.

https://en.wikipedia.org/wiki/OLED

- **FinFET - Hitachi (1988)** 

FinFET (fin field-effect transistor), a type of 3D multi-gate MOSFET, was developed by Digh Hisamoto and his team of researchers at Hitachi Central Research Laboratory in 1989.[18][19]

https://en.wikipedia.org/wiki/Semiconductor_device

- **Larger (14") TFT screens (1988) - Sharp**

In 1988, a Sharp research team led by engineer T. Nagayasu demonstrated a 14-inch full-color LCD display,[10][18] which convinced the electronics industry that LCD would eventually replace CRTs as the standard television display technology.[10]

https://en.wikipedia.org/wiki/Flat-panel_display

## Electronics
**[`^        back to top        ^`](#)**

- **From published schematic diagrams to motherboards (single Integrated Circuits) (1980s)**
 
The most popular computers of the 1980s such as the Apple II and IBM PC had published schematic diagrams and other documentation which permitted rapid reverse-engineering and third-party replacement motherboards. Usually intended for building new computers compatible with the exemplars, many motherboards offered additional performance or other features and were used to upgrade the manufacturer's original equipment.

During the late 1980s and early 1990s, it became economical to move an increasing number of peripheral functions onto the motherboard. In the late 1980s, personal computer motherboards began to include single ICs (also called Super I/O chips) capable of supporting a set of low-speed peripherals: PS/2 keyboard and mouse, floppy disk drive, serial ports, and parallel ports.

https://en.wikipedia.org/wiki/Motherboard

- **Firt commercial flash memory - (1987, Toshiba), (1988, Intel)**

Toshiba commercially launched NAND flash memory in 1987.[1][13] Intel Corporation introduced the first commercial NOR type flash chip in 1988.[22

https://en.wikipedia.org/wiki/Flash_memory

In 1989, Intel employed the FGMOS as an analog nonvolatile memory element** in its **electrically trainable artificial neural network (ETANN) chip**,[3] demonstrating the potential of using FGMOS devices for applications other than digital memory.

https://en.wikipedia.org/wiki/Floating-gate_MOSFET

- **First commercial blue LED based on the indirect bandgap semiconductor, silicon carbide (SiC) (1989) - Cree**

In August 1989, Cree introduced the first commercially available blue LED based on the indirect bandgap semiconductor, silicon carbide (SiC).[43] SiC LEDs had very low efficiency, no more than about 0.03%, but did emit in the blue portion of the visible light spectrum.[44][45]

https://en.wikipedia.org/wiki/Light-emitting_diode

## Energy
**[`^        back to top        ^`](#)**


## Telecommunications
**[`^        back to top        ^`](#)**

- **Leased lines - T3 circuits**

With the extension of digital services in the 1980s, **leased lines were used to connect customer premises to frame relay or ATM networks**. Access data rates increased from the original T1 option with maximum transmission speed of 1.544 Mbit/s up to **T3 circuits**.

https://en.wikipedia.org/wiki/Leased_line

- **Breakup of the Bell System (1984) - Birth of ILECs, inter-exchange carrier, local exchange carrier**

During the 1970s, a growing conviction that the scope of AT&T's monopoly had become more of a hindrance than a stimulus to innovation led to a new antitrust case against the company. The resulting settlement produced the Bell breakup in 1984, the artificial division of the industry between local and long-distance calling, and the opening of the long-distance market to full competition.

https://www.princeton.edu/~starr/articles/articles02/Starr-TelecomImplosion-9-02.htm

The breakup of the Bell System was mandated on January 8, 1982, by an agreed consent decree providing that AT&T Corporation would, as had been initially proposed by AT&T, relinquish control of the Bell Operating Companies, which had provided local telephone service in the United States.[1] This effectively took the monopoly that was the Bell System and split it into entirely separate companies that would continue to provide telephone service. AT&T would continue to be a provider of long-distance service, while the now-independent Regional Bell Operating Companies (RBOCs), nicknamed the "Baby Bells", would provide local service, and would no longer be directly supplied with equipment from AT&T subsidiary Western Electric.

This divestiture was initiated by the filing in 1974 by the United States Department of Justice of an antitrust lawsuit against AT&T.[2] AT&T was, at the time, the sole provider of telephone service throughout most of the United States. Furthermore, most telephonic equipment in the United States was produced by its subsidiary Western Electric. This vertical integration led AT&T to have almost total control over communication technology in the country, which led to the antitrust case United States v. AT&T. The plaintiff in the court complaint asked the court to order AT&T to divest ownership of Western Electric.[3]

Feeling that it was about to lose the suit, AT&T proposed an alternative: its breakup. It proposed that it retain control of Western Electric, Yellow Pages, the Bell trademark, Bell Labs, and AT&T Long Distance. It also proposed that it be freed from a 1956 antitrust consent decree, then administered by Judge Vincent P. Biunno in the United States District Court for the District of New Jersey, that barred it from participating in the general sale of computers (retreat from international markets, relinquish ownership in Bell Canada, and Northern Electric a Western Electric subsidiary).[4] In return, it proposed to give up ownership of the local operating companies. This last concession, it argued, would achieve the government's goal of creating competition in supplying telephone equipment and supplies to the operative companies. The settlement was finalized on January 8, 1982, with some changes ordered by the decree court: the regional holding companies got the Bell trademark, Yellow Pages, and about half of Bell Labs.

Effective January 1, 1984, the Bell System's many member companies were variously merged into seven independent "Regional Holding Companies", also known as Regional Bell Operating Companies (RBOCs), or "Baby Bells". This divestiture reduced the book value of AT&T by approximately 70%.

https://en.wikipedia.org/wiki/Breakup_of_the_Bell_System

An **incumbent local exchange carrier (ILEC)** is a local telephone company which held the regional monopoly on landline service before the market was opened to competitive local exchange carriers, or the corporate successor of such a firm.

In the United States, ILECs were companies in existence at the time of the breakup of AT&T into the Regional Bell Operating Companies (RBOCs), also known as the "Baby Bells"

https://en.wikipedia.org/wiki/Incumbent_local_exchange_carrier

- **Artificial division between long distance and local calls in the U.S. (1985)**

Even after the breakup of the Bell system in 1984, AT&T and the regional Bell operating companies (the "Baby Bells") had remained bulwarks of the economy.

https://www.princeton.edu/~starr/articles/articles02/Starr-TelecomImplosion-9-02.htm

Three types of carriers could be distinguished:
- **Inter-Exchange Carrier (IEC)**, a company allowed to handle long-distance calls following the break-up of the Bell system in the US by anti-trust regulators.
https://foldoc.org/IntereXchange+Carrier
- **Local Exchange Carriers (LEC)**, a company allowed to handle local calls following the break-up of the Bell system in the US by anti-trust regulators. These vary from Regional Bell Operating Companies (RBOC) through to small independents such as Farmers Cooperative.
https://foldoc.org/Local+Exchange+Carriers
- **Competitive Access Providers (CAP) or "Bypass Carrier"**, a company which provided network links between the customer and the IntereXchange Carrier or even directly to the InternetService Provider. CAPs operate private networks independentof Local Exchange Carriers.
https://foldoc.org/Competitive+Access+Provider

LEC were not allowed to handle long-distance traffic and Inter Exchange carriers were not allowed to handle local calls.

- **Integrated Services Digital Network (ISDN) (1988)** 

ISDN is a set of communication standards for simultaneous digital transmission of voice, video, data, and other network services over the digitalised circuits of the public switched telephone network.[1] Work on the standard began in 1980 at Bell Labs and was formally standardized in 1988 in the CCITT "Red Book".
Prior to ISDN, the telephone system consisted of digital links like T1/E1 on the long-distance lines between telephone company offices and analog signals on copper telephone wires to the customers, the "last mile". 

https://en.wikipedia.org/wiki/Integrated_Services_Digital_Network

- **ISPs - Internet Service Providers (1980s)**

An Internet service provider (ISP) is an organization that provides services for accessing, using, or participating in the Internet. ISPs can be organized in various forms, such as commercial, community-owned, non-profit, or otherwise privately owned.

Internet services typically provided by ISPs can include Internet access, Internet transit, domain name registration, web hosting, Usenet service, and colocation.

An ISP typically serves as the access point or the gateway that provides a user access to everything available on the Internet.[1] Such a network can also be called as an eyeball network.

During the 1980s, online service providers such as CompuServe and America On Line (AOL) began to offer limited capabilities to access the Internet, such as e-mail interchange, but full access to the Internet was not readily available to the general public.

In 1989, the first Internet service providers, companies offering the public direct access to the Internet for a monthly fee, were established in Australia[4] and the United States. In Brookline, Massachusetts, **The World** became the first commercial ISP in the US. Its first customer was served in November 1989.[5] These companies generally offered dial-up connections, using the public telephone network to provide last-mile connections to their customers. The barriers to entry for dial-up ISPs were low and many providers emerged.

However, cable television companies and the telephone carriers already had wired connections to their customers and could offer Internet connections at much higher speeds than dial-up using broadband technology such as cable modems and digital subscriber line (DSL). As a result, these companies often became the dominant ISPs in their service areas, and what was once a highly competitive ISP market became effectively a monopoly or duopoly in countries with a commercial telecommunications market, such as the United States.

In 1995, NSFNET was decommissioned removing the last restrictions on the use of the Internet to carry commercial traffic and network access points were created to allow peering arrangements between commercial ISPs.

https://en.wikipedia.org/wiki/Internet_service_provider

## Networking
**[`^        back to top        ^`](#)**

- **OSI Model vs. TCP/IP War - TCP/IP Emergence (IPv4)**

Hubert Zimmermann, and Charles Bachman as chairman, played a key role in the development of the Open Systems Interconnections reference model. Beginning in 1978, this international work led to a draft proposal in 1980 and the final OSI model was published in 1984.

The early research and development of standards for data networks and protocols culminated in the Internet–OSI Standards War in the late 1980s and early 1990s.
Beginning in the early 1980s, ARPA pursued commercial partnerships with the telecommunication and computer industry which enabled the adoption of TCP/IP. In Europe, CERN purchased UNIX machines with TCP/IP for their intranet between 1984 and 1988

At the beginning of the 1990s, academic institutions and organizations in some European countries had adopted TCP/IP.[nb 6] In February 1990 RARE stated "without putting into question its OSI policy, recognizes the TCP/IP family of protocols as an open multivendor suite, well adapted to scientific and technical applications." In the same month, CERN established a transatlantic TCP/IP link with Cornell University in the United States.[53][67] Conversely, starting in August 1990, the NSFNET backbone supported the OSI Connectionless Network Protocol (CLNP) in addition to TCP/IP. 

https://en.wikipedia.org/wiki/Protocol_Wars

- **RPC - Remote Procedure Call (1981)**

In distributed computing, a remote procedure call (RPC) is when a computer program causes a procedure (subroutine) to execute in a different address space (commonly on another computer on a shared network), which is coded as if it were a normal (local) procedure call, without the programmer explicitly coding the details for the remote interaction. That is, the programmer writes essentially the same code whether the subroutine is local to the executing program, or remote. This is a form of client–server interaction (caller is client, executor is server), typically implemented via a request–response message-passing system. In the object-oriented programming paradigm, RPCs are represented by remote method invocation (RMI). The RPC model implies a level of location transparency, namely that calling procedures are largely the same whether they are local or remote, but usually, they are not identical, so local calls can be distinguished from remote calls. Remote calls are usually orders of magnitude slower and less reliable than local calls, so distinguishing them is important.

RPCs are a form of inter-process communication (IPC), in that different processes have different address spaces: if on the same host machine, they have distinct virtual address spaces, even though the physical address space is the same; while if they are on different hosts, the physical address space is different. Many different (often incompatible) technologies have been used to implement the concept.

Request–response protocols date to early distributed computing in the late 1960s, theoretical proposals of remote procedure calls as the model of network operations date to the 1970s, and practical implementations date to the early 1980s. Bruce Jay Nelson is generally credited with coining the term "remote procedure call" in 1981.[1]

Remote procedure calls used in modern operating systems trace their roots back to the RC 4000 multiprogramming system,[2] which used a request-response communication protocol for process synchronization.[3] The idea of treating network operations as remote procedure calls goes back at least to the 1970s in early ARPANET documents.[4] In 1978, Per Brinch Hansen proposed Distributed Processes, a language for distributed computing based on "external requests" consisting of procedure calls between processes.[5]

One of the earliest practical implementations was in 1982 by Brian Randell and colleagues for their Newcastle Connection between UNIX machines.[6] This was soon followed by "Lupine" by Andrew Birrell and Bruce Nelson in the Cedar environment at Xerox PARC.[7][8][9] Lupine automatically generated stubs, providing type-safe bindings, and used an efficient protocol for communication.[8] One of the first business uses of RPC was by Xerox under the name "Courier" in 1981. The first popular implementation of RPC on Unix was Sun's RPC (now called ONC RPC), used as the basis for Network File System (NFS).

In the 1990s, with the popularity of object-oriented programming, an alternative model of remote method invocation (RMI) was widely implemented, such as in Common Object Request Broker Architecture (CORBA, 1991) and Java remote method invocation. RMIs, in turn, fell in popularity with the rise of the internet, particularly in the 2000s.

https://en.wikipedia.org/wiki/Remote_procedure_call

- **Ethernet (1980) - IEEE 802.3 (1983)**
Ethernet (/ˈiːθərnɛt/) is a family of wired computer networking technologies commonly used in local area networks (LAN), metropolitan area networks (MAN) and wide area networks (WAN).[1] It was commercially introduced in 1980 and first standardized in 1983 as IEEE 802.3. Ethernet has since been refined to support higher bit rates, a greater number of nodes, and longer link distances, but retains much backward compatibility. Over time, Ethernet has largely replaced competing wired LAN technologies such as Token Ring, FDDI and ARCNET.

The original 10BASE5 Ethernet uses coaxial cable as a shared medium, while the newer Ethernet variants use twisted pair and fiber optic links in conjunction with switches. Over the course of its history, Ethernet data transfer rates have been increased from the original 2.94 Mbit/s[2] to the latest 400 Gbit/s, with rates up to 1.6 Tbit/s under development. The Ethernet standards include several wiring and signaling variants of the OSI physical layer.

https://en.wikipedia.org/wiki/Ethernet

- **BBS - Bulletin Board System (1980s)**

With the advent of the personal computer (PCs) in the early 1980s, one could use a modem to dial into a remote mainframe computer. In this case, the PC was used like a dumb terminal. But now files could be transferred and one PC could connect to another via modems.

The 1980s saw the rise of the **Bulletin Board System (BBS)**. A BBS was just a computer with a modem listening for incoming calls. The public could dial up a BBS with a modem and then download free software, participate in discussions on various topics, play on-line games, etc. Dialing in to a BBS was something like going to an Internet site. Except that to go to another BBS site, you would need to dial another number (and possible pay long distance telephone charges). Many BBSs would have a monthly charge but some were run by volunteers and were free. Many companies established BBSs for customers that contained support information, catalogs, etc. In the early 1990s, BBSs were booming. By the mid 1990s some even offered Internet connections. For some history of BBSs see Sysops' Corner: History of BBSing

https://tldp.org/HOWTO/Modem-HOWTO-29.html

- **Multiprotocol router - Cisco IOS (1985)**

Cisco Systems was founded in December 1984 by Sandy Lerner along with her husband Leonard Bosack. Lerner was the director of computer facilities for the Stanford University Graduate School of Business. Bosack was in charge of the Stanford University computer science department's computers.[15]

Cisco's initial product has roots in Stanford University's campus technology. In the early 1980s students and staff at Stanford, including Bosack, used technology on the campus to link all of the school's computer systems to talk to one another, creating a box that functioned as a **multiprotocol router** called the "Blue Box".[16] The Blue Box used circuitry made by Andy Bechtolsheim, and software that was originally written at Stanford by research engineer William Yeager.[16] Due to the underlying architecture, and its ability to scale well, Yeager's well-designed invention became a key to Cisco's early success.[17]

In 1985, Bosack and Stanford employee Kirk Lougheed began a project to formally network Stanford's campus.[16] They adapted Yeager's software into what became the foundation for **Cisco IOS**, despite Yeager's claims that he had been denied permission to sell the Blue Box commercially. On July 11, 1986, Bosack and Lougheed were forced to resign from Stanford and the university contemplated filing criminal complaints against Cisco and its founders for the theft of its software, hardware designs, and other intellectual properties.[16] In 1987, Stanford licensed the router software and two computer boards to Cisco.[16] In addition to Bosack, Lerner, Lougheed, Greg Satz (a programmer), and Richard Troiano (who handled sales), completed the early Cisco team.[16] The company's first CEO was Bill Graves, who held the position from 1987 to 1988.[18] In 1988, John Morgridge was appointed CEO.[1

- **NSFNET (1986)**

In the early 1980s, the National Science Foundation (NSF) funded national supercomputing centers at several universities in the United States, and provided interconnectivity in 1986 with the NSFNET project, thus creating network access to these supercomputer sites for research and academic organizations in the United States. International connections to NSFNET, the emergence of architecture such as the Domain Name System, and the adoption of TCP/IP internationally on existing networks marked the beginnings of the Internet.[6][7][8] Commercial Internet service providers (ISPs) emerged in 1989 in the United States and Australia.[9] The ARPANET was decommissioned in 1990.[10] Limited private connections to parts of the Internet by officially commercial entities emerged in several American cities by late 1989 and 1990.

https://en.wikipedia.org/wiki/History_of_the_Internet

- **Internet access (1989)**

Dial-up Internet has been around since the 1980s via public providers such as NSFNET-linked universities. The BBC established Internet access via Brunel University in the United Kingdom in 1989.

https://en.wikipedia.org/wiki/Dial-up_Internet_access

## Cryptography
**[`^        back to top        ^`](#)**

- **Age of RSA - RSA Patent granted (1983)**

https://en.wikipedia.org/wiki/RSA_(cryptosystem)

- **X.509 (1988)** 

In cryptography, X.509 is an International Telecommunication Union (ITU) standard defining the format of public key certificates.[1] X.509 certificates are used in many Internet protocols, including TLS/SSL, which is the basis for HTTPS,[2] the secure protocol for browsing the web. They are also used in offline applications, like electronic signatures.

https://en.wikipedia.org/wiki/X.509
## Computers
**[`^        back to top        ^`](#)**
### Form factor
**[`^        back to top        ^`](#)**
### OS
**[`^        back to top        ^`](#)**

- **IBM DOS operating system (1981) - IBM / Microsoft**

IBM initially announced intent to support multiple operating systems: CP/M-86, UCSD p-System,[62] and an in-house product called IBM PC DOS, developed by Microsoft.[63][8] In practice, IBM's expectation and intent was for the market to primarily use PC DOS,[64] CP/M-86 was not available for six months after the PC's release[65] and received extremely few orders once it was,[66] and p-System was also not available at release. PC DOS rapidly established itself as the standard OS for the PC and remained the standard for over a decade, with a variant being sold by Microsoft themselves as MS-DOS.

https://en.wikipedia.org/wiki/IBM_Personal_Computer

https://en.wikipedia.org/wiki/IBM_PC_DOS

- **Classic MacOS (1984)**

The "classic" Mac OS is the original Macintosh operating system that was introduced in 1984 alongside the first Macintosh and remained in primary use on Macs until the introduction of Mac OS X in 2001.

https://en.wikipedia.org/wiki/Macintosh_operating_systems

- **Windows 2.0 (1987) - Microsoft**

Windows 2.0 is a major release of Microsoft Windows, a family of graphical operating systems for personal computers developed by Microsoft. It was released to manufacturing on December 9, 1987, as a successor to Windows 1.0.

The product includes two different variants, a base edition for 8086 real mode, and Windows/386, an enhanced edition for i386 protected mode. Windows 2.0 differs from its predecessor by allowing users to overlap and resize application windows, while the operating environment also introduced desktop icons, keyboard shortcuts, and support for 16-color VGA graphics. It also **introduced Microsoft Word and Excel**, and integrated the Control Panel, while the developer support increased substantially.

Noted as an improvement of its predecessor, Microsoft Windows gained more sales and popularity after the release of the operating environment, although it is also considered to be the incarnation that remained a work in progress. Due to the introduction of overlapping windows, Apple Inc. had filed a lawsuit against Microsoft in March 1988 after accusing them of violating copyrights Apple held, although in the end, the judge ruled in favor of Microsoft. The operating environment was succeeded by Windows 2.1 in May 1988, while Microsoft ended its support on December 31, 2001.

https://en.wikipedia.org/wiki/Windows_2.0x

**Dynamic Data Exchange** was first introduced in 1987 with the release of Windows 2.0 as a method of interprocess communication so that one program could communicate with or control another program, somewhat like Sun's RPC (Remote Procedure Call).[1] At the time, the only method for communication between the operating system and client applications was the "Windows Messaging Layer." DDE extended this protocol to allow peer-to-peer communication among client applications, via message broadcasts.

https://en.wikipedia.org/wiki/Dynamic_Data_Exchange

### Peripherals
**[`^        back to top        ^`](#)**

- **Laser printers to mass markets based on Canon CX engine (1980s) - HP LaserJet, Apple LaserWriter**

*1981: The first small personal computer designed for office use, the Xerox Star 8010, reached market. The system used a desktop metaphor that was unsurpassed in commercial sales, until the Apple Macintosh. Although it was innovative, the Star workstation was a prohibitively-expensive (US$17,000) system, affordable only to a fraction of the businesses and institutions at which it was targeted.[9]

**1984: The first laser printer intended for mass-market sales, the HP LaserJet**, was released; it used the Canon CX engine, controlled by HP software. The LaserJet was quickly followed by printers from Brother Industries, IBM, and others. First-generation machines had large photosensitive drums, of circumference greater than the loaded paper's length. Once faster-recovery coatings were developed, the drums could touch the paper multiple times in a pass, and therefore be smaller in diameter.

**1985: Apple introduced the LaserWriter (also based on the Canon CX engine)**,[10] but used the newly released PostScript page-description language (up until this point, each manufacturer used its own proprietary page-description language, making the supporting software complex and expensive). PostScript allowed the use of text, fonts, graphics, images, and color largely independent of the printer's brand or resolution.
PageMaker, developed by Aldus for the Macintosh and LaserWriter, was also released in 1985 and the combination became very popular for desktop publishing.[5][6]

https://en.wikipedia.org/wiki/Laser_printing

### Storage
**[`^        back to top        ^`](#)**

- **IBM PC/XT - Internal HDD - 10 MB - (1983) - IBM**

Most HDDs in the early 1980s were sold to PC end users as an external, add-on subsystem. The subsystem was not sold under the drive manufacturer's name but under the subsystem manufacturer's name such as Corvus Systems and Tallgrass Technologies, or under the PC system manufacturer's name such as the Apple ProFile. The IBM PC/XT in 1983 included an internal 10 MB HDD, and soon thereafter internal HDDs proliferated on personal computers.

External HDDs remained popular for much longer on the Apple Macintosh. Many Macintosh computers made between 1986 and 1998 featured a SCSI port on the back, making external expansion simple. Older compact Macintosh computers did not have user-accessible hard drive bays (indeed, the Macintosh 128K, Macintosh 512K, and Macintosh Plus did not feature a hard drive bay at all), so on those models external SCSI disks were the only reasonable option for expanding upon any internal storage.

https://en.wikipedia.org/wiki/Hard_disk_drive

- **Apple UniDisk 3.5 - 3"1/2 Floppy Disk (1985) - Apple**

In September 1985, Apple released its first 3+1⁄2-inch drive (A2M2053) for the Apple II series utilizing Sony's new 800-kilobyte double-sided drive mechanism, which would not be released for the Macintosh until four months later. The Apple UniDisk 3.5 drive contained additional circuitry making it an "intelligent" or "smart" drive; this made it incompatible with the Macintosh, despite having the identical mechanism that was to be later used in the Macintosh drive. 

https://en.wikipedia.org/wiki/Macintosh_External_Disk_Drive

- **Apple 800K External Drive - External Drive (1986) - Apple**

In January 1986, Apple introduced the Macintosh Plus which had a Sony double-sided 800-kilobyte capacity disk drive, and used the new HFS disk format providing directories and sub-directories. This drive was fitted into an external case as the Macintosh 800K External Drive (M0131), which was slimmer than the earlier 400-kilobyte drive.

https://en.wikipedia.org/wiki/Macintosh_External_Disk_Drive


### Uses
**[`^        back to top        ^`](#)**

#### Servers

- **Bind  (1984) : First DNS server**. Still widely in use (BIND9) 

https://en.wikipedia.org/wiki/Domain_Name_System

- **BBS - Bulletin Board System (1973-1995)**

A bulletin board system or BBS (also called Computer Bulletin Board Service, CBBS[1]) is a computer server running software that allows users to connect to the system using a terminal program. Once logged in, the user can perform functions such as uploading and downloading software and data, reading news and bulletins, and exchanging messages with other users through public message boards and sometimes via direct chatting. In the early 1980s, message networks such as FidoNet were developed to provide services such as NetMail, which is similar to internet-based email.[2]

Many BBSes also offer online games in which users can compete with each other. BBSes with multiple phone lines often provide chat rooms, allowing users to interact with each other. Bulletin board systems were in many ways a precursor to the modern form of the World Wide Web, social networks, and other aspects of the Internet. Low-cost, high-performance asynchronous modems drove the use of online services and BBSes through the early 1990s. InfoWorld estimated that there were 60,000 BBSes serving 17 million users in the United States alone in 1994, a collective market much larger than major online services such as CompuServe.

The introduction of inexpensive dial-up internet service and the Mosaic web browser offered ease of use and global access that BBS and online systems did not provide, and led to a rapid crash in the market starting in late 1994-early 1995. Over the next year, many of the leading BBS software providers went bankrupt and tens of thousands of BBSes disappeared. Today, BBSing survives largely as a nostalgic hobby in most parts of the world, but it is still an extremely popular form of communication for Taiwanese youth (see PTT Bulletin Board System).[3] Most surviving BBSes are accessible over Telnet and typically offer free email accounts, FTP services, IRC and all the protocols commonly used on the Internet. Some offer access through packet switched networks or packet radio connections.[1]

https://en.wikipedia.org/wiki/Bulletin_board_system




#### CGI

- **Pixar early history**

In 1982, the Pixar team began working on special-effects film sequences with Industrial Light & Magic. After years of research, and key milestones such as the Genesis Effect in Star Trek II: The Wrath of Khan and the Stained Glass Knight in Young Sherlock Holmes,[14] the group, which then numbered 40 individuals, was spun out as a corporation in February 1986 by Catmull and Smith. Among the 38 remaining employees, there were also Malcolm Blanchard, David DiFrancesco, Ralph Guggenheim, and Bill Reeves, who had been part of the team since the days of NYIT. Tom Duff, also an NYIT member, would later join Pixar after its formation.[2] With Lucas's 1983 divorce, which coincided with the sudden dropoff in revenues from Star Wars licenses following the release of Return of the Jedi, they knew he would most likely sell the whole Graphics Group. Worried that the employees would be lost to them if that happened, which would prevent the creation of the first computer-animated movie, they concluded that the best way to keep the team together was to turn the group into an independent company. But Moore's Law also suggested that sufficient computing power for the first film was still some years away, and they needed to focus on a proper product until then. Eventually, they decided they should be a hardware company in the meantime, with their Pixar Image Computer as the core product, a system primarily sold to governmental, scientific, and medical markets.[2][10][19] They also used SGI computers.[20]

In 1983, Nolan Bushnell founded a new computer-guided animation studio called Kadabrascope as a subsidiary of his Chuck E. Cheese's Pizza Time Theatres company (PTT), which was founded in 1977. Only one major project was made out of the new studio, an animated Christmas special for NBC starring Chuck E. Cheese and other PTT mascots; known as "Chuck E. Cheese: The Christmas That Almost Wasn't". The animation movement would be made using tweening instead of traditional cel animation. After the video game crash of 1983, Bushnell started selling some subsidiaries of PTT to keep the business afloat. Sente Technologies (another division, was founded to have games distributed in PTT stores) was sold to Bally Games and Kadabrascope was sold to Lucasfilm. The Kadabrascope assets were combined with the Computer Division of Lucasfilm.[21] Coincidentally, one of Steve Jobs's first jobs was under Bushnell in 1973 as a technician at his other company Atari, which Bushnell sold to Warner Communications in 1976 to focus on PTT.[22] PTT would later go bankrupt in 1984 and be acquired by ShowBiz Pizza Place.[23]

In 1986, the newly independent Pixar was headed by President Edwin Catmull and Executive Vice President Alvy Ray Smith. Lucas's search for investors led to an offer from Steve Jobs, which Lucas initially found too low. He eventually accepted after determining it impossible to find other investors. At that point, Smith and Catmull had been declined 45 times, and 35 venture capitalists and ten large corporations had declined.[24] Jobs, who had been edged out of Apple in 1985,[2] was now founder and CEO of the new computer company NeXT. On February 3, 1986, he paid $5 million of his own money to George Lucas for technology rights and invested $5 million cash as capital into the company, joining the board of directors as chairman.[2][25]

In 1985, while still at Lucasfilm, they had made a deal with the Japanese publisher Shogakukan to make a computer-animated movie called Monkey, based on the Monkey King. The project continued sometime after they became a separate company in 1986, but it became clear that the technology was not sufficiently advanced. The computers were not powerful enough and the budget would be too high. So they focused on the computer hardware business for years until a computer-animated feature became feasible according to Moore's law.[26][27]

At the time, Walt Disney Studios was interested and eventually bought and used the Pixar Image Computer and custom software written by Pixar as part of its Computer Animation Production System (CAPS) project, to migrate the laborious ink and paint part of the 2D animation process to a more automated method. The company's first feature film to be released using this new animation method was The Rescuers Down Under (1990).[28][29]

In a bid to drive sales of the system and increase the company's capital, Jobs suggested releasing the product to the mainstream market. Pixar employee John Lasseter, who had long been working on not-for-profit short demonstration animations, such as Luxo Jr. (1986) to show off the device's capabilities, premiered his creations to great fanfare at SIGGRAPH, the computer graphics industry's largest convention.[30]

However, the Image Computer had inadequate sales[30] which threatened to end the company as financial losses grew. Jobs increased investment in exchange for an increased stake, reducing the proportion of management and employee ownership until eventually, his total investment of $50 million gave him control of the entire company. In 1989, Lasseter's growing animation department, originally composed of just four people (Lasseter, Bill Reeves, Eben Ostby, and Sam Leffler), was turned into a division that produced computer-animated commercials for outside companies.

https://en.wikipedia.org/wiki/Pixar#Early_history

- **Tin toy, 1989 Academy Award for Best Animated Short Film, first for a computer-generated film (1988) - Pixar**

At Pixar, Lasseter created short, computer-animated films to show off the Pixar Image Computer's capabilities. In 1988, Lasseter produced the short film **Tin Toy* told from the perspective of a toy, referencing Lasseter's love of classic toys. It **won the 1989 Academy Award for Best Animated Short Film, the first computer-generated film to do so.** [9]

Tin Toy gained Disney's attention, and the new team at The Walt Disney Company, CEO Michael Eisner and chairman Jeffrey Katzenberg in the film division, sought to get Lasseter to come back.[9] Lasseter, grateful for Jobs' faith in him, felt compelled to stay with Pixar, telling co-founder Ed Catmull, "I can go to Disney and be a director, or I can stay here and make history."[9] Katzenberg realized he could not lure Lasseter back to Disney and therefore set plans into motion to ink a production deal with Pixar to produce a film. [9] Disney had always made all their movies in-house and refused to change this. But when Tim Burton, who used to work at Disney, wanted to buy back the rights to The Nightmare Before Christmas, Disney struck a deal allowing him to make it as a Disney film outside the studio. This allowed Pixar to make their movies outside Disney.[10]

https://en.wikipedia.org/wiki/Toy_Story

## Consumer Electronics
**[`^        back to top        ^`](#)**
### Gadgets
**[`^        back to top        ^`](#)**

- **Symbolic computing and graphing calculators - HP, Casio**

The first calculator capable of symbolic computing was the HP-28C, released in 1987. It could, for example, solve quadratic equations symbolically. 

The first graphing calculator was the Casio fx-7000G released in 1985.

https://en.wikipedia.org/wiki/Calculator


### Multimedia
**[`^        back to top        ^`](#)**

- **Starcom Cable TV Converter - infrared LED remote controls (1980) - Jerrold Electronics / General Instrument**

In 1980, the most popular remote control was the Starcom Cable TV Converter[25] (from Jerrold Electronics, a division of General Instrument)[13] which used 40-kHz sound to change channels. Then, a Canadian company, Viewstar, Inc., was formed by engineer Paul Hrivnak and started producing a cable TV converter with an infrared remote control. The product was sold through Philips for approximately $190 CAD. The Viewstar converter was an immediate success, the millionth converter being sold on March 21, 1985, with 1.6 million sold by 1989.[26][27]

https://en.wikipedia.org/wiki/Remote_control#Infrared,_line_of_sight_and_operating_angle

- **Pocket LCD TVs (1982) - Seiko Epson**

The first color LCD televisions were developed as handheld televisions in Japan. In 1980, Hattori Seiko's R&D group began development on color LCD pocket televisions.[72] In 1982, Seiko Epson released the first LCD television, the Epson TV Watch, a wristwatch equipped with a small active-matrix LCD television.[73][74] Sharp Corporation introduced dot matrix TN-LCD in 1983.[62] In 1984, Epson released the ET-10, the first full-color, pocket LCD television.[75] The same year, Citizen Watch,[76] introduced the Citizen Pocket TV,[72] a 2.7-inch color LCD TV,[76] with the first commercial TFT LCD.[72] In 1988, Sharp demonstrated a 14-inch, active-matrix, full-color, full-motion TFT-LCD. This led to Japan launching an LCD industry, which developed large-size LCDs, including TFT computer monitors and LCD televisions.[77] Epson developed the 3LCD projection technology in the 1980s, and licensed it for use in projectors in 1988.[78] Epson's VPJ-700, released in January 1989, was the world's first compact, full-color LCD projector.[74]

https://en.wikipedia.org/wiki/Liquid-crystal_display

By 1982, pocket LCD TVs based on LCD technology were developed in Japan.[15] The 2.1-inch Epson ET-10[16] Epson Elf was the first color LCD pocket TV, released in 1984.[17] 

https://en.wikipedia.org/wiki/Flat-panel_display

- **Sony CDP-101 - Audio compact disk player (1982) - Sony**

Compact Disc Digital Audio (CDDA or CD-DA), also known as Digital Audio Compact Disc or simply as Audio CD, is the standard format for audio compact discs. The standard is defined in the Red Book, one of a series of Rainbow Books (named for their binding colors) that contain the technical specifications for all CD formats.

The first commercially available audio CD player, the Sony CDP-101, was released October 1982 in Japan. The format gained worldwide acceptance in 1983–84, selling more than a million CD players in those two years, to play 22.5 million discs.[1]

Beginning in the 2000s, CDs were increasingly being replaced by other forms of digital storage and distribution, with the result that by 2010 the number of audio CDs being sold in the U.S. had dropped about 50% from their peak; however, they remained one of the primary distribution methods for the music industry.

https://en.wikipedia.org/wiki/Compact_Disc_Digital_Audio

### Screens
**[`^        back to top        ^`](#)**

- **Orange monochrome plasma displays for laptops (1983) - IBM**

In 1983, IBM introduced a 19-inch (48 cm) orange-on-black monochrome display (Model 3290 Information Panel) which was able to show up to four simultaneous IBM 3270 terminal sessions. By the end of the decade, orange monochrome plasma displays were used in a number of high-end AC-powered portable computers, such as the Compaq Portable 386 (1987) and the IBM P75 (1990). Plasma displays had a better contrast ratio, viewability angle, and less motion blur than the LCDs that were available at the time, and were used until the introduction of active-matrix color LCD displays in 1992.[59]

Due to heavy competition from monochrome LCDs used in laptops and the high costs of plasma display technology, in 1987 IBM planned to shut down its factory in Kingston, New York, the largest plasma plant in the world, in favor of manufacturing mainframe computers, which would have left development to Japanese companies.[60] Dr. Larry F. Weber, a University of Illinois ECE PhD (in plasma display research) and staff scientist working at CERL (home of the PLATO System), co-founded Plasmaco with Stephen Globus and IBM plant manager James Kehoe, and bought the plant from IBM for US$50,000. Weber stayed in Urbana as CTO until 1990, then moved to upstate New York to work at Plasmaco.

https://en.wikipedia.org/wiki/Plasma_display

- **Flat screen CRT TV (1987) - Zenith**

In 1987, flat-screen CRTs were developed by Zenith for computer monitors, reducing reflections and helping increase image contrast and brightness.[63][64] Such CRTs were expensive, which limited their use to computer monitors.[65] Attempts were made to produce flat-screen CRTs using inexpensive and widely available float glass.[66]

https://en.wikipedia.org/wiki/Cathode-ray_tube

- **SVGA Graphics Cards (1988)**

In the late 1980s, after the release of IBM's VGA, third-party manufacturers began making graphics cards based on its specifications with extended capabilities. As these cards grew in popularity they began to be referred to as "Super VGA."
This term was not an official standard, but a shorthand for enhanced VGA cards which had become common by 1988.[1] One card that explicitly used the term was **Genoa's SuperVGA HiRes.**[3]
Super VGA cards broke compatibility with the IBM VGA standard, requiring software developers to provide specific display drivers and implementations for each card their software could operate on.

https://en.wikipedia.org/wiki/Super_VGA


### Broadcast
**[`^        back to top        ^`](#)**

- **TVRO/C-band satellite era (1980–1986)**

On 26 April 1982, the first satellite channel in the UK, Satellite Television Ltd. (later Sky One), was launched.[68] Its signals were transmitted from the ESA's Orbital Test Satellites
Originally, all channels were broadcast in the clear (ITC) because the equipment necessary to receive the programming was too expensive for consumers. With the growing number of TVRO systems, the program providers and broadcasters had to scramble their signal and develop subscription systems.
In January 1986, HBO began using the now-obsolete VideoCipher II system to encrypt their channels.
On 11 December 1988 Luxembourg launched Astra 1A, the first satellite to provide medium power satellite coverage to Western Europe.[75] This was one of the first medium-powered satellites, transmitting signals in Ku band and allowing reception with small(90 cm) dishes for the first time ever.

https://en.wikipedia.org/wiki/Satellite_television

- **HD-MAC - last analog HDTV system (1986)**

In 1986, the European Community proposed HD-MAC, an analog HDTV system with 1,152 lines. A public demonstration took place for the 1992 Summer Olympics in Barcelona. However HD-MAC was scrapped in 1993 and the Digital Video Broadcasting (DVB) project was formed, which would foresee development of a digital HDTV standard.[7]

https://en.wikipedia.org/wiki/High-definition_television

### Video games
**[`^        back to top        ^`](#)**

- **Golden age : Move of arcade games to microprocessors (1978-1983)**

As technology moved from transistor-transistor logic (TTL) integrated circuits to microprocessors, a new wave of arcade video games arose, starting with Taito's **Space Invaders** in 1978 and leading to a golden age of arcade video games that included **Pac-Man** (Namco, 1980), **Missile Command** (Atari, 1980), and **Donkey Kong (Nintendo, 1981)**. The golden age waned in 1983 due to an excess number of arcade games, the growing draw of home video game consoles and computers, and a moral panic on the impact of arcade video games on youth.[22][57] The arcade industry was also partially impacted by the video game crash of 1983.

https://en.wikipedia.org/wiki/Arcade_game#History

Space Invaders led off what is considered to be the golden age of arcade games which lasted from 1978 to 1982. Several influential and best-selling arcade games were released during this period from Atari, Namco, Taito, Williams, and Nintendo, including Asteroids (1979), Galaxian (1979), Defender (1980), Missile Command (1980), Tempest (1981), and Galaga (1981). Pac-Man, released in 1980, became a popular culture icon, and a new wave of games appeared that focused on identifiable characters and alternate mechanics such as navigating a maze or traversing a series of platforms. Aside from Pac-Man and its sequel, Ms. Pac-Man (1982), the most popular games in this vein during the golden age were Donkey Kong (1981) and Q*bert (1982).[14] Games like Pac-Man, Donkey Kong and Q*bert also introduced the **concept of narratives and characters to video games**, which led companies to adopt these later as mascots for marketing purposes.[17][18]

https://en.wikipedia.org/wiki/History_of_video_games

- **Second generation consoles, shift to Japan and new gaming industry model**

At the start of the second generation, all games were developed and produced in-house. Four former Atari programmers, having left from conflicts in management style after Atari was purchased by Warner Communications in 1976, established Activision in 1979 to develop their own VCS games, which included Kaboom! and Pitfall!. Atari sued Activision on the basis of theft of trade secrets and violation of their non-disclosure agreements, but the two companies settled out of court in 1982, with Activision agreeing to pay a small license fee to Atari for every game of theirs their sold. This established Activision as the first third-party developer for a console. This also established a working model for licensing other third-party developers, which several companies followed in Activision's wake, partially contributing to the video game crash of 1983 due to oversaturation.[19]

As the second generation of consoles coincided with the golden age of arcade video games, a common trend that emerged during the generation was licensing arcade video games for consoles. Many of them were increasingly licensed from Japanese video game companies by 1980, which led to Jonathan Greenberg of Forbes predicting in early 1981 that Japanese companies would eventually dominate the North American video game industry later in the decade.[20]

At this stage, both consoles and game cartridges were intended to be sold for profit by manufacturers. However, by segregating games from the console, this approach established the use of the razorblade business model in future console generations, where consoles would be sold at or below cost while licensing fees from third-party games would bring in profits.[21][22]

https://en.wikipedia.org/wiki/Second_generation_of_video_game_consoles

- **8 bits game consoles - Third generation video games consoles (1983)**

In the history of video games, the third generation of game consoles, commonly referred to as the 8-bit era, began on July 15, 1983 with the Japanese release of two systems: Nintendo's Family Computer (commonly abbreviated to **Famicom**) and **Sega's SG-1000**.[1][2] When the Famicom was released outside of Japan it was remodelled and marketed as the **Nintendo Entertainment System (NES)**. This generation marked the end of the video game crash of 1983, and a shift in the dominance of home video game manufacturers from the United States to Japan.[3] Handheld consoles were not a major part of this generation, although the Game & Watch line from Nintendo (which started in 1980) and the Milton Bradley Microvision (which came out in 1979) were sold at the time. However, both are considered second generation hardware.
The best-selling console of this generation was the **NES/Famicom** from Nintendo, followed by the **Sega Master System** (the improved successor to the SG-1000), and the **Atari 7800**. Although the previous generation of consoles had also used 8-bit processors, it was at the end of the third generation that home consoles were first labeled and marketed by their "bits". 

https://en.wikipedia.org/wiki/Third_generation_of_video_game_consoles

- **16 bits game consoles - Fourth generation video games consoles (1987)**

In the history of video games, the fourth generation of game consoles, more commonly referred to as the 16-bit era, began on October 30, 1987, with the Japanese release of **NEC Home Electronics**' PC Engine (known as the TurboGrafx-16 in North America).
Although NEC released the first console of this era, sales were mostly dominated by the rivalry between Sega and Nintendo across most markets: the Sega Mega Drive (named the Sega Genesis in North America) and the **Super Nintendo Entertainment System **(SNES; the Super Famicom in Japan). Cartridge-based handheld consoles became prominent during this time, dominated by the **Nintendo Game Boy** (1989). Color handhelds were also released, including the Atari Lynx (1989) and Sega Game Gear (1990).

The first handheld game console released in the fourth generation was the Game Boy, on April 21, 1989. It went on to dominate handheld sales by an extremely large margin, despite featuring a 8-bit microprocessor and a low-contrast, unlit monochrome screen while all three of its leading competitors had color. Three major franchises made their debut on the Game Boy: Tetris, the Game Boy's killer application; Pokémon; and Kirby. With some design (Game Boy Pocket, Game Boy Light) and hardware (Game Boy Color) changes, it continued in production in some form until 2008, enjoying a better than 18-year run.
https://en.wikipedia.org/wiki/Fourth_generation_of_video_game_consoles

- **Nintendo Gameboy (1989) - Nintendo**
Cartridge-based handheld consoles became prominent during this time, dominated by the Nintendo Game Boy (1989).
Color handhelds were also released, including the Atari Lynx (1989) and Sega Game Gear (1990).
https://en.wikipedia.org/wiki/Fourth_generation_of_video_game_consoles

- **Recovery and decline of the arcade market (1986-1989)**

The arcade market had recovered by 1986, with the help of software conversion kits, the arrival of popular **beat 'em up games** (such as Kung-Fu Master and Renegade), and advanced motion simulator games (such as Sega's "taikan" games including Hang-On, Space Harrier and Out Run). However, the growth of home video game systems such as the Nintendo Entertainment System led to another brief arcade decline towards the end of the 1980s

https://en.wikipedia.org/wiki/Arcade_game#History

## Standards and protocols
**[`^        back to top        ^`](#)**

### Physical layer
- **G.652 (1984)** : 

international standard that describes the geometrical, mechanical, and transmission attributes of a **single-mode optical fibre and cable**, developed by the Standardization Sector of the International Telecommunication Union (ITU-T) that specifies the most popular type of single-mode optical fiber (SMF) cable

https://en.wikipedia.org/wiki/G.652

- **IEEE 802.3 (1983) - 10BASE5**
IEEE 802.3 is a working group and a collection of Institute of Electrical and Electronics Engineers (IEEE) standards produced by the working group defining the physical layer and data link layer's media access control (MAC) of wired Ethernet. This is generally a local area network (LAN) technology with some wide area network (WAN) applications. Physical connections are made between nodes and/or infrastructure devices (hubs, switches, routers) by various types of copper or fiber cable.

802.3 is a technology that supports the IEEE 802.1 network architecture.

802.3 also defines LAN access method using CSMA/CD.

IEEE 802.3 standard	1983	10BASE5 10 Mbit/s (1.25 MB/s) over thick coax. Same as Ethernet II (above) except Type field is replaced by Length, and an 802.2 LLC header follows the 802.3 header. Based on the CSMA/CD Process.

https://en.wikipedia.org/wiki/IEEE_802.3

### Link layer

- **802.3d	-	Fiber-optic inter-repeater link, replaced by 10BASE-FL in 1993 (1987)**

10BASE-F, or sometimes 10BASE-FX, is a generic term for the family of 10 Mbit/s Ethernet standards using fiber optic cable. In 10BASE-F, the 10 represents a maximum throughput of 10 Mbit/s, BASE indicates its use of baseband transmission, and F indicates that it relies on medium of fiber-optic cable. The technical standard requires two strands of 62.5/125 µm multimode fiber. 

Fiber-optic inter-repeater link (FOIRL) is a specification of Ethernet over optical fiber. It was especially designed as a back-to-back transport between repeater hubs as to decrease latency and collision detection time, thus increasing the possible network radius. It was replaced by 10BASE-FL.[1]

https://en.wikipedia.org/wiki/Classic_Ethernet#FOIRL

- **ARP - Address Resolution Protocol (1982)**

communication protocol used for discovering the link layer address, such as a MAC address, associated with a given internet layer address, typically an IPv4 address.  Essential to the internet.

https://en.wikipedia.org/wiki/Address_Resolution_Protocol

### Network layer
- **IPv4 - Internet Protocol version 4 (1981)**

the fourth version of the Internet Protocol (IP). Described in IETF publication RFC 791 (September 1981). First version deployed for production on SATNET in 1982 and on the ARPANET in January 1983. Essential to networking and the internet. 

https://en.wikipedia.org/wiki/IPv4

- **BGP - Border Gateway Protocol (1989)** :  exterior gateway protocol designed to exchange routing and reachability information among autonomous systems (AS) on the Internet. Essential to the internet. https://en.wikipedia.org/wiki/Border_Gateway_Protocol

- **IGMP - Internet Group Management Protocol (1989)** : a communications protocol used by hosts and adjacent routers on IPv4 networks to establish multicast group memberships. IGMP is an integral part of IP multicast and allows the network to direct multicast transmissions only to hosts that have requested them.
IGMP can be used for one-to-many networking applications such as online streaming video and gaming, and allows more efficient use of resources when supporting these types of applications.
https://en.wikipedia.org/wiki/Internet_Group_Management_Protocol

### Transport layer
- **UDP - User_Datagram_Protocol (1980)** : Simple message-oriented transport layer protocol (reception is not certain).  Essential to the internet. 
https://en.wikipedia.org/wiki/User_Datagram_Protocol 

### Session layer

- **NetBIOS (1983-1986)**

NetBIOS (/ˈnɛtbaɪɒs/) is an acronym for Network Basic Input/Output System. It provides services related to the session layer of the OSI model allowing applications on separate computers to communicate over a local area network. As strictly an API, NetBIOS is not a networking protocol. Older operating systems[clarification needed] ran NetBIOS over IEEE 802.2 and IPX/SPX using the NetBIOS Frames (NBF) and NetBIOS over IPX/SPX (NBX) protocols, respectively. In modern networks, NetBIOS normally runs over TCP/IP via the NetBIOS over TCP/IP (NBT) protocol. This results in each computer in the network having both an IP address and a NetBIOS name corresponding to a (possibly different) host name. NetBIOS is also used for identifying system names in TCP/IP (Windows). Simply saying, it is a protocol that allows communication of files and printers through the Session Layer of the OSI Model in a LAN.[clarification needed]

NetBIOS is a non-routable OSI Session Layer 5 Protocol and a service that allows applications on computers to communicate with one another over a local area network (LAN). NetBIOS was developed in 1983 by Sytek Inc. as an API for software communication over IBM PC Network LAN technology.[1] On IBM PC Network, as an API alone, NetBIOS relied on proprietary Sytek networking protocols for communication over the wire.[citation needed] Despite supporting a maximum of 80 PCs in a LAN, NetBIOS became an industry standard.[1]

In 1985, IBM went forward with the Token Ring network scheme and a NetBIOS emulator was produced to allow NetBIOS-aware applications from the PC-Network era to work over this new design. This emulator, named NetBIOS Extended User Interface (NetBEUI), expanded the base NetBIOS API with, among other things, the ability to deal with the greater node capacity of Token Ring. A new networking protocol, NBF, was simultaneously produced to allow NetBEUI (NetBIOS) to provide its services over Token Ring – specifically, at the IEEE 802.2 Logical Link Control layer.

In 1985, Microsoft created a NetBIOS implementation for its MS-Net networking technology. As in the case of IBM's Token Ring, the services of Microsoft's NetBIOS implementation were provided over the IEEE 802.2 Logical Link Control layer by the NBF protocol.[citation needed] Until Microsoft adopted Domain Name System (DNS) resolution of hostnames, Microsoft operating systems used NetBIOS to resolve names in Windows client-server networks.[1]

In 1986, Novell released Advanced Novell NetWare 2.0 featuring the company's own NetBIOS emulator. Its services were encapsulated within NetWare's IPX/SPX protocol using the NetBIOS over IPX/SPX (NBX) protocol.

In 1987, a method of encapsulating NetBIOS in TCP and UDP packets, NetBIOS over TCP/IP (NBT), was published. It was described in RFC 1001 ("Protocol Standard for a NetBIOS Service on a TCP/UDP Transport: Concepts and Methods") and RFC 1002 ("Protocol Standard for a NetBIOS Service on a TCP/UDP Transport: Detailed Specifications"). The NBT protocol was developed in order to "allow an implementation [of NetBIOS applications] to be built on virtually any type of system where the TCP/IP protocol suite is available," and to "allow NetBIOS interoperation in the Internet."

After the PS/2 computer hit the market in 1987, IBM released the PC LAN Support Program, which included a driver for NetBIOS.

Since its original publishing in a technical reference book from IBM, the NetBIOS API specification has become a de facto standard.

NetBIOS provides three distinct services:
- Name service (NetBIOS-NS) for name registration and resolution.
- Datagram distribution service (NetBIOS-DGM) for connectionless communication.
- Session service (NetBIOS-SSN) for connection-oriented communication.

https://en.wikipedia.org/wiki/NetBIOS

### Application layer
- **TFTP - Trivial File Transfer Protoco (1981)**

a simple lockstep File Transfer Protocol which allows a client to get a file from or put a file onto a remote host. One of its primary uses is in the early stages of nodes booting from a local area network. 
Insecure (no login or access control mechanism) but still in use. was mostly superseded by FTP. 

https://en.wikipedia.org/wiki/Trivial_File_Transfer_Protocol

- **NICNAME/WHOIS - WHOIS (1982)** 
 
Who is responsible for the domain, IP. Essential to the internet. 
 
https://en.wikipedia.org/wiki/WHOIS
 
- **NTP - Network_Time_Protocol (1985)** 

used for network time coordination between computers. Essential to networking.

https://en.wikipedia.org/wiki/Network_Time_Protocol

- **DNS - domain name server (1987)**

hierarchical and decentralized naming system used to identify computers reachable through the Internet or other Internet Protocol (IP) networks. The resource records contained in the DNS associate domain names with other forms of information. These are most commonly used to map human-friendly domain names to the numerical IP addresses computers.
Essential to the internet and networking

https://en.wikipedia.org/wiki/Domain_Name_System

- **SNMP - Simple Network Management Protocol (1988)**

protocol for collecting and organizing information about managed devices on IP networks and for modifying that information to change device behaviour. Devices that typically support SNMP include cable modems, routers, switches, servers, workstations, printers, and more. Widely used in network management for network monitoring.

https://en.wikipedia.org/wiki/Simple_Network_Management_Protocol

### Data transmission

#### Text transmission
- **SMTP - Email sending protocol (1980)**.

Essential to Emails. 
https://en.wikipedia.org/wiki/Simple_Mail_Transfer_Protocol

- **ASN.1 - Abstract Syntax Notation One (1984)**

A standard interface description language for defining data structures that can be serialized and deserialized in a cross-platform way. It is broadly used in telecommunications and computer networking, and especially in cryptography.[1]

https://en.wikipedia.org/wiki/ASN.1

- **POP1 - Post Office Protocol (1984)**

Email reception protocol. Essential to Emails (POP3). 

https://en.wikipedia.org/wiki/Post_Office_Protocol

- **RARP - Reverse Address Resolution Protocol (1984)**
 
for the configuration of simple devices, replaced by BOOTP 

https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol

- **X.400 (1984)**

a suite of ITU-T Recommendations that defines the ITU-T **Message Handling System (MHS)**. At one time, the designers of X.400 were expecting it to be the predominant form of email, but this role has been taken by the SMTP-based Internet e-mail.

https://en.wikipedia.org/wiki/X.400

- **IMAP2 : Internet Message Access Protocol (1988)** 

email synchronization protocol. does not delete automatically emails on the server. Essential to emails (IMAP4) 
https://en.wikipedia.org/wiki/Internet_Message_Access_Protocol

- **WWW (1989)**

Research at CERN in Switzerland by the British computer scientist Tim Berners-Lee in 1989–90 resulted in the World Wide Web, linking hypertext documents into an information system, accessible from any node on the network.

https://en.wikipedia.org/wiki/History_of_the_Internet

#### Images

- **BMP - Bitmap image file, GIF ancestor (1981) - IBM and Microsoft**

The BMP file format, also known as bitmap image file, device independent bitmap (DIB) file format and bitmap, is a raster graphics image file format used to store bitmap digital images, independently of the display device (such as a graphics adapter), especially on Microsoft Windows[2] and OS/2[3] operating systems.
The BMP file format is capable of storing two-dimensional digital images both monochrome and color, in various color depths, and optionally with data compression, alpha channels, and color profiles. The Windows Metafile (WMF) specification covers the BMP file format.[4]

https://en.wikipedia.org/wiki/BMP_file_format

Microsoft Corporation and IBM Corporation needed to record images in a format that their applications and operating systems could easily  render on low-end machines (Intel 80286).  The resulting "BMP" format contains a single raster graphic with basic header fields that can be
easily mapped (or "blitted") to locations in memory.  As computing moved from 16-bit to 32-bit, BMP evolved to contain 32-bit structures. 

https://datatracker.ietf.org/doc/html/rfc7903

- **ILBM - Interleaved Bitmap (1985) - Electronic Arts**

Interleaved Bitmap (ILBM) is an image file format conforming to the Interchange File Format (IFF) standard. The format originated on the Amiga platform, and on IBM-compatible systems, files in this format or the related PBM (Planar Bitmap) format are typically encountered in games from late 1980s and early 1990s that were either Amiga ports or had their graphical assets designed on Amiga machines.[citation needed]
A characteristic feature of the format is that it stores bitmaps in the form of interleaved bit planes, which gives the format its name; this reflects the way the Amiga graphics hardware natively reads graphics data from memory. A simple form of compression is supported to make ILBM files more compact.[4]
On the Amiga, these files are not associated with a particular file extension, though as they started being used on PC systems where extensions are systematically used, they employed a .lbm or occasionally a .bbm extension.

https://en.wikipedia.org/wiki/ILBM

- **GIF - Bitmap image file, PNG ancestor (1987)**

Graphics Interchange Format (GIF; /ɡɪf/ GHIF or /dʒɪf/ JIF , see pronunciation) is a bitmap image format that was developed by a team at the online services provider CompuServe led by American computer scientist Steve Wilhite and released on 15 June 1987

https://en.wikipedia.org/wiki/GIF

#### Audio and Video

- **IFF - Interchange File Format (1985) - Electronic Arts**

Interchange File Format (IFF), is a generic container file format originally introduced by the Electronic Arts company in 1985 (in cooperation with Commodore) in order to facilitate transfer of data between software produced by different companies.
IFF files do not have any standard extension. On many systems that generate IFF files, file extensions are not important (the OS stores file format metadata separately from the file name). An .iff extension is commonly used for ILBM format files, which use the IFF container format.

https://en.wikipedia.org/wiki/Interchange_File_Format

- **AIFF - Audio Interchange File Format (1988) - Apple**

Audio Interchange File Format (AIFF) is an audio file format standard used for storing sound data for personal computers and other electronic audio devices. The format was developed by Apple Inc. in 1988 based on Electronic Arts' Interchange File Format (IFF, widely used on Amiga systems) and is most commonly used on Apple Macintosh computer systems.

The audio data in most AIFF files is uncompressed pulse-code modulation (PCM). This type of AIFF file uses much more disk space than lossy formats like MP3—about 10 MB for one minute of stereo audio at a sample rate of 44.1 kHz and a bit depth of 16 bits. There is also a compressed variant of AIFF known as AIFF-C or AIFC, with various defined compression codecs.

https://en.wikipedia.org/wiki/Audio_Interchange_File_Format

#### Video transmission
- **H.120 (1984)** - **first digital video compression standard**. 

It was developed by COST 211 and published by the CCITT (now the ITU-T) in 1984, with a revision in 1988.

https://en.wikipedia.org/wiki/H.120

the first digital video coding standard. v1 (1984) featured conditional replenishment, differential PCM (DPCM), scalar quantization, variable-length coding and a switch for quincunx sampling. v2 (1988) added motion compensation and background prediction. This standard was little-used and no codecs exist.
https://en.wikipedia.org/wiki/Video_Coding_Experts_Group

- **H.261(1988) - first digital video compression standard of practical use**

H.261 is an ITU-T video compression standard, first ratified in November 1988.[1][2] It is the first member of the H.26x family of video coding standards in the domain of the ITU-T Study Group 16 Video Coding Experts Group (VCEG, then Specialists Group on Coding for Visual Telephony). It was the first video coding standard that was useful in practical terms.

H.261 was originally designed for transmission over ISDN lines on which data rates are multiples of 64 kbit/s. The coding algorithm was designed to be able to operate at video bit rates between 40 kbit/s and 2 Mbit/s. The standard supports two video frame sizes: CIF (352×288 luma with 176×144 chroma) and QCIF (176×144 with 88×72 chroma) using a 4:2:0 sampling scheme. It also has a backward-compatible trick for sending still images with 704×576 luma resolution and 352×288 chroma resolution (which was added in a later revision in 1993).

https://en.wikipedia.org/wiki/H.261

#### File storage

- **ISO 9660 - CD-ROM file system (1988)**

ISO 9660 (also known as ECMA-119) is a file system for optical disc media. Being sold by the International Organization for Standardization (ISO) the file system is considered an international technical standard. Since the specification is available for anybody to purchase,[1] implementations have been written for many operating systems.

https://en.wikipedia.org/wiki/ISO_9660

#### File compression

- **LZW Algorithm (1984)**

Lempel–Ziv–Welch (LZW) is a universal lossless data compression algorithm created by Abraham Lempel, Jacob Ziv, and Terry Welch. It was published by Welch in 1984 as an improved implementation of the LZ78 algorithm published by Lempel and Ziv in 1978. The algorithm is simple to implement and has the potential for very high throughput in hardware implementations.[1] It is the algorithm of the widely used Unix file compression utility compress and is used in the GIF image format.

https://en.wikipedia.org/wiki/Lempel%E2%80%93Ziv%E2%80%93Welch

- **ARC (1986)**

ARC is a lossless data compression and archival format by System Enhancement Associates (SEA). The file format and the program were both called ARC. The format is known as the subject of controversy in the 1980s, part of important debates over what would later be known as open formats.

ARC was extremely popular during the early days of the dial-up BBS. ARC was convenient as it combined the functions of the SQ program to compress files and the LU program to create .LBR archives of multiple files. The format was later replaced by the ZIP format, which offered better compression ratios and the ability to retain directory structures through the compression/decompression process.

In 1985, Thom Henderson of System Enhancement Associates wrote a program called ARC,[3] based on earlier programs such as ar, that not only grouped files into a single archive file but also compressed them to save disk space, a feature of great importance on early personal computers, where space was very limited and modem transmission speeds were very slow. The archive files produced by ARC had file names ending in ".ARC" and were thus sometimes called "arc files".

The source code for ARC was released by SEA in 1986 and subsequently ported to Unix and Atari ST in 1987 by Howard Chu. This more portable codebase was subsequently ported to other platforms, including VAX/VMS and IBM System/370 mainframes. Howard's work was also the first to disprove the prevalent belief that Lempel-Ziv encoded files could not be further compressed. Additional compression could be achieved by using Huffman coding on the LZW data, and Howard's version of ARC was the first program to demonstrate this property. This hybrid technique was later used in several other compression schemes by Phil Katz and others.

https://en.wikipedia.org/wiki/ARC_(file_format)

- **PKZIP (1986) - PKWARE**

PKZIP is a file archiving computer program, notable for introducing the popular ZIP file format. PKZIP was first introduced for MS-DOS on the IBM-PC compatible platform in 1989. Since then versions have been released for a number of other architectures and operating systems. PKZIP was originally written by Phil Katz and marketed by his company PKWARE, Inc starting in 1986. The company bears his initials: 'PK'.

https://en.wikipedia.org/wiki/PKZIP

- **ZIP (1989)**

ZIP is an archive file format that supports lossless data compression. A ZIP file may contain one or more files or directories that may have been compressed. The ZIP file format permits a number of compression algorithms, though DEFLATE is the most common. This format was originally created in 1989 and was first implemented in PKWARE, Inc.'s PKZIP utility,[2] as a replacement for the previous ARC compression format by Thom Henderson.

https://en.wikipedia.org/wiki/ZIP_(file_format)

#### Remote access
- **X Window System (X11, or simply X) (1984)**

A windowing system for bitmap displays, common on Unix-like operating systems. Originated as part of Project Athena at Massachusetts Institute of Technology (MIT). At version 11 since 1987.

https://en.wikipedia.org/wiki/X_Window_System

#### Instant messaging
- **IRC : Internet Relay Chat (1988)**

text-based chat system for instant messaging.

https://en.wikipedia.org/wiki/Internet_Relay_Chat
https://en.wikipedia.org/wiki/Instant_messaging

#### Machine to Machine

- **Modem speed protocols**

  * V.22 1200 bps; fallback to 600 bps ; QDPSK = DPSK (1980)
  * V.22bis 2400 bps; QAM (1984)
  * V.32 9600 bps; QAM (1984 but not widely used until years later)

https://tldp.org/HOWTO/Modem-HOWTO-29.html

- **SMB - Server Message Block - files and printers access across the network (1983)**

Server Message Block (SMB) is a communication protocol[1] originally developed in 1983 by Barry A. Feigenbaum at IBM[2] and intended to provide shared access to files and printers across nodes on a network of systems running IBM's OS/2. It also provides an authenticated inter-process communication (IPC) mechanism. In 1987, Microsoft and 3Com implemented SMB in LAN Manager for OS/2, at which time SMB used the NetBIOS service atop the NetBIOS Frames protocol as its underlying transport. Later, Microsoft implemented SMB in Windows NT 3.1 and has been updating it ever since, adapting it to work with newer underlying transports: TCP/IP and NetBT. SMB implementation consists of two vaguely named Windows services: "Server" (ID: LanmanServer) and "Workstation" (ID: LanmanWorkstation).[3] It uses NTLM or Kerberos protocols for user authentication.

https://en.wikipedia.org/wiki/Server_Message_Block

- **BOOTP - Bootstrap Protocol (1985)** 

introduced the concept of a relay agent, which allowed the forwarding of BOOTP packets across networks, allowing one central BOOTP server to serve hosts on many IP subnets, replaced by DHCP

https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol

#### Electronic Data Exchange

- **ODETTE/OFTP (1986+)**

The Odette File Transfer Protocol (OFTP) is a protocol created in 1986, used for EDI (Electronic Data Interchange) between two communications business partners. Its name comes from the Odette Organisation (the Organization for data exchange by teletransmission in Europe).

The ODETTE File Transfer Protocol (ODETTE-FTP) was defined in 1986 by working group four of the Organisation for Data Exchange by Tele-Transmission in Europe (ODETTE) to address the electronic data interchange (EDI) requirements of the European automotive industry. It was designed in the spirit of the Open System Interconnection (OSI) model utilising the Network Service provided by the CCITT X.25 recommendation.

OFTP 2 was written in 2007 by Data Interchange, as a specification for the secure transfer of business documents over the Internet, ISDN and X.25 networks. A description of OFTP 1.3 can be found in RFC 2204, whilst OFTP 2 is defined in RFC 5024.

OFTP 2 can work point-to-point or indirectly via a VAN (Value Added Network). A single OFTP 2 entity can make and receive calls, exchanging files in both directions.[1] This means that OFTP 2 can work in a push or pull mode, as opposed to AS2, which can only work in a push mode.[2]

OFTP 2 can encrypt and digitally sign message data, request signed receipts and also offers high levels of data compression. All of these services are available when using OFTP 2 over TCP/IP, X.25/ISDN or native X.25. When used over a TCP/IP network such as the Internet, additional session level security is available by using OFTP 2 over Transport Layer Security (TLS).

https://en.wikipedia.org/wiki/OFTP

- **EDIFACT (1987+)**

United Nations/Electronic Data Interchange for Administration, Commerce and Transport (UN/EDIFACT) is an international standard for electronic data interchange (EDI) developed for the United Nations and approved and published by UNECE, the UN Economic Commission for Europe.[1]

In 1987, following the convergence of the UN and US/ANSI syntax proposals, the UN/EDIFACT Syntax Rules were approved as the ISO standard ISO 9735 by the International Organization for Standardization.[2]

The EDIFACT standard provides:

a set of syntax rules to structure data
an interactive exchange protocol (I-EDI)
standard messages which allow multi-country and multi-industry exchange
The work of maintenance and further development of this standard is done through the United Nations Centre for Trade Facilitation and Electronic Business (UN/CEFACT) under the UN Economic Commission for Europe, in the Finance Domain working group UN CEFACT TBG5.

https://en.wikipedia.org/wiki/EDIFACT

### Automation

- **CEBus (1984-1992)**

CEBus(r), short for Consumer Electronics Bus, also known as EIA-600, is a set of electrical standards and communication protocols for electronic devices to transmit commands and data. It is suitable for devices in households and offices to use, and might be useful for utility interface and light industrial applications.
In 1984, members of the Electronic Industries Alliance (EIA) identified a need for standards that included more capability than the de facto home automation standard X10. X10 provided blind transmission of the commands ON, OFF, DIM, BRIGHT, ALL LIGHTS ON, and ALL UNITS OFF over powerline carrier, and later infrared and short range radio mediums. Over a six-year period, engineers representing international companies met on a regular basis and developed a proposed standard. They called this standard CEBus (pronounced "see bus"). The CEBus standard was released in September 1992.
CEBus is an open architecture set of specification documents which define protocols for products to communicate through power line wire, low voltage twisted pair wire, coaxial cable, infrared, RF, and fiber optics.
The CEBus Standard was developed on the foundation of an IR (infrared) protocol developed by GE (General Electric). This work was transferred to the EIA at the beginning of the EIA's involvement, under the plan that it would be expanded then maintained by the EIA.

https://en.wikipedia.org/wiki/CEBus

## Programming languages and frameworks
**[`^        back to top        ^`](#)**
## Navigation
**[`^        back to top        ^`](#)**

**Decision to open GPS to civilian use and deployment of modern GPS satellites**

In 1983, after Soviet interceptor aircraft shot down the civilian airliner KAL 007 that strayed into prohibited airspace because of navigational errors, killing all 269 people on board, U.S. President Ronald Reagan announced that GPS would be made available for civilian uses once it was completed,[54][55] although it had been previously published in Navigation magazine, and that the CA code (Coarse/Acquisition code) would be available to civilian users.[citation needed]

By 1985, ten more experimental Block-I satellites had been launched to validate the concept.

Beginning in 1988, command and control of these satellites was moved from Onizuka AFS, California to the 2nd Satellite Control Squadron (2SCS) located at Falcon Air Force Station in Colorado Springs, Colorado.[56][57]

On February 14, 1989, the first modern Block-II satellite was launched.

https://en.wikipedia.org/wiki/Global_Positioning_System



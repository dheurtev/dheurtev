# 1990s

## Telecommunications : Broadband internet ##
In the 1990s, with the advances of the Internet, leased lines were also used to **connect customer premises to ISP point of presence** 
https://en.wikipedia.org/wiki/Leased_line

**ADSL**
Lechleider also believed this higher-speed standard would be much more attractive to customers than ISDN had proven. Unfortunately, at these speeds, the systems suffered from a type of crosstalk known as "NEXT", for "near-end crosstalk". This made longer connections on customer lines difficult. Lechleider noted that NEXT only occurred when similar frequencies were being used, and could be diminished if one of the directions used a different carrier rate, but doing so would reduce the potential bandwidth of that channel. Lechleider suggested that most consumer use would be asymmetric anyway, and that providing a high-speed channel towards the user and a lower speed return would be suitable for many uses.[6]
This work in the early 1990s eventually led to the ADSL concept, which emerged in 1995. An early supporter of the concept was Alcatel, who jumped on ADSL while many other companies were still devoted to ISDN. Krish Prabu stated that "Alcatel will have to invest one billion dollars in ADSL before it makes a profit, but it is worth it." They introduced the first DSL Access Multiplexers (DSLAM), the large multi-modem systems used at the telephony offices, and later introduced customer ADSL modems under the Thomson brand. Alcatel remained the primary vendor of ADSL systems for well over a decade.[7]
ADSL quickly replaced ISDN as the customer-facing solution for last-mile connectivity. ISDN has largely disappeared on the customer side, remaining in use only in niche roles like dedicated teleconferencing systems and similar legacy systems.
https://en.wikipedia.org/wiki/Integrated_Services_Digital_Network

## Networking : IP traffic ##
**Transition to IP traffic**
Beginning in March 1991 the JANET IP Service (JIPS) was set up as a pilot project to host IP traffic on the existing network.[69] Within eight months the IP traffic had exceeded the levels of X.25 traffic, and the IP support became official in November. Also in 1991, Dai Davies introduced Internet technology over X.25 into the pan-European NREN, EuropaNet, although he experienced personal opposition to this approach.[70][71] The European Academic and Research Network (EARN) and RARE adopted IP around the same time,[nb 7] and the European Internet backbone EBONE became operational in 1992.[53] OSI usage on the NSFNET remained low when compared to TCP/IP. There was some talk of moving JANET to OSI protocols in the 1990s, but this never happened. The X.25 service was closed in August 1997
https://en.wikipedia.org/wiki/Protocol_Wars

## Cryptography : Asymetric keys ##
- **PGP (1991)**
Pretty Good Privacy is an encryption program that provides cryptographic privacy and authentication for data communication
https://en.wikipedia.org/wiki/Pretty_Good_Privacy
- **DSA (1991)**: The Digital Signature Algorithm (DSA) is a Federal Information Processing Standard for digital signatures, based on the mathematical concept of modular exponentiation and the discrete logarithm problem. DSA is a variant of the Schnorr and ElGamal signature schemes.[1]: 486 . 
The National Institute of Standards and Technology (NIST) proposed DSA for use in their Digital Signature Standard (DSS) in 1991, and adopted it as FIPS 186 in 1994
https://en.wikipedia.org/wiki/Digital_Signature_Algorithm
- Leads to SSL and TLS development (see below)
- **RSA released in public domain before patent expiration in 2000**
https://en.wikipedia.org/wiki/RSA_(cryptosystem)

## Computers : Home computer, from GUI to web servers/browsers ##

### Evolution of mainframes ###
graphic display terminals, and terminal emulation became obsolete in the 1990s due to the advent of personal computers provided with **GUIs**.
https://en.wikipedia.org/wiki/Mainframe_computer

In 1991, AT&T Corporation briefly owned NCR. During the same period, companies found that servers based on microcomputer designs could be deployed at a fraction of the acquisition price and offer local users much greater control over their own systems given the IT policies and practices at that time. Terminals used for interacting with mainframe systems were gradually replaced by personal computers. Consequently, demand plummeted and new mainframe installations were restricted mainly to financial services and government. In the early 1990s, there was a rough consensus among industry analysts that the mainframe was a dying market as mainframe platforms were increasingly replaced by personal computer networks. InfoWorld's Stewart Alsop infamously predicted that the last mainframe would be unplugged in 1996; in 1993, he cited Cheryl Currid, a computer industry analyst as saying that the last mainframe "will stop working on December 31, 1999",[20] a reference to the anticipated Year 2000 problem (Y2K).
https://en.wikipedia.org/wiki/Mainframe_computer

### Evolution of hardware ###

- **XGA - Extended Graphics Array (1990) - IBM**
The Extended Graphics Array (XGA) is an IBM display standard introduced in 1990. Later it became the most common appellation of the **1024 × 768 pixels** display resolution, but the official definition is broader than that. It was not a new and improved replacement for Super VGA, but rather became one particular subset of the broad range of capabilities covered under the "Super VGA" umbrella.
https://en.wikipedia.org/wiki/Graphics_display_resolution#Extended_Graphics_Array

- **PCI 1.0 - Peripheral Component Interconnect (1992) - Intel**
Peripheral Component Interconnect (PCI)[3] is a local computer bus for attaching hardware devices in a computer and is part of the PCI Local Bus standard. The PCI bus supports the functions found on a processor bus but in a standardized format that is independent of any given processor's native bus. Devices connected to the PCI bus appear to a bus master to be connected directly to its own bus and are assigned addresses in the processor's address space.
Work on PCI began at the Intel Architecture Labs (IAL, also Architecture Development Lab) c. 1990. A team of primarily IAL engineers defined the architecture and developed a proof of concept chipset and platform (Saturn) partnering with teams in the company's desktop PC systems and core logic product organizations.

PCI was immediately put to use in servers, replacing Micro Channel architecture (MCA) and Extended Industry Standard Architecture (EISA) as the server expansion bus of choice. In mainstream PCs, PCI was slower to replace VLB, and did not gain significant market penetration until late 1994 in second-generation Pentium PCs. By 1996, VLB was all but extinct, and manufacturers had adopted PCI even for Intel 80486 (486) computers.[11] EISA continued to be used alongside PCI through 2000. Apple Computer adopted PCI for professional Power Macintosh computers (replacing NuBus) in mid-1995, and the consumer Performa product line (replacing LC Processor Direct Slot (PDS)) in mid-1996.
https://en.wikipedia.org/wiki/Peripheral_Component_Interconnect

- **PCMIA (1990-1992)**
In computing, PC Card is a configuration for computer parallel communication peripheral interface, designed for laptop computers. Originally introduced as PCMCIA, the PC Card standard as well as its successors like CardBus were defined and developed by the Personal Computer Memory Card International Association (PCMCIA).
It was originally designed as a standard for memory-expansion cards for computer storage. The existence of a usable general standard for notebook peripherals led to many kinds of devices being made available based on its configurability, including network cards, modems, and hard disks.
The PCMCIA 1.0 card standard was published by the Personal Computer Memory Card International Association in November 1990 and was soon adopted by more than eighty vendors.[1] [2] It corresponds with the Japanese JEIDA memory card 4.0 standard.[2]
**SanDisk** (operating at the time as "SunDisk") launched its PCMCIA card in October 1992. The company was the first to introduce a writeable Flash RAM card for the HP 95LX (the first MS-DOS pocket computer). These cards conformed to a supplemental PCMCIA-ATA standard that allowed them to appear as more conventional IDE hard drives to the 95LX or a PC. This had the advantage of raising the upper limit on capacity to the full 32M available under DOS 3.22 on the 95LX.[3]
Type II PC Card: IBM V.34 data/fax modem, manufactured by TDK
It soon became clear that the PCMCIA card standard needed expansion to support "smart" I/O cards to address the emerging need for fax, modem, LAN, harddisk and floppy disk cards.[1] It also needed interrupt facilities and hot plugging, which required the definition of new BIOS and operating system interfaces.[1] This led to the introduction of release 2.0 of the PCMCIA standard and JEIDA 4.1 in September 1991,[1][2] which saw corrections and expansion with Card Services (CS) in the PCMCIA 2.1 standard in November 1992.[1][2]
https://en.wikipedia.org/wiki/PC_Card

- **IEEE 1284 - bidirectional printer cable (1994)**
In 1991 the Network Printing Alliance was formed to develop a new standard. In March 1994, the IEEE 1284 specification was released. 1284 included all of these modes, and allowed operation in any of them.
An IEEE 1284 compliant printer cable, with both DB-25 and 36-pin Centronics connectors
The IEEE 1284 standard allows for faster throughput and bidirectional data flow with a theoretical maximum throughput of 4 megabytes per second; actual throughput is around 2 megabytes/second depending on hardware. In the printer venue, this allows for faster printing and back-channel status and management. Since the new standard allowed the peripheral to send large amounts of data back to the host, devices that had previously used SCSI interfaces could be produced at a much lower cost. This included scanners, tape drives, hard disks, computer networks connected directly via parallel interface, network adapters and other devices. No longer was the consumer required to purchase an expensive SCSI card—they could simply use their built-in parallel interface.
The parallel interface has since been mostly displaced by local area network interfaces and USB 2.0.
https://en.wikipedia.org/wiki/IEEE_1284

- **VESA Card(1993)**
The VESA Local Bus (usually abbreviated to VL-Bus or VLB) is a short-lived expansion bus introduced during the i486 generation of x86 IBM-compatible personal computers. Created by VESA (Video Electronics Standards Association), the VESA Local Bus worked alongside the then-dominant ISA bus to provide a standardized high-speed conduit intended primarily to accelerate video (graphics) operations. VLB provides a standardized fast path that add-in (video) card makers could tap for greatly accelerated memory-mapped I/O and DMA, while still using the familiar ISA bus to handle basic device duties such as interrupts and port-mapped I/O. Some high-end 386dx motherboards also had a VL-Bus slot.
https://en.wikipedia.org/wiki/VESA_Local_Bus

- **CompactFlash (CF) - flash memory mass storage (1994) Sandisk**
CompactFlash (CF) is a flash memory mass storage device used mainly in portable electronic devices. The format was specified and the devices were first manufactured by SanDisk in 1994.[3] CompactFlash became one of the most successful of the early memory card formats, surpassing Miniature Card and SmartMedia. Subsequent formats, such as MMC/SD, various Memory Stick formats, and xD-Picture Card offered stiff competition
https://en.wikipedia.org/wiki/CompactFlash

- **DVD (1996)**
The DVD (common abbreviation for Digital Video Disc or Digital Versatile Disc)[8][9] is a digital optical disc data storage format invented and developed in 1995 and released in late 1996. Currently allowing up to 17.08 GB of storage,[10] the medium can store any kind of digital data and was widely used for software and other computer files as well as video programs watched using DVD players. DVDs offer higher storage capacity than compact discs while having the same dimensions.
https://en.wikipedia.org/wiki/DVD

- **CardBus (1995-1997)**
CardBus are PCMCIA 5.0 or later (JEIDA 4.2 or later) 32-bit PCMCIA devices, introduced in 1995 and present in laptops from late 1997 onward. CardBus is effectively a 32-bit, 33 MHz PCI bus in the PC Card design. CardBus supports bus mastering, which allows a controller on the bus to talk to other devices or memory without going through the CPU. Many chipsets, such as those that support Wi-Fi, are available for both PCI and CardBus
https://en.wikipedia.org/wiki/PC_Card

- **AGP - Accelerated Graphics Port (1997)**
Accelerated Graphics Port (AGP) is a parallel expansion card standard, designed for attaching a video card to a computer system to assist in the acceleration of 3D computer graphics. It was originally designed as a successor to PCI-type connections for video cards. Since 2004, AGP was progressively phased out in favor of PCI Express (PCIe), which is serial, as opposed to parallel; by mid-2008, PCI Express cards dominated the market and only a few AGP models were available,[1] with GPU manufacturers and add-in board partners eventually dropping support for the interface in favor of PCI Express.
https://en.wikipedia.org/wiki/Accelerated_Graphics_Port
The AGP slot first appeared on x86-compatible system boards based on Socket 7 Intel P5 Pentium and Slot 1 P6 Pentium II processors. Intel introduced AGP support with the i440LX Slot 1 chipset on August 26, 1997, and a flood of products followed from all the major system board vendors.[3]
The first Socket 7 chipsets to support AGP were the VIA Apollo VP3, SiS 5591/5592, and the ALI Aladdin V. Intel never released an AGP-equipped Socket 7 chipset. FIC demonstrated the first Socket 7 AGP system board in November 1997 as the FIC PA-2012 based on the VIA Apollo VP3 chipset, followed very quickly by the EPoX P55-VP3 also based on the VIA VP3 chipset which was first to market.[4]
Early video chipsets featuring AGP support included the Rendition Vérité V2200, 3dfx Voodoo Banshee, Nvidia RIVA 128, 3Dlabs PERMEDIA 2, Intel i740, ATI Rage series, Matrox Millennium II, and S3 ViRGE GX/2. Some early AGP boards used graphics processors built around PCI and were simply bridged to AGP. This resulted in the cards benefiting little from the new bus, with the only improvement used being the 66 MHz bus clock, with its resulting doubled bandwidth over PCI, and bus exclusivity. Examples of such cards were the Voodoo Banshee, Vérité V2200, Millennium II, and S3 ViRGE GX/2. Intel's i740 was explicitly designed to exploit the new AGP feature set; in fact it was designed to texture only from AGP memory, making PCI versions of the board difficult to implement (local board RAM had to emulate AGP memory.)
Microsoft first introduced AGP support into Windows 95 OEM Service Release 2 (OSR2 version 1111 or 950B) via the USB SUPPLEMENT to OSR2 patch.[5] After applying the patch the Windows 95 system became Windows 95 version 4.00.950 B. The first Windows NT-based operating system to receive AGP support was Windows NT 4.0 with Service Pack 3, introduced in 1997. Linux support for AGP enhanced fast data transfers was first added in 1999 with the implementation of the AGPgart kernel module.
https://en.wikipedia.org/wiki/Accelerated_Graphics_Port

- **USB (1996)**
Universal Serial Bus (USB) is an industry standard that establishes specifications for cables, connectors and protocols for connection, communication and power supply (interfacing) between computers, peripherals and other computers.[2] A broad variety of USB hardware exists, including 14 different connector types, of which USB-C is the most recent and the only one not currently deprecated.
First released in 1996, the USB standards are maintained by the USB Implementers Forum (USB-IF). The four generations of USB are: USB 1.x, USB 2.0, USB 3.x, and USB4.[3]
Compaq
DEC
IBM
Intel
Microsoft
NEC
Nortel
USB 1.x
Released in January 1996, USB 1.0 specified signaling rates of 1.5 Mbit/s (Low Bandwidth or Low Speed) and 12 Mbit/s (Full Speed).[15] It did not allow for extension cables or pass-through monitors, due to timing and power limitations. Few USB devices made it to the market until USB 1.1 was released in August 1998. USB 1.1 was the earliest revision that was widely adopted and led to what Microsoft designated the "Legacy-free PC".[16][17][18]
https://en.wikipedia.org/wiki/USB

In 1998, Apple's iMac G3 was introduced as the first widely known example of a legacy-free PC,[9][10][11] and drew much criticism for its lack of legacy peripherals such as a floppy drive and Apple Desktop Bus (ADB) connector; [12] However, its success popularizd USB ports.
Compaq released the iPaq desktop in 1999.
From November 1999 to July 2000, Dell's WebPC was an early less-successful Wintel legacy-free PC.
A legacy-free PC is a type of personal computer that lacks a floppy and/or optical disc drive, legacy ports, and an Industry Standard Architecture (ISA) bus (or sometimes, any internal expansion bus at all). According to Microsoft, "The basic goal for these requirements is that the operating system, devices, and end users cannot detect the presence of the following: ISA slots or devices; legacy floppy disk controller (FDC); and PS/2, serial, parallel, and game ports."[1] The legacy ports are usually replaced with Universal Serial Bus (USB) ports. A USB adapter may be used if an older device must be connected to a PC lacking these ports.[2] According to the 2001 edition of Microsoft's PC System Design Guide, a legacy-free PC must be able to boot from a USB device.[3]
https://en.wikipedia.org/wiki/Legacy-free_PC

### Evolution of software : Web server/browsers and Gui ###
#### Web servers and browsers ####
- **httpd (1990) : First web server goes live** 
https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol
CERN httpd (later also known as W3C httpd) is an early, now discontinued, web server (HTTP) daemon originally developed at CERN from 1990 onwards by Tim Berners-Lee, Ari Luotonen[2] and Henrik Frystyk Nielsen.[1] Implemented in C, it was the first web server software.[3]
https://en.wikipedia.org/wiki/CERN_httpd
- **NSCA Mosaïc (1993)**: web browser developped at the end of 1992 at the american research center NCSA
https://en.wikipedia.org/wiki/Mosaic_(web_browser)
- **NSCA HTTPd (1993)**
NCSA HTTPd is an early, now discontinued, web server originally developed at the NCSA at the University of Illinois at Urbana–Champaign by Robert McCool and others.[1] First released in 1993, it was among the earliest web servers developed, following Tim Berners-Lee's CERN httpd, Tony Sanders' Plexus server, and some others
https://en.wikipedia.org/wiki/NCSA_HTTPd
- **Netscape Navigator (1994): web browser**
https://en.wikipedia.org/wiki/Netscape
- **Apache HTTP Server (1995): Most successful internet server**
Originally based on the NCSA HTTPd server, development of Apache began in early 1995 after work on the NCSA code stalled. Apache played a key role in the initial growth of the World Wide Web,[11] quickly overtaking NCSA HTTPd as the dominant HTTP server. In 2009, it became the first web server software to serve more than 100 million websites.[12]
https://en.wikipedia.org/wiki/Apache_HTTP_Server
- **Microsoft Internet Explorer (1995): Most successful web browser**
Starting in 1995, It was first released as part of the add-on package Plus! for Windows 95 that year. Later versions were available as free downloads, or in-service packs, and included in the original equipment manufacturer (OEM) service releases of Windows 95 and later versions of Windows. 
Internet Explorer was once the most widely used web browser, attaining a peak of 95% usage share by 2003.[12] This came after Microsoft used bundling to win the first browser war against Netscape, which was the dominant browser in the 1990s
https://en.wikipedia.org/wiki/Internet_Explorer

#### GUI ####
- **Microsoft Windows 3.0 (1990) : Multi-tasked DOS**
improved the design, mostly because of virtual memory and loadable virtual device drivers (VxDs) that allow Windows to share arbitrary devices between **multi-tasked DOS applications**.
https://en.wikipedia.org/wiki/Microsoft_Windows
- **Microsoft Windows 3.11 (1993) : Windows for Workgroups - peer-to-peer networking features**
Windows 3.1, made generally available on March 1, 1992, featured a facelift. In August 1993, ***Windows for Workgroups, a special version with integrated peer-to-peer networking features*** and a version number of 3.11, was released.
https://en.wikipedia.org/wiki/Microsoft_Windows
- **Microsoft Windows 95 (1995) : 32 bit applications, plug and play hardware**
Windows 95 introduced support for native 32-bit applications, plug and play hardware, preemptive multitasking, long file names of up to 255 characters, and provided increased stability over its predecessors. Windows 95 also introduced a redesigned, object oriented user interface, replacing the previous Program Manager with the Start menu, taskbar, and Windows Explorer shell. Windows 95 was a major commercial success for Microsoft
https://en.wikipedia.org/wiki/Microsoft_Windows
- **Microsoft Windows 98 (1998) : USB support**
The release of Windows 98 on June 25, 1998, which introduced the Windows Driver Model, support for USB composite devices, support for ACPI, hibernation, and support for multi-monitor configuration**
https://en.wikipedia.org/wiki/Microsoft_Windows
- **VNC (1999): Remote desktop application** : 
The remote desktop application VNC (Virtual Network Computing) is made available by the AT&T Laboratories Cambridge. ORL, the Olivetti Research Laboratory was founded 12 years earlier, accquired in 1999 by AT&T to create AT&T; Laboratories Cambridge.
https://en.wikipedia.org/wiki/Virtual_Network_Computing

## Consumer electronics - automation ##
**LonWork (1999)** - LonWorks or Local Operating Network is an open standard (ISO/IEC 14908) for networking platforms specifically created to address the needs of control applications. The platform is built on a protocol created by Echelon Corporation for networking devices over media such as twisted pair, powerlines, fibre optics , and RF. It is used for the automation of various functions within buildings such as lighting and HVAC; see building automation.
The technology has its origins with chip designs, power line and twisted pair, signaling technology, routers, network management software, and other products from Echelon Corporation. In 1999 the communications protocol (then known as LonTalk) was submitted to ANSI and accepted as a standard for control networking (ANSI/CEA-709.1-B). Echelon's power line and twisted pair signaling technology was also submitted to ANSI for standardization and accepted. Since then, ANSI/CEA-709.1 has been accepted as the basis for IEEE 1473-L (in-train controls), AAR electro-pneumatic braking systems for freight trains, IFSF (European petrol station control), SEMI (semiconductor equipment manufacturing), and in 2005 as EN 14908 (European building automation standard). The protocol is also one of several data link/physical layers of the BACnet ASHRAE/ANSI standard for building automation.
China ratified the technology as a national controls standard, GB/Z 20177.1-2006 and as a building and intelligent community standard, GB/T 20299.4-2006; and in 2007 CECED, the European Committee of Domestic Equipment Manufacturers, adopted the protocol as part of its Household Appliances Control and Monitoring – Application Interworking Specification (AIS) standards.
During 2008 ISO and IEC have granted the communications protocol, twisted pair signaling technology, power line signaling technology, and Internet Protocol (IP) compatibility standard numbers ISO/IEC 14908-1, -2, -3, and -4.[1]
https://en.wikipedia.org/wiki/LonWorks

## TV : ATSC in preparation of HDTV
Advanced Television Systems Committee (ATSC) standards are an American set of standards for digital television transmission over terrestrial, cable and satellite networks. It is largely a replacement for the analog NTSC standard and, like that standard, is used mostly in the United States, Mexico, Canada, and South Korea. Several former NTSC users, in particular Japan, have not used ATSC during their digital television transition, because they adopted their own system called ISDB.
The ATSC standards were developed in the early 1990s by the Grand Alliance, a consortium of electronics and telecommunications companies that assembled to develop a specification for what is now known as HDTV.
The high-definition television standards defined by the ATSC produce widescreen 16:9 images up to 1920×1080 pixels in size – more than six times the display resolution of the earlier standard. However, many different image sizes are also supported. The reduced bandwidth requirements of lower-resolution images allow up to six standard-definition "subchannels" to be broadcast on a single 6 MHz TV channel.
ATSC standards are marked A/x (x is the standard number) and can be downloaded for free from the ATSC's website at ATSC.org. ATSC Standard A/53, which implemented the system developed by the Grand Alliance, was published in 1995; the standard was adopted by the Federal Communications Commission in the United States in 1996. It was revised in 2009. ATSC Standard A/72 was approved in 2008 and introduces H.264/AVC video coding to the ATSC system.
ATSC supports 5.1-channel surround sound using Dolby Digital's AC-3 format. Numerous auxiliary datacasting services can also be provided.
Many aspects of ATSC are patented, including elements of the MPEG video coding, the AC-3 audio coding, and the 8VSB modulation.[2] The cost of patent licensing, estimated at up to $50 per digital TV receiver,[3] had prompted complaints by manufacturers.[4]
Companies with patents included : 
LG Electronics, Zenith Electronics, Panasonic, Samsung Electronics, Columbia University, Mitsubishi Electric, JVC Kenwood, Cisco Technology, Inc., Vientos Alisios Co., Ltd., Philips
https://en.wikipedia.org/wiki/ATSC_standards

**DVB**
DVB-S and DVB-C were ratified in 1994. DVB-T was ratified in early 1997. The first commercial DVB-T broadcasts were performed by the United Kingdom's Digital TV Group in late 1998. In 2003 Berlin, Germany was the first area to completely stop broadcasting analog TV signals. Most European countries are fully covered by digital television and many have switched off PAL/SECAM services.
Digital Video Broadcasting (DVB) is a set of international open standards for digital television. DVB standards are maintained by the DVB Project, an international industry consortium,[1] and are published by a Joint Technical Committee (JTC) of the European Telecommunications Standardisé Institute (ETSI), European Committee for Electrotechnical Standardization (CENELEC) and European Broadcasting Union (EBU).
Satellite: DVB-S, DVB-S2, and DVB-SH
DVB-SMATV for distribution via SMATV
Cable: DVB-C, DVB-C2
https://en.wikipedia.org/wiki/Digital_Video_Broadcasting
DVB-T, short for Digital Video Broadcasting — Terrestrial, is the DVB European-based consortium standard for the broadcast transmission of digital terrestrial television that was first published in 1997[1] and first broadcast in Singapore in February, 1998.[2][3][4][5][6][7][8] This system transmits compressed digital audio, digital video and other data in an MPEG transport stream, using coded orthogonal frequency-division multiplexing (COFDM or OFDM) modulation. It is also the format widely used worldwide (including North America) for Electronic News Gathering for transmission of video and audio from a mobile newsgathering vehicle to a central receive point.
https://en.wikipedia.org/wiki/DVB-T

### HD TV tests
#### United States : Deployment
HDTV technology was introduced in the United States in the early 1990s and made official in 1993 by the Digital HDTV Grand Alliance, a group of television, electronic equipment, communications companies consisting of AT&T Bell Labs, General Instrument, Philips, Sarnoff, Thomson, Zenith and the Massachusetts Institute of Technology. Field testing of HDTV at 199 sites in the United States was completed August 14, 1994.[34] The first public HDTV broadcast in the United States occurred on July 23, 1996, when the Raleigh, North Carolina television station WRAL-HD began broadcasting from the existing tower of WRAL-TV southeast of Raleigh, winning a race to be first with the HD Model Station in Washington, D.C., which began broadcasting July 31, 1996 with the callsign WHD-TV, based out of the facilities of NBC owned and operated station WRC-TV.[35][36][37] The American Advanced Television Systems Committee (ATSC) HDTV system had its public launch on October 29, 1998, during the live coverage of astronaut John Glenn's return mission to space on board the Space Shuttle Discovery.[38] The signal was transmitted coast-to-coast, and was seen by the public in science centers, and other public theaters specially equipped to receive and display the broadcast.[38][39]
https://en.wikipedia.org/wiki/High-definition_television
#### Europe : Tests
Between 1988 and 1991, several European organizations were working on discrete cosine transform (DCT) based digital video coding standards for both SDTV and HDTV. The EU 256 project by the CMTT and ETSI, along with research by Italian broadcaster RAI, developed a DCT video codec that broadcast near-studio-quality HDTV transmission at about 70–140 Mbit/s.[23][40] The first HDTV transmissions in Europe, albeit not direct-to-home, began in 1990, when RAI broadcast the 1990 FIFA World Cup using several experimental HDTV technologies, including the digital DCT-based EU 256 codec,[23] 
https://en.wikipedia.org/wiki/High-definition_television

In the US in the early 1990s, four large cable companies launched PrimeStar, a direct broadcasting company using medium power satellites. The relatively strong transmissions allowed the use of smaller (90 cm) dishes. Its popularity declined with the 1994 launch of the Hughes DirecTV and Dish Network satellite television systems.
Digital satellite broadcasts began in 1994 in the United States through DirecTV using the DSS format. They were launched (with the DVB-S standard) in South Africa, Middle East, North Africa and Asia-Pacific in 1994 and 1995, and in 1996 and 1997 in European countries including France, Germany, Spain, Portugal, Italy and the Netherlands, as well as Japan, North America and Latin America. Digital DVB-S broadcasts in the United Kingdom and Ireland started in 1998. Japan started broadcasting with the ISDB-S standard in 2000.
On March 4, 1996, EchoStar introduced Digital Sky Highway (Dish Network) using the EchoStar 1 satellite.[80] EchoStar launched a second satellite in September 1996 to increase the number of channels available on Dish Network to 170.[80] These systems provided better pictures and stereo sound on 150–200 video and audio channels, and allowed small dishes to be used. This greatly reduced the popularity of TVRO systems. In the mid-1990s, channels began moving their broadcasts to digital television transmission using the DigiCipher conditional access system.[81]
https://en.wikipedia.org/wiki/Satellite_television

## Some standards, languages and protocols ##

### Network layer ###
- **IPv6 - Internet Protocol version 6 (1995)** : most recent version of the Internet Protocol (IP), the communications protocol that provides an identification and location system for computers on networks and routes traffic across the Internet. 
Introduced in 1995, IPv6 was developed by the Internet Engineering Task Force (IETF) to deal with the long-anticipated problem of IPv4 address exhaustion, and is intended to replace IPv4.
In December 1998, IPv6 became a Draft Standard for the IETF, which subsequently ratified it as an Internet Standard on 14 July 2017.
Deployment was slowed by the widespread use of NAT (1999).
https://en.wikipedia.org/wiki/IPv6
- **NAT - Network address translation (1999)** : a method of mapping an IP address space into another by modifying network address information in the IP header of packets while they are in transit across a traffic routing device.
Popular with the exhaustion of IPv4 addresses and home routers. Essential to networking. 
https://en.wikipedia.org/wiki/Network_address_translation

### Transport layer ###
- **SSL - Secure Socket Layer (1995-1998)**: 
Netscape developed the original SSL protocols, and Taher Elgamal, chief scientist at Netscape Communications from 1995 to 1998. Superseded by TLS.
https://en.wikipedia.org/wiki/Transport_Layer_Security
- **TLS - Transport Layer Security (1999)** : a cryptographic protocol designed to provide communications security over a computer network. The protocol is widely used in applications such as email, instant messaging, and voice over IP, but its use in securing HTTPS remains the most publicly visible.
Essential to networking and the internet.
https://en.wikipedia.org/wiki/Transport_Layer_Security

### Application layer ###
- **HTTP/0.9 - Hypertext Transfer Protocol (1991)** : application layer protocol in the Internet protocol suite model for distributed, collaborative, hypermedia information systems. Essential to the internet.
https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol
- **DHCP - Dynamic Host Configuration Protocol (1991)** : a network management protocol used on Internet Protocol (IP) networks for automatically assigning IP addresses and other communication parameters to devices connected to the network using a client–server architecture.
Essential to networking.
https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol

### Data transmission ###
#### Text ####
- **HTML (1990-1991) - HyperText Markup Language**
In 1980, physicist Tim Berners-Lee, a contractor at CERN, proposed and prototyped ENQUIRE, a system for CERN researchers to use and share documents. In 1989, Berners-Lee wrote a memo proposing an Internet-based hypertext system.[3] Berners-Lee specified HTML and wrote the browser and server software in late 1990. 
The first publicly available description of HTML was a document called "HTML Tags", first mentioned on the Internet by Tim Berners-Lee in late 1991.
https://en.wikipedia.org/wiki/HTML
- **URL (1992-1994) - Uniform Resource Locators**
Uniform Resource Locators were defined in RFC 1738 in 1994 by Tim Berners-Lee, the inventor of the World Wide Web, and the URI working group of the Internet Engineering Task Force (IETF),[7] as an outcome of collaboration started at the IETF Living Documents birds of a feather session in 1992.[7][8]
https://en.wikipedia.org/wiki/URL
- **XML (1998) - Extensible Markup Language** : a markup language and file format for storing, transmitting, and reconstructing arbitrary data. It defines a set of rules for encoding documents in a format that is both human-readable and machine-readable. The World Wide Web Consortium's XML 1.0 Specification[2] of 1998[3] and several other related specifications[4]—all of them free open standards—define XML.[5]
https://en.wikipedia.org/wiki/XML
#### Images ####
- **JPEG (1992)**: Picture compression format.
https://en.wikipedia.org/wiki/JPEG
- **PNG (1997):** Portable Network Graphics (PNG, officially pronounced /pɪŋ/[2][3] PING, colloquially pronounced /ˌpiːɛnˈdʒiː/[4] PEE-en-JEE) is a raster-graphics file format that supports lossless data compression.
PNG was published as informational RFC 2083 in March 1997 and as an ISO/IEC 15948 standard in 2004
https://en.wikipedia.org/wiki/Portable_Network_Graphics
#### Voice over IP ####
- **SIP - Session Initiation Protocol (1996)** : signaling protocol used for initiating, maintaining, and terminating communication sessions that include voice, video and messaging applications. 
SIP is used in **Internet telephony**, in private IP telephone systems, as well as mobile phone calling over LTE (**VoLTE**). Essential to telecommunications.
https://en.wikipedia.org/wiki/Session_Initiation_Protocol
#### Video over IP ####
- **MPEG-1 (1993)**
Since 1972, International Telecommunication Union's radio telecommunications sector (ITU-R) had been working on creating a global recommendation for Analog HDTV. These recommendations, however, did not fit in the broadcasting bands which could reach home users. The standardization of MPEG-1 in 1993 led to the acceptance of recommendations ITU-R BT.709
https://en.wikipedia.org/wiki/High-definition_television
- **MPEG-2 (1995)**
MPEG-2 evolved out of the shortcomings of MPEG-1.
MPEG-1's known weaknesses:
An audio compression system limited to two channels (stereo).
No standardized support for interlaced video with poor compression when used for interlaced video
Only one standardized "profile" (Constrained Parameters Bitstream), which was unsuited for higher resolution video. MPEG-1 could support 4k video but there was no easy way to encode video for higher resolutions, and identify hardware capable of supporting it, as the limitations of such hardware were not defined.
Support for only one chroma subsampling, 4:2:0.
Sakae Okubo of NTT was the ITU-T coordinator for developing the H.262/MPEG-2 Part 2 video coding standard and the requirements chairman in MPEG for the MPEG-2 set of standards.[27] The majority of patents underlying MPEG-2 technology are owned by three companies: Sony (311 patents), Thomson (198 patents) and Mitsubishi Electric (119 patents).[28] Hyundai Electronics (now SK Hynix) developed the first MPEG-2 SAVI (System/Audio/Video) decoder in 1995.[29]
https://en.wikipedia.org/wiki/MPEG-2
- **H.323 (1996):** is a recommendation from the ITU Telecommunication Standardization Sector (ITU-T) that defines the protocols to provide audio-visual communication sessions on any packet network.[1] The H.323 standard addresses call signaling and control, multimedia transport and control, and bandwidth control for point-to-point and multi-point conferences.[2]
It is widely implemented[3] by **voice and videoconferencing equipment manufacturers**, is used within various **Internet real-time applications** such as GnuGK and NetMeeting and is widely deployed worldwide by service providers and enterprises for both voice and video services over IP networks.
https://en.wikipedia.org/wiki/H.323
- **H.263 (1996)**
The H.263 standard was first designed to be utilized in H.324 based systems (PSTN and other **circuit-switched network videoconferencing and videotelephony)**, but it also found use in H.323 (RTP/IP-based videoconferencing), H.320 (ISDN-based videoconferencing, where it became the most widely used video compression standard),[4] RTSP (streaming media) and SIP (IP-based videoconferencing) solutions.
https://en.wikipedia.org/wiki/H.263

#### Instant messaging ####
- **XMPP (1999)** : open communication protocol designed for **instant messaging (IM), presence information, and contact list maintenance**. enables the near-real-time exchange of structured data between two or more network entities. Widely in use.
https://en.wikipedia.org/wiki/XMPP
#### Machine-to-machine ####
- **MQTT (1999)** : lightweight, **publish-subscribe, machine to machine network protocol**. It is designed for connections with remote locations that have devices with resource constraints or limited network bandwidth. Widely in use.
https://en.wikipedia.org/wiki/MQTT
#### Files ####
- **Rsync (1999)**: utility for **efficiently transferring and synchronizing files** between a computer and a storage drive and across networked computers by comparing the modification times and sizes of files. Detailed in the creator's PhD Thesis.
https://en.wikipedia.org/wiki/Rsync
#### Remote access ####
- **SSH - Secure Shell (1995): remote login and command-line execution** : The Secure Shell Protocol (SSH) is a cryptographic network protocol for operating network services securely over an unsecured network.[1] Its most notable applications are remote login and command-line execution.
SSH applications are based on a client–server architecture, connecting an SSH client instance with an SSH server
SSH was first designed in 1995 by Finnish computer scientist Tatu Ylönen. Subsequent development of the protocol suite proceeded in several developer groups, producing several variants of implementation. The protocol specification distinguishes two major versions, referred to as SSH-1 and SSH-2. The most commonly implemented software stack is **OpenSSH**, released in **1999** as open-source software by the OpenBSD developers. 
https://en.wikipedia.org/wiki/Secure_Shell
- **VNC - Virtual Network Computing (1999)** : **Remote desktop protocol**. Still widely used. Insecure (not encrypted by default).
https://en.wikipedia.org/wiki/Virtual_Network_Computing

# 1990s

**In short:**
- [Inventions](#inventions) : LCD displays improvements (TN and IPS), high-efficiency green light-emitting polymer-based device, high brightness blue led, idea of using quantum dots as light source, electronic ink
- [Electronics](#electronics) : First while LED sold
- [Energy](#energy) : 
- [Telecommunications](#telecommunications) : 
- [Networking](#networking) : 
- [Cryptography](#cryptography) : Assymetric keys
- [Computers](#computers) :
  * [Form factor](#form-factor) : 
  * [OS](#os) : 
  * [Peripherals](#peripherals) : 
  * [Storage](#storage) :  
  * [Uses](#uses) :
    
    *CGI* : Pixar from hardware to 3D software to Toystory - first full-length 3D film
- [Consumer Electronics](#consumer-electronics) :
  * [Gadgets](#gadgets) : Sophisticated scientific calculators
  * [Multimedia](#multimedia) : DVD, First DVD Player
  * [Screens](#screens) : XGA computer monitors, HD resolution CRT, large plasma flat-panel TVs
  * [Broadcast](#broadcast) : HDTV with ATSC/DVB standards, Medium power satellites with smaller dishes
  * [Video games](#video-games) : Renaissance of arcade games, text-based multi-player virtual reality (Moo), fourth (Nintendo Super NES) to fifth generation video game consoles (Nintento 64, Sony Playstation)
- [Standards and protocols](#standards-and-protocols) : JPEG, MPEG-1, MPEG-2, WAV, MP3, PNG, SIP, SSH, VNC, Rsync, CORBA, ZIP compression tools and competitors (Winzip, RAR, ARJ, DEFLATE, 7-zip), CIFS, SOCKS, PPTP, Modems speeds (14.4k to 56k), HDTV (ATSC/DVB)
- [Programming languages and frameworks](#programming-languages-and-frameworks): OpenGL, Direct X, Direct3D, Unreal engine
- [Navigation](#navigation) : GPS is operational, military use, miniaturization and shift to dual-use

## Inventions
**[`^        back to top        ^`](#)**

- **LCD displays improvements (TN and IPS) (1990s)**

In 1990, under different titles, inventors conceived electro optical effects as alternatives to twisted nematic field effect LCDs (TN- and STN- LCDs). One approach was to use interdigital electrodes on one glass substrate only to produce an electric field essentially parallel to the glass substrates.[79][80] To take full advantage of the properties of this In Plane Switching (IPS) technology further work was needed. After thorough analysis, details of advantageous embodiments are filed in Germany by Guenter Baur et al. and patented in various countries.[81][82] The Fraunhofer Institute ISE in Freiburg, where the inventors worked, assigns these patents to Merck KGaA, Darmstadt, a supplier of LC substances. In 1992, shortly thereafter, engineers at Hitachi work out various practical details of the IPS technology to interconnect the thin-film transistor array as a matrix and to avoid undesirable stray fields in between pixels.[83][84]

Hitachi also improved the viewing angle dependence further by optimizing the shape of the electrodes (Super IPS). NEC and Hitachi become early manufacturers of active-matrix addressed LCDs based on the IPS technology. This is a milestone for implementing large-screen LCDs having acceptable visual performance for flat-panel computer monitors and television screens. In 1996, Samsung developed the optical patterning technique that enables multi-domain LCD. Multi-domain and In Plane Switching subsequently remain the dominant LCD designs through 2006.[85] 

In the late 1990s, the LCD industry began shifting away from Japan, towards South Korea and Taiwan,[77] which later shifted to China.

https://en.wikipedia.org/wiki/Liquid-crystal_display

- **High-efficiency green light-emitting polymer-based device (1990)**

Research into polymer electroluminescence culminated in 1990, with J. H. Burroughes et al. at the Cavendish Laboratory at Cambridge University, UK, reporting a high-efficiency green light-emitting polymer-based device using 100 nm thick films of poly(p-phenylene vinylene).[29] Moving from molecular to macromolecular materials solved the problems previously encountered with the long-term stability of the organic films and enabled high-quality films to be easily made.[30] Subsequent research developed multilayer polymers and the new field of plastic electronics and OLED research and device production grew rapidly.[31] White OLEDs, pioneered by J. Kido et al. at Yamagata University, Japan in 1995, achieved the commercialization of OLED-backlit displays and lighting.[32][33]

https://en.wikipedia.org/wiki/OLED

- **High brightness blue led (1993)**

Two years later, in 1993, high-brightness blue LEDs were demonstrated by Shuji Nakamura of Nichia Corporation using a gallium nitride growth process.[48][49][50] In parallel, Isamu Akasaki and Hiroshi Amano of Nagoya University were working on developing the important GaN deposition on sapphire substrates and the demonstration of p-type doping of GaN. This new development revolutionized LED lighting, making high-power blue light sources practical, leading to the development of technologies like Blu-ray.[citation needed]

In 1995, Alberto Barbieri at the Cardiff University Laboratory (GB) investigated the efficiency and reliability of high-brightness LEDs and demonstrated a "transparent contact" LED using indium tin oxide (ITO) on (AlGaInP/GaAs).

https://en.wikipedia.org/wiki/Light-emitting_diode

- **Idea of using quantum dots as a light source (1990s)**

The idea of using quantum dots as a light source emerged in the 1990s. Early applications included imaging using QD infrared photodetectors, light emitting diodes and single-color light emitting devices.[12] 

https://en.wikipedia.org/wiki/Quantum_dot_display

Quantum dots (QDs) are semiconductor particles a few nanometres in size, having optical and electronic properties that differ from larger particles due to quantum mechanics. They are a central topic in nanotechnology. When the quantum dots are illuminated by UV light, an electron in the quantum dot can be excited to a state of higher energy. In the case of a semiconducting quantum dot, this process corresponds to the transition of an electron from the valence band to the conductance band. The excited electron can drop back into the valence band releasing its energy as light. This light emission (photoluminescence) is illustrated in the figure on the right. The color of that light depends on the energy difference between the conductance band and the valence band, or the transition between discrete energy states when band structure is no longer a good definition in QDs.

https://en.wikipedia.org/wiki/Quantum_dot

- **Electronic Ink (1997) - E Ink**

The notion of a low-power paper-like display had existed since the 1970s, originally conceived by researchers at Xerox PARC, but had never been realized.[4] While a post-doctoral student at Stanford University, physicist Joseph Jacobson envisioned a multi-page book with content that could be changed at the push of a button and required little power to use.[5]

Neil Gershenfeld recruited Jacobson for the MIT Media Lab in 1995, after hearing Jacobson's ideas for an electronic book.[4] Jacobson, in turn, recruited MIT undergrads Barrett Comiskey, a math major, and J.D. Albert, a mechanical engineering major, to create the display technology required to realize his vision.[1]

The initial approach was to create tiny spheres which were half white and half black, and which, depending on the electric charge, would rotate such that the white side or the black side would be visible on the display. Albert and Comiskey were told this approach was impossible by most experienced chemists and materials scientists and they had trouble creating these perfectly half-white, half-black spheres; during his experiments, Albert accidentally created some all-white spheres.[1]

Comiskey experimented with charging and encapsulating those all-white particles in microcapsules mixed in with a dark dye. The result was a system of microcapsules that could be applied to a surface and could then be charged independently to create black and white images.[1] A first patent was filed by MIT for the microencapsulated electrophoretic display in October 1996.[6]

The scientific paper was featured on the cover of Nature, something extremely unusual for work done by undergraduates. The advantage of the microencapsulated electrophoretic display and its potential for satisfying the practical requirements of electronic paper were summarized in the abstract of the Nature paper:

It has for many years been an ambition of researchers in display media to create a flexible low-cost system that is the electronic analogue of paper ... viewing characteristic[s] result in an "ink on paper" look. But such displays have to date suffered from short lifetimes and difficulty in manufacture. Here we report the synthesis of an electrophoretic ink based on the microencapsulation of an electrophoretic dispersion. The use of a microencapsulated electrophoretic medium solves the lifetime issues and permits the fabrication of a bistable electronic display solely by means of printing. This system may satisfy the practical requirements of electronic paper.[7]

A second patent was filed by MIT for the microencapsulated electrophoretic display in March 1997.[8]

Subsequently, Albert, Comiskey and Jacobson along with Russ Wilcox and Jerome Rubin founded the E Ink Corporation in 1997, two months prior to Albert and Comiskey's graduation from MIT.[1]

https://en.wikipedia.org/wiki/E_Ink

## Electronics
**[`^        back to top        ^`](#)**

- **First while LED sold (1996)**

In the autumn of 1996, the first white light-emitting diodes (LEDs) were offered for sale.

https://onlinelibrary.wiley.com/doi/10.1002/lpor.201600147

## Energy
**[`^        back to top        ^`](#)**
## Telecommunications
**[`^        back to top        ^`](#)**
## Networking
**[`^        back to top        ^`](#)**
## Cryptography
**[`^        back to top        ^`](#)**
## Computers
**[`^        back to top        ^`](#)**
### Form factor
**[`^        back to top        ^`](#)**
### OS
**[`^        back to top        ^`](#)**
### Peripherals
**[`^        back to top        ^`](#)**
### Storage
**[`^        back to top        ^`](#)**



### Uses
**[`^        back to top        ^`](#)**


#### CGI

- **Pixar from hardware to 3D software to Toystory - first full-length 3D film (1995)**

In April 1990, Pixar sold its hardware division, including all proprietary hardware technology and imaging software, to Vicom Systems, and transferred 18 of Pixar's approximately 100 employees. That year, Pixar moved from San Rafael to Richmond, California.[33] Pixar released some of its software tools on the open market for Macintosh and Windows systems. RenderMan is one of the leading 3D packages of the early 1990s, and Typestry is a special-purpose 3D text renderer that competed with RayDream.[citation needed]

During this period, Pixar continued its successful relationship with Walt Disney Feature Animation, a studio whose corporate parent would ultimately become its most important partner. As 1991 began, however, the layoff of 30 employees in the company's computer hardware department—including the company's president, Chuck Kolstad,[34] reduced the total number of employees to just 42, approximately its original number.[35] Pixar made a historic $26 million deal with Disney to produce three computer-animated feature films, the first of which was Toy Story, the product of the technological limitations that challenged CGI.[36] By then the software programmers, who were doing RenderMan and IceMan, and Lasseter's animation department, which made television commercials (and four Luxo Jr. shorts for Sesame Street the same year), were all that remained of Pixar.[37]

Even with income from these projects, the company continued to lose money and Steve Jobs, as chairman of the board and now the full owner, often considered selling it. Even as late as 1994, Jobs contemplated selling Pixar to other companies such as Hallmark Cards, Microsoft co-founder Paul Allen, and Oracle CEO and co-founder Larry Ellison.[38] Only after learning from New York critics that Toy Story would probably be a hit—and confirming that Disney would distribute it for the 1995 Christmas season—did he decide to give Pixar another chance.[39][40] For the first time, he also took an active leadership role in the company and made himself CEO.[citation needed] Toy Story grossed more than $373 million worldwide[41] and, when Pixar held its initial public offering on November 29, 1995, it exceeded Netscape's as the biggest IPO of the year. In its first half-hour of trading, Pixar stock shot from $22 to $45, delaying trading because of unmatched buy orders. Shares climbed to US$49 and closed the day at $39.[42]

https://en.wikipedia.org/wiki/Pixar#Early_history

## Consumer Electronics
**[`^        back to top        ^`](#)**

### Gadgets
**[`^        back to top        ^`](#)**

- **Sophisticated calculators, TI, HP**

The two leading manufacturers, HP and TI, released increasingly feature-laden calculators during the 1980s and 1990s. At the turn of the millennium, the line between a graphing calculator and a handheld computer was not always clear, as some very advanced calculators such as the TI-89, the Voyage 200 and HP-49G could differentiate and integrate functions, solve differential equations, run word processing and PIM software, and connect by wire or IR to other calculators/computers.

https://en.wikipedia.org/wiki/Calculator

### Multimedia
**[`^        back to top        ^`](#)**

- **DVD (1996)**

The DVD (common abbreviation for Digital Video Disc or Digital Versatile Disc)[8][9] is a digital optical disc data storage format invented and developed in 1995 and released in late 1996. Currently allowing up to 17.08 GB of storage,[10] the medium can store any kind of digital data and was widely used for software and other computer files as well as video programs watched using DVD players. DVDs offer higher storage capacity than compact discs while having the same dimensions.

https://en.wikipedia.org/wiki/DVD

- **Toshiba SD-3000 - First DVD Player (1996)**

In November 1996, Toshiba introduced the world's first DVD player, the SD-3000, as a result of developments initiated in 1994. At the time, the VHS VCR was dominating the market.Further, the laser disk used analog video.

The DVD (called SD at the time) produced by Toshiba used digital audio and video could fit an entire movie on a disk the same size as a CD: 12 cm in diameter. This was a revolutionary standard that made possible high audio and video quality and multiple functions. I

https://toshiba-mirai-kagakukan.jp/en/learn/history/ichigoki/1996dvd/index.htm

### Screens
**[`^        back to top        ^`](#)**

- **XGA - Extended Graphics Array (1990) - IBM**

The Extended Graphics Array (XGA) is an IBM display standard introduced in 1990. Later it became the most common appellation of the **1024 × 768 pixels** display resolution, but the official definition is broader than that. It was not a new and improved replacement for Super VGA, but rather became one particular subset of the broad range of capabilities covered under the "Super VGA" umbrella.

https://en.wikipedia.org/wiki/Graphics_display_resolution#Extended_Graphics_Array

- **first CRT with HD resolution (1990) - Sony**

In 1990, the first CRTs with HD resolution were released to the market by Sony.[67]

In the mid-1990s, some 160 million CRTs were made per year.[68]

https://en.wikipedia.org/wiki/Cathode-ray_tube

- **large plasma flat-panel TV (1990s)**

In 1992, Fujitsu introduced the world's first 21-inch (53 cm) full-color display. It was based on technology created at the University of Illinois at Urbana–Champaign and NHK Science & Technology Research Laboratories.

In 1994, Weber demonstrated a color plasma display at an industry convention in San Jose. Panasonic Corporation began a joint development project with Plasmaco, which led in 1996 to the purchase of Plasmaco, its color AC technology, and its American factory for US$26 million.

In 1995, Fujitsu introduced the first 42-inch (107 cm) plasma display panel;[61][62] it had 852×480 resolution and was progressively scanned.[63] Two years later, Philips introduced the first large commercially available flat-panel TV, using the Fujitsu panels. It was available at four Sears locations in the US for $14,999, including in-home installation. Pioneer also began selling plasma televisions that year, and other manufacturers followed. By the year 2000 prices had dropped to $10,000.

https://en.wikipedia.org/wiki/Plasma_display

### Broadcast
**[`^        back to top        ^`](#)**

- **Europe: HDTV launch - Italy (1990)**

Between 1988 and 1991, several European organizations were working on discrete cosine transform (DCT) based digital video coding standards for both SDTV and HDTV. The EU 256 project by the CMTT and ETSI, along with research by Italian broadcaster RAI, developed a DCT video codec that broadcast near-studio-quality HDTV transmission at about 70–140 Mbit/s.[23][40] The first HDTV transmissions in Europe, albeit not direct-to-home, began in 1990, when RAI broadcast the 1990 FIFA World Cup using several experimental HDTV technologies, including the digital DCT-based EU 256 codec,[23] 

https://en.wikipedia.org/wiki/High-definition_television

- **Europe : DVB - Digital Video Broadcasting (1993-1997) : Satelitte, Cable, Terrestrial**

DVB-S and DVB-C were ratified in 1994. DVB-T was ratified in early 1997. The first commercial DVB-T broadcasts were performed by the United Kingdom's Digital TV Group in late 1998. In 2003 Berlin, Germany was the first area to completely stop broadcasting analog TV signals. Most European countries are fully covered by digital television and many have switched off PAL/SECAM services.
Digital Video Broadcasting (DVB) is a set of international open standards for digital television. DVB standards are maintained by the DVB Project, an international industry consortium,[1] and are published by a Joint Technical Committee (JTC) of the European Telecommunications Standardisé Institute (ETSI), European Committee for Electrotechnical Standardization (CENELEC) and European Broadcasting Union (EBU).
Satellite: DVB-S, DVB-S2, and DVB-SH
DVB-SMATV for distribution via SMATV
Cable: DVB-C, DVB-C2

https://en.wikipedia.org/wiki/Digital_Video_Broadcasting

DVB-T, short for Digital Video Broadcasting — Terrestrial, is the DVB European-based consortium standard for the broadcast transmission of digital terrestrial television that was first published in 1997[1] and first broadcast in Singapore in February, 1998.[2][3][4][5][6][7][8] This system transmits compressed digital audio, digital video and other data in an MPEG transport stream, using coded orthogonal frequency-division multiplexing (COFDM or OFDM) modulation. It is also the format widely used worldwide (including North America) for Electronic News Gathering for transmission of video and audio from a mobile newsgathering vehicle to a central receive point.

https://en.wikipedia.org/wiki/DVB-T

- **HDTV deployment start (1994)**

HDTV technology was introduced in the United States in the early 1990s and made official in 1993 by the Digital HDTV Grand Alliance, a group of television, electronic equipment, communications companies consisting of AT&T Bell Labs, General Instrument, Philips, Sarnoff, Thomson, Zenith and the Massachusetts Institute of Technology. Field testing of HDTV at 199 sites in the United States was completed August 14, 1994.[34] The first public HDTV broadcast in the United States occurred on July 23, 1996, when the Raleigh, North Carolina television station WRAL-HD began broadcasting from the existing tower of WRAL-TV southeast of Raleigh, winning a race to be first with the HD Model Station in Washington, D.C., which began broadcasting July 31, 1996 with the callsign WHD-TV, based out of the facilities of NBC owned and operated station WRC-TV.[35][36][37] The American Advanced Television Systems Committee (ATSC) HDTV system had its public launch on October 29, 1998, during the live coverage of astronaut John Glenn's return mission to space on board the Space Shuttle Discovery.[38] The signal was transmitted coast-to-coast, and was seen by the public in science centers, and other public theaters specially equipped to receive and display the broadcast.[38][39]

https://en.wikipedia.org/wiki/High-definition_television

- **USA : ATSC HDTV Standards (1996)**

Advanced Television Systems Committee (ATSC) standards are an American set of standards for digital television transmission over terrestrial, cable and satellite networks. It is largely a replacement for the analog NTSC standard and, like that standard, is used mostly in the United States, Mexico, Canada, and South Korea. Several former NTSC users, in particular Japan, have not used ATSC during their digital television transition, because they adopted their own system called ISDB.
The ATSC standards were developed in the early 1990s by the Grand Alliance, a consortium of electronics and telecommunications companies that assembled to develop a specification for what is now known as HDTV.
The high-definition television standards defined by the ATSC produce widescreen 16:9 images up to 1920×1080 pixels in size – more than six times the display resolution of the earlier standard. However, many different image sizes are also supported. The reduced bandwidth requirements of lower-resolution images allow up to six standard-definition "subchannels" to be broadcast on a single 6 MHz TV channel.
ATSC standards are marked A/x (x is the standard number) and can be downloaded for free from the ATSC's website at ATSC.org. ATSC Standard A/53, which implemented the system developed by the Grand Alliance, was published in 1995; the standard was adopted by the Federal Communications Commission in the United States in 1996. It was revised in 2009. ATSC Standard A/72 was approved in 2008 and introduces H.264/AVC video coding to the ATSC system.
ATSC supports 5.1-channel surround sound using Dolby Digital's AC-3 format. Numerous auxiliary datacasting services can also be provided.
Many aspects of ATSC are patented, including elements of the MPEG video coding, the AC-3 audio coding, and the 8VSB modulation.[2] The cost of patent licensing, estimated at up to $50 per digital TV receiver,[3] had prompted complaints by manufacturers.[4]
Companies with patents included : 
LG Electronics, Zenith Electronics, Panasonic, Samsung Electronics, Columbia University, Mitsubishi Electric, JVC Kenwood, Cisco Technology, Inc., Vientos Alisios Co., Ltd., Philips

https://en.wikipedia.org/wiki/ATSC_standards

- **Satelitte : Medium power satellites with smaller dishes - PrimeStar**

In the US in the early 1990s, four large cable companies launched PrimeStar, a direct broadcasting company using medium power satellites. The relatively strong transmissions allowed the use of smaller (90 cm) dishes. Its popularity declined with the 1994 launch of the Hughes DirecTV and Dish Network satellite television systems.
Digital satellite broadcasts began in 1994 in the United States through DirecTV using the DSS format. They were launched (with the DVB-S standard) in South Africa, Middle East, North Africa and Asia-Pacific in 1994 and 1995, and in 1996 and 1997 in European countries including France, Germany, Spain, Portugal, Italy and the Netherlands, as well as Japan, North America and Latin America. Digital DVB-S broadcasts in the United Kingdom and Ireland started in 1998. Japan started broadcasting with the ISDB-S standard in 2000.
On March 4, 1996, EchoStar introduced Digital Sky Highway (Dish Network) using the EchoStar 1 satellite.[80] EchoStar launched a second satellite in September 1996 to increase the number of channels available on Dish Network to 170.[80] These systems provided better pictures and stereo sound on 150–200 video and audio channels, and allowed small dishes to be used. This greatly reduced the popularity of TVRO systems. In the mid-1990s, channels began moving their broadcasts to digital television transmission using the DigiCipher conditional access system.[81]

https://en.wikipedia.org/wiki/Satellite_television

### Video games
**[`^        back to top        ^`](#)**

- **Renaissance of arcade (1990-1996)**
 
Fighting games like Street Fighter II (1991) and Mortal Kombat (1992) helped to revive it in the early 1990s, leading to a renaissance for the arcade industry.[22] 3D graphics were popularized in arcades during the early 1990s with games such as Sega's Virtua Racing and Virtua Fighter,[59] with later arcade systems such as the Sega Model 3 remaining considerably more advanced than home systems through the late 1990s.[60][61] However, the improved capabilities of home consoles and computers to mimic arcade video games during this time drew crowds away from arcades.[22]

https://en.wikipedia.org/wiki/Arcade_game#History

- **SNES - Super Nitendo (1990) - Nintendo - ROM, Cartridge**

The Super Nintendo Entertainment System (SNES),[b] commonly shortened to Super NES or Super Nintendo,[c] is a 16-bit home video game console developed by Nintendo that was released in 1990 in Japan and South Korea,[19] 1991 in North America, 1992 in Europe and Oceania, and 1993 in South America. In Japan, it is called the Super Famicom (SFC).[d] In South Korea, it is called the Super Comboy[e] and was distributed by Hyundai Electronics.[20] The system was released in Brazil on August 30, 1993,[19][21] by Playtronic. Although each version is essentially the same, several forms of regional lockout prevent cartridges for one version from being used in other versions.
The Super NES is Nintendo's second programmable home console, following the Nintendo Entertainment System (NES). The console introduced advanced graphics and sound capabilities compared with other systems at the time. It was designed to accommodate the ongoing development of a variety of enhancement chips integrated into game cartridges to be competitive into the next generation.

https://en.wikipedia.org/wiki/Super_Nintendo_Entertainment_System

- **Text-based multi-player virtual reality (MOO) (1990s)**

A MOO ("MUD, object-oriented"[1][2]) is a text-based online virtual reality system to which multiple users (players) are connected at the same time.

The term MOO is used in two distinct, but related, senses. One is to refer to those programs descended from the original MOO server, and the other is to refer to any MUD that uses object-oriented techniques to organize its database of objects, particularly if it does so in a similar fashion to the original MOO or its derivatives. Most of this article refers to the original MOO and its direct descendants, but see Non-Descendant MOOs for a list of MOO-like systems.

The original MOO server was authored by Stephen White, based on his experience from creating the programmable TinyMUCK system.[3][2] There was additional later development and maintenance from LambdaMOO founder, and former Xerox PARC employee, Pavel Curtis.

One of the most distinguishing features of a MOO is that its users can perform object-oriented programming within the server, ultimately expanding and changing how the server behaves to everyone.[4] Examples of such changes include authoring new rooms and objects, creating new generic objects for others to use, and changing the way the MOO interface operates. The programming language used for extension is the MOO programming language, and many MOOs feature convenient libraries of verbs that can be used by programmers in their coding known as Utilities. The MOO programming language is a domain-specific language.[citation needed]

https://en.wikipedia.org/wiki/MOO

LambdaMOO is an online community[1] of the variety called a MOO. It is the oldest MOO today.[citation needed]

LambdaMOO was founded in 1990 by Pavel Curtis at Xerox PARC.[2][3][4][5] Now hosted in the state of Washington, it is operated and administered entirely on a volunteer basis. Guests are allowed, and membership is free to anyone with an e-mail address.

LambdaMOO gained some notoriety when Julian Dibbell wrote a book called My Tiny Life describing his experiences there.[6] Over its history, LambdaMOO has been highly influential in the examination of virtual-world social issues.[2]

https://en.wikipedia.org/wiki/LambdaMOO

- **Consoles surpasses arcade (1997-1998)**

Up until about 1996, arcade video games had remained the largest sector of the global video game industry, before arcades declined in the late 1990s, with the console market surpassing arcade video games for the first time around 1997–1998.[62

https://en.wikipedia.org/wiki/Arcade_game#History

- **32/64 bits game consoles - Fifth generation video games consoles (1993-2006)**

The fifth-generation era (also known as the 32-bit era, the 64-bit era, or the 3D era) refers to computer and video games, video game consoles, and handheld gaming consoles dating from approximately October 4, 1993 to March 23, 2006.[note 1] For home consoles, the best-selling console was the **Sony PlayStation**, followed by the **Nintendo 64**, and then the **Sega Saturn**. The PlayStation also had a redesigned version, the PSone, which was launched on July 7, 2000.

Some features that distinguished fifth generation consoles from previous fourth generation consoles include:
- 3D polygon graphics with texture mapping
- 3D graphics capabilities – lighting, Gouraud shading, anti-aliasing and texture filtering
- Optical disc (CD-ROM) game storage, allowing much larger storage space (up to 650 MB) than ROM cartridges
- CD quality audio recordings (music and speech) – PCM audio with 16-bit depth and 44.1 kHz sampling rate
- Wide adoption of full motion video, displaying pre-rendered computer animation or live action footage
- Analog controllers
- Display resolutions from 480i/480p to 576i
- Color depth up to 16,777,216 colors (24-bit true color)

https://en.wikipedia.org/wiki/Fifth_generation_of_video_game_consoles

- **Sony PlayStation - First console to ship over 100 million units (1994) - Sony**

PlayStation (Japanese: プレイステーション, Hepburn: Pureisutēshon, officially abbreviated as PS) is a video game brand that consists of five home video game consoles, two handhelds, a media center, and a smartphone, as well as an online service and multiple magazines. The brand is produced by Sony Interactive Entertainment, a division of Sony; the first PlayStation console was released in Japan in December 1994, and worldwide the following year.[1]
The original console in the series was the first console of any type to ship over 100 million units, doing so in under a decade.[2]

https://en.wikipedia.org/wiki/PlayStation

Sony began developing the standalone PlayStation after a failed venture with Nintendo to create a CD-ROM peripheral for the Super Nintendo Entertainment System in the early 1990s. The console was primarily designed by Ken Kutaragi and Sony Computer Entertainment in Japan, while additional development was outsourced in the United Kingdom. An emphasis on 3D polygon graphics was placed at the forefront of the console's design. PlayStation game production was designed to be streamlined and inclusive, enticing the support of many third-party developers.

The console proved popular for its extensive game library, popular franchises, low retail price, and aggressive youth marketing which advertised it as the preferable console for adolescents and adults. Premier PlayStation franchises included Gran Turismo, Crash Bandicoot, Tomb Raider, and Final Fantasy, all of which spawned numerous sequels. PlayStation games continued to sell until Sony ceased production of the PlayStation and its games on 23 March 2006—over eleven years after it had been released, and less than a year before the debut of the PlayStation 3.[8] A total of 3,061 PlayStation games were released, with cumulative sales of 967 million units.

SCE was an upstart in the video game industry in late 1994, as the video game market in the early 1990s was dominated by Nintendo and Sega. Nintendo had been the clear leader in the industry since the introduction of the Nintendo Entertainment System in 1985 and the Nintendo 64 was initially expected to maintain this position. The PlayStation's target audience included the generation which was the first to grow up with mainstream video games, along with 18- to 29-year-olds who were not the primary focus of Nintendo.[202] By the late 1990s, Sony became a highly regarded console brand due to the PlayStation, with a significant lead over second-place Nintendo, while Sega was relegated to a distant third.[203]

The PlayStation became the first "computer entertainment platform" to ship over 100 million units worldwide,[6][204] with many critics attributing the console's success to third-party developers.[76] It remains the fifth best-selling console of all time as of 2022, with a total of 102.49 million units sold.[204] Around 7,900 individual games were published for the console during its 11-year life span, the second-most amount of games ever produced for a console.[6] Its success resulted in a significant financial boon for Sony as profits from its video game division contributed to 23%.[205]

The success of the PlayStation contributed to the demise of cartridge-based home consoles. While not the first system to use an optical disc format, it was the first highly successful one, and ended up going head-to-head with the proprietary cartridge-relying Nintendo 64.[c][207] After the demise of the Sega Saturn, Nintendo was left as Sony's main competitor in Western markets. Nintendo chose not to use CDs for the Nintendo 64; it was likely concerned with the proprietary cartridge format's ability to help enforce copy protection, given its substantial reliance on licensing and exclusive games for its revenue.

https://en.wikipedia.org/wiki/PlayStation_(console)

## Standards and protocols
**[`^        back to top        ^`](#)**

## Some standards and protocols
**[`^        back to top        ^`](#)**

### Physical layer

- **Classic Ethernet (1990-1993)**

  * 802.3i	10BASE-T (1990) : 10 Mbit/s (1.25 MB/s) over twisted pair https://en.wikipedia.org/wiki/IEEE_802.3
  * 10BASEFL (1993) : 10BASE-F specification of Ethernet over optical fiber 
 
https://en.wikipedia.org/wiki/Classic_Ethernet

- **Fast Ethernet (1995-1998)**
  * 802.3u	-	100BASE-TX, 100BASE-T4, 100BASE-FX (1995) : Fast Ethernet at 100 Mbit/s (12.5 MB/s) with autonegotiation 

https://en.wikipedia.org/wiki/Fast_Ethernet

- **Gigabit Ethernet (1998-1999)**
  * 802.3z	- 1000BASE-X Gbit/s (1998): Ethernet over optical fiber at 1 Gbit/s (125 MB/s) 
  * 802.3ab	- 1000BASE-T Gbit/s (1999): Ethernet over twisted pair at 1 Gbit/s (125 MB/s)

https://en.wikipedia.org/wiki/Gigabit_Ethernet

- **Modem speeds : 14.4k to 56k**
  
  * V.32bis 14.4k bps; QAM (1991)
  * V.34 28.8k bps; QAM (1994) AKA V.fast
  * V.34bis 33.6k bps; QAM (1996)
  * V.90 56k bps; Modulus Conversion downstream, QAM upstream (1998)
  * V.92 56k bps; Modulus conversion in both directions (2000)

https://tldp.org/HOWTO/Modem-HOWTO-29.html

### Link layer

- **ATM - Asynchronous Transfer Mode**

Asynchronous Transfer Mode (ATM) is a telecommunications standard defined by American National Standards Institute (ANSI) and ITU-T (formerly CCITT) for digital transmission of multiple types of traffic. ATM was developed to meet the needs of the Broadband Integrated Services Digital Network as defined in the late 1980s,[1] and designed to integrate telecommunication networks. It can handle both traditional high-throughput data traffic and real-time, low-latency content such as telephony (voice) and video.[2][3] ATM provides functionality that uses features of circuit switching and packet switching networks by using asynchronous time-division multiplexing.[4][5]

In the OSI reference model data link layer (layer 2), the basic transfer units are called frames. In ATM these frames are of a fixed length (53 octets) called cells. This differs from approaches such as IP or Ethernet that use variable-sized packets or frames. ATM uses a connection-oriented model in which a virtual circuit must be established between two endpoints before the data exchange begins.[5] These virtual circuits may be either permanent (dedicated connections that are usually preconfigured by the service provider), or switched (set up on a per-call basis using signaling and disconnected when the call is terminated).

The ATM network reference model approximately maps to the three lowest layers of the OSI model: physical layer, data link layer, and network layer.[6] ATM is a core protocol used in the SONET/SDH backbone of the public switched telephone network (PSTN) and in the Integrated Services Digital Network (ISDN) but has largely been superseded in favor of next-generation networks based on Internet Protocol (IP) technology. Wireless and mobile ATM never established a significant foothold.

ATM became popular with telephone companies and many computer makers in the 1990s. However, even by the end of the decade, the better price/performance of Internet Protocol-based products was competing with ATM technology for integrating real-time and bursty network traffic.[17] Companies such as FORE Systems focused on ATM products, while other large vendors such as Cisco Systems provided ATM as an option

https://en.wikipedia.org/wiki/Asynchronous_Transfer_Mode

- **Frame Relay protocols (1993-1998)**

  * RFC 1490 – Multiprotocol Interconnect over Frame Relay (1993) https://datatracker.ietf.org/doc/html/rfc1490
  * RFC 1973 – PPP in Frame Relay (1996) https://datatracker.ietf.org/doc/html/rfc1973
  * RFC 2427 – Multiprotocol Interconnect over Frame Relay (1998) https://datatracker.ietf.org/doc/html/rfc2427

https://en.wikipedia.org/wiki/Frame_Relay

### Network layer

- **IPv6 - Internet Protocol version 6 (1995)**

most recent version of the Internet Protocol (IP), the communications protocol that provides an identification and location system for computers on networks and routes traffic across the Internet. 
Introduced in 1995, IPv6 was developed by the Internet Engineering Task Force (IETF) to deal with the long-anticipated problem of IPv4 address exhaustion, and is intended to replace IPv4.
In December 1998, IPv6 became a Draft Standard for the IETF, which subsequently ratified it as an Internet Standard on 14 July 2017.
Deployment was slowed by the widespread use of NAT (1999).

https://en.wikipedia.org/wiki/IPv6

- **NAT - Network address translation (1999)** : a method of mapping an IP address space into another by modifying network address information in the IP header of packets while they are in transit across a traffic routing device.
Popular with the exhaustion of IPv4 addresses and home routers. Essential to networking. 
https://en.wikipedia.org/wiki/Network_address_translation

### Transport layer

- **SSL - Secure Socket Layer (1995-1998)**

Netscape developed the original SSL protocols, and Taher Elgamal, chief scientist at Netscape Communications from 1995 to 1998. Superseded by TLS.

https://en.wikipedia.org/wiki/Transport_Layer_Security

- **TLS - Transport Layer Security (1999)** 

A cryptographic protocol designed to provide communications security over a computer network. The protocol is widely used 
in applications such as email, instant messaging, and voice over IP, but its use in securing HTTPS remains the most publicly visible.
Essential to networking and the internet.
https://en.wikipedia.org/wiki/Transport_Layer_Security

- **PPTP - Point-to-Point Tunneling Protocol (1999) - Microsoft**

The Point-to-Point Tunneling Protocol (PPTP) is an obsolete method for implementing virtual private networks. PPTP has many well known security issues.

PPTP uses a TCP control channel and a Generic Routing Encapsulation tunnel to encapsulate PPP packets. Many modern VPNs use various forms of UDP for this same functionality.

The PPTP specification does not describe encryption or authentication features and relies on the Point-to-Point Protocol being tunneled to implement any and all security functionalities.

The PPTP implementation that ships with the Microsoft Windows product families implements various levels of authentication and encryption natively as standard features of the Windows PPTP stack. The intended use of this protocol is to provide security levels and remote access levels comparable with typical VPN products.

https://en.wikipedia.org/wiki/Point-to-Point_Tunneling_Protocol

### Session layer

- **SOCKS - SOCKS4 (1992) - SOCKS5 (1996)**

SOCKS is a de facto standard for circuit-level gateways (level 5 gateways).[6]

The circuit/session level nature of SOCKS make it a versatile tool in forwarding any TCP (or UDP since SOCKS5) traffic, creating an interface for all types of routing tools. It can be used as:

A circumvention tool, allowing traffic to bypass Internet filtering to access content otherwise blocked, e.g., by governments, workplaces, schools, and country-specific web services.[7] Since SOCKS is very detectable, a common approach is to present a SOCKS interface for more sophisticated protocols:
The Tor onion proxy software presents a SOCKS interface to its clients.[8]

Providing similar functionality to a virtual private network, allowing connections to be forwarded to a server's "local" network:
Some SSH suites, such as OpenSSH, support dynamic port forwarding that allows the user to create a local SOCKS proxy.[9] This can free the user from the limitations of connecting only to a predefined remote port and server.

The protocol was originally developed/designed by David Koblas, a system administrator of MIPS Computer Systems. After MIPS was taken over by Silicon Graphics in 1992, Koblas presented a paper on SOCKS at that year's Usenix Security Symposium,[2] making SOCKS publicly available.[3] The protocol was extended to version 4 by Ying-Da Lee of NEC.

The SOCKS reference architecture and client are owned by Permeo Technologies,[4] a spin-off from NEC. (Blue Coat Systems bought out Permeo Technologies, and were in turn acquired by Symantec.)

The SOCKS5 protocol was originally a security protocol that made firewalls and other security products easier to administer. It was approved by the IETF in 1996 as RFC 1928 (authored by: M. Leech, M. Ganis, Y. Lee, R. Kuris, D. Koblas, and L. Jones). The protocol was developed in collaboration with Aventail Corporation, which markets the technology outside of Asia.[5]

https://en.wikipedia.org/wiki/SOCKS

### Application layer

- **HTTP/0.9 - Hypertext Transfer Protocol (1991)**

application layer protocol in the Internet protocol suite model for distributed, collaborative, hypermedia information systems. Essential to the internet.

https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol

- **DHCP - Dynamic Host Configuration Protocol (1991)** 

A network management protocol used on Internet Protocol (IP) networks for automatically assigning IP addresses and other communication parameters to devices connected to the network using a client–server architecture.
Essential to networking.

https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol

- **RADIUS (1991)**

Remote Authentication Dial-In User Service (RADIUS) is a networking protocol that provides centralized authentication, authorization, and accounting (AAA) management for users who connect and use a network service. RADIUS was developed by Livingston Enterprises in 1991 as an access server authentication and accounting protocol. It was later brought into IEEE 802 and IETF standards.

RADIUS is a client/server protocol that runs in the application layer, and can use either TCP or UDP. Network access servers, which control access to a network, usually contain a RADIUS client component that communicates with the RADIUS server.[1] RADIUS is often the back-end of choice for 802.1X authentication.[2] A RADIUS server is usually a background process running on UNIX or Microsoft Windows.[1]
As more dial-up customers used the NSFNET a request for proposal was sent out by Merit Network in 1991 to consolidate their various proprietary authentication, authorization and accounting systems. Among the early respondents was Livingston Enterprises and an early version of the RADIUS was written after a meeting. The early RADIUS server was installed on a UNIX operating system. Livingston Enterprises was acquired by Lucent and together with Merit steps were taken to gain industry acceptance for RADIUS as a protocol. Both companies offered a RADIUS server at no charge.[11] In 1997 RADIUS was published as RFC 2058 and RFC 2059, current versions are RFC 2865 and RFC 2866.[12]

https://en.wikipedia.org/wiki/RADIUS

- **LDAP (1993)**

The Lightweight Directory Access Protocol (LDAP /ˈɛldæp/) is an open, vendor-neutral, industry standard application protocol for accessing and maintaining distributed directory information services over an Internet Protocol (IP) network.[1] Directory services play an important role in developing intranet and Internet applications by allowing the sharing of information about users, systems, networks, services, and applications throughout the network.[2] As examples, directory services may provide any organized set of records, often with a hierarchical structure, such as a corporate email directory. Similarly, a telephone directory is a list of subscribers with an address and a phone number.
LDAP is specified in a series of Internet Engineering Task Force (IETF) Standard Track publications called Request for Comments (RFCs), using the description language ASN.1. The latest specification is Version 3, published as RFC 4511[3] (a road map to the technical specifications is provided by RFC4510).
A common use of LDAP is to provide a central place to store usernames and passwords. This allows many different applications and services to connect to the LDAP server to validate users.[4]
LDAP is based on a simpler subset of the standards contained within the X.500 standard. Because of this relationship, LDAP is sometimes called X.500-lite.[5]
The protocol was originally created[7] by Tim Howes of the University of Michigan, Steve Kille of Isode Limited, Colin Robbins of Nexor and Wengyik Yeong of Performance Systems International, circa 1993, as a successor[8] to DIXIE and DAS. Mark Wahl of Critical Angle Inc., Tim Howes, and Steve Kille started work in 1996 on a new version of LDAP, LDAPv3, under the aegis of the Internet Engineering Task Force (IETF). LDAPv3, first published in 1997, superseded LDAPv2 and added support for extensibility, integrated the Simple Authentication and Security Layer, and better aligned the protocol to the 1993 edition of X.500. Further development of the LDAPv3 specifications themselves and of numerous extensions adding features to LDAPv3 has come through the IETF.

https://en.wikipedia.org/wiki/Lightweight_Directory_Access_Protocol

### Data transmission

#### Text

- **HTML (1990-1991) - HyperText Markup Language**

In 1980, physicist Tim Berners-Lee, a contractor at CERN, proposed and prototyped ENQUIRE, a system for CERN researchers to use and share documents. In 1989, Berners-Lee wrote a memo proposing an Internet-based hypertext system.[3] Berners-Lee specified HTML and wrote the browser and server software in late 1990. 
The first publicly available description of HTML was a document called "HTML Tags", first mentioned on the Internet by Tim Berners-Lee in late 1991.

https://en.wikipedia.org/wiki/HTML

- **URL (1992-1994) - Uniform Resource Locators**

Uniform Resource Locators were defined in RFC 1738 in 1994 by Tim Berners-Lee, the inventor of the World Wide Web, and the URI working group of the Internet Engineering Task Force (IETF),[7] as an outcome of collaboration started at the IETF Living Documents birds of a feather session in 1992.[7][8]

https://en.wikipedia.org/wiki/URL

#### Images

- **WMF - Windows Metafile, SVG ancestor (1991) - Microsoft**

Long before the invention of Scalable Vector Graphics, Microsoft Corporation recognized the value of recording images in a format that its applications and operating systems could easily render irrespective of the output device.  With the release of Windows 3.0, Microsoft released its Windows Metafile (WMF) format, which can contain vector and raster graphics in one package.  

https://datatracker.ietf.org/doc/html/rfc7903

- **JPEG (1992)**

Picture compression format.

https://en.wikipedia.org/wiki/JPEG

- **PNG (1997)** 

Portable Network Graphics (PNG, officially pronounced /pɪŋ/[2][3] PING, colloquially pronounced /ˌpiːɛnˈdʒiː/[4] PEE-en-JEE) is a raster-graphics file format that supports lossless data compression.
PNG was published as informational RFC 2083 in March 1997 and as an ISO/IEC 15948 standard in 2004

https://en.wikipedia.org/wiki/Portable_Network_Graphics

#### Music and Video

- **RIFF - Resource Interchange File Format (1991) - Microsoft and IBM**

The Resource Interchange File Format (RIFF) is a generic file container format for storing data in tagged chunks.[2] It is primarily used to store multimedia such as sound and video, though it may also be used to store any arbitrary data.[3]
The Microsoft implementation is mostly known through container formats like AVI, ANI and WAV, which use RIFF as their basis.[4]
RIFF was introduced in 1991 by Microsoft and IBM, and was presented by Microsoft as the default format for Windows 3.1 multimedia files. It is based on Electronic Arts' Interchange File Format, introduced in 1985 on the Commodore Amiga, the only difference being that multi-byte integers are in little-endian format, native to the 80x86 processor series used in IBM PCs, rather than the big-endian format native to the 68k processor series used in Amiga and Apple Macintosh computers, where IFF files were heavily used. A RIFX format, which is big-endian, was also introduced.

https://en.wikipedia.org/wiki/Resource_Interchange_File_Format

- **Quicktime (1991-2018) - Apple**

QuickTime is an extensible multimedia framework developed by Apple Inc., capable of handling various formats of digital video, picture, sound, panoramic images, and interactivity. Created in 1991, the latest Mac version, QuickTime X, is available for Mac OS X Snow Leopard up to macOS Mojave. Apple ceased support for the Windows version of QuickTime in 2016, and ceased support for QuickTime 7 on macOS in 2018

Apple released the first version of QuickTime on December 2, 1991 as a multimedia add-on for System 6 and later. The lead developer of QuickTime, Bruce Leak, ran the first public demonstration at the May 1991 Worldwide Developers Conference, where he played Apple's famous 1984 advertisement in a window at 320×240 pixels resolution.

QuickTime 1.x

The original video codecs included:
  * the Animation codec, which used run-length encoding and was better suited to cartoon-type images with large areas of flat color
  * the Apple Video codec (also known as "Road Pizza"), suited to normal live-action video.[32]
  * the Graphics codec, for 8-bit images, including ones that had undergone dithering
The first commercial project produced using QuickTime 1.0 was the CD-ROM From Alice to Ocean. The first publicly visible use of QuickTime was Ben & Jerry's interactive factory tour (dubbed The Rik & Joe Show after its in-house developers). The Rik and Joe Show was demonstrated onstage at MacWorld in San Francisco when John Sculley announced QuickTime.[33]

Apple released QuickTime 1.5 for Mac OS in the latter part of 1992. This added the SuperMac-developed Cinepak vector-quantization video codec (initially known as Compact Video). It could play video at 320×240 resolution at 30 frames per second on a 25 MHz Motorola 68040 CPU. It also added text tracks, which allowed for captioning, lyrics and other potential uses.

It was followed by several version (up to version 7 and X) in the 2000s and 2010s.

https://en.wikipedia.org/wiki/QuickTime


- **WAV - Uncompressed sound format (1991) - Microsoft and IBM**

Waveform Audio File Format[3] (WAVE,[3] or WAV due to its filename extension;[3][6][7] pronounced "wave"[8]) is an audio file format standard, developed by IBM and Microsoft, for storing an audio bitstream on PCs. It is the main format used on Microsoft Windows systems for uncompressed audio. The usual bitstream encoding is the linear pulse-code modulation (LPCM) format.
WAV is an application of the Resource Interchange File Format (RIFF) bitstream format method for storing data in chunks, and thus is similar to the 8SVX and the AIFF format used on Amiga and Macintosh computers, respectively.
August 1991

https://en.wikipedia.org/wiki/WAV

- **AVI - Audio Video Interleave (1992) - Microsoft**

Audio Video Interleave (also Audio Video Interleaved and known by its initials and filename extension AVI, usually pronounced /ˌeɪ.viːˈaɪ/[3]), is a proprietary multimedia container format and Windows standard[4] introduced by Microsoft in November 1992 as part of its Video for Windows software. AVI files can contain both audio and video data in a file container that allows synchronous audio-with-video playback. Like the DVD video format, AVI files support multiple streaming audio and video, although these features are seldom used.

https://en.wikipedia.org/wiki/Audio_Video_Interleave

- **MP3 (1993)**

MP3 (formally MPEG-1 Audio Layer III or MPEG-2 Audio Layer III)[4] is a coding format for digital audio developed largely by the Fraunhofer Society in Germany, with support from other digital scientists in the United States and elsewhere. Originally defined as the third audio format of the MPEG-1 standard, it was retained and further extended — defining additional bit-rates and support for more audio channels — as the third audio format of the subsequent MPEG-2 standard. A third version, known as MPEG 2.5 — extended to better support lower bit rates — is commonly implemented, but is not a recognized standard.
On 7 July 1994, the Fraunhofer Society released the first software MP3 encoder, called l3enc.[59] The filename extension .mp3 was chosen by the Fraunhofer team on 14 July 1995 (previously, the files had been named .bit).[1] With the first real-time software MP3 player WinPlay3 (released 9 September 1995) many people were able to encode and play back MP3 files on their PCs. Because of the relatively small hard drives of the era (≈500–1000 MB) lossy compression was essential to store multiple albums' worth of music on a home computer as full recordings (as opposed to MIDI notation, or tracker files which combined notation with short recordings of instruments playing single notes).

https://en.wikipedia.org/wiki/MP3

#### File compression

- **DEFLATE (1993-1996)**

In computing, Deflate (stylized as DEFLATE) is a lossless data compression file format that uses a combination of LZ77 and Huffman coding. It was designed by Phil Katz, for version 2 of his PKZIP archiving tool. Deflate was later specified in RFC 1951 (1996).[1]

Katz also designed the original algorithm used to construct Deflate streams. This algorithm was patented as U.S. Patent 5,051,745, and assigned to PKWARE, Inc.[2][3] As stated in the RFC document, an algorithm producing Deflate files was widely thought to be implementable in a manner not covered by patents.[1] This led to its widespread use – for example, in gzip compressed files and PNG image files, in addition to the ZIP file format for which Katz originally designed it. The patent has since expired.

https://en.wikipedia.org/wiki/Deflate

- **Winzip - Popular ZIP Gui on Windows (1991)** 

WinZip is a trialware file archiver and compressor for Windows, macOS, iOS and Android. It is developed by WinZip Computing (formerly Nico Mak Computing), which is owned by Corel Corporation. The program can create archives in Zip file format, unpack some other archive file formats and it also has various tools for system integration.

WinZip 1.0 was released in April 1991 as a Graphical User Interface (GUI) front-end for PKZI.

https://en.wikipedia.org/wiki/WinZip

- **ARJ (1993)**

ARJ (Archived by Robert Jung) is a software tool designed by Robert K. Jung for creating high-efficiency compressed file archives. ARJ is currently on version 2.86 for MS-DOS and 3.20 for Microsoft Windows and supports 16-bit, 32-bit and 64-bit Intel architectures.[1]

ARJ was one of many file compression utilities for MS-DOS and Microsoft Windows during the early and mid-1990s. Parts of ARJ were covered by U.S. Patent 5,140,321 (expired). ARJ is well-documented and includes over 150 command line switches.

https://en.wikipedia.org/wiki/ARJ

- **RAR (1993)**

RAR is a proprietary archive file format that supports data compression, error correction and file spanning.[3] It was developed in 1993 by Russian software engineer Eugene Roshal and the software is licensed by win.rar GmbH.[3] The name RAR stands for Roshal Archive.

https://en.wikipedia.org/wiki/RAR_(file_format)

- **7ZIP - 7z file format, ZIP improvement (1999) - Igor Pavlov**

7-Zip is a free and open-source file archiver, a utility used to place groups of files within compressed containers known as "archives". It is developed by Igor Pavlov and was first released in 1999.[2] 7-Zip has its own archive format called 7z, but can read and write several others.

By default, 7-Zip creates 7z-format archives with a .7z file extension.

In 2011, TopTenReviews found that the 7z compression was at least 17% better than ZIP,[17] and 7-Zip's own site has since 2002 reported that while compression ratio results are very dependent upon the data used for the tests, "Usually, 7-Zip compresses to 7z format 30–70% better than to zip format, and 7-Zip compresses to zip format 2–10% better than most other zip-compatible programs."[18

https://en.wikipedia.org/wiki/7-Zip

#### Voice over IP

- **SIP - Session Initiation Protocol (1996)** 

Signaling protocol used for initiating, maintaining, and terminating communication sessions that include voice, video and messaging applications. 
SIP is used in **Internet telephony**, in private IP telephone systems, as well as mobile phone calling over LTE (**VoLTE**). Essential to telecommunications.

https://en.wikipedia.org/wiki/Session_Initiation_Protocol

#### Video over IP

- **MPEG-1 (1993)**

Since 1972, International Telecommunication Union's radio telecommunications sector (ITU-R) had been working on creating a global recommendation for Analog HDTV. These recommendations, however, did not fit in the broadcasting bands which could reach home users. The standardization of MPEG-1 in 1993 led to the acceptance of recommendations ITU-R BT.709

https://en.wikipedia.org/wiki/High-definition_television

- **MPEG-2 (1995)**

MPEG-2 evolved out of the shortcomings of MPEG-1.
MPEG-1's known weaknesses:
An audio compression system limited to two channels (stereo).
No standardized support for interlaced video with poor compression when used for interlaced video
Only one standardized "profile" (Constrained Parameters Bitstream), which was unsuited for higher resolution video. MPEG-1 could support 4k video but there was no easy way to encode video for higher resolutions, and identify hardware capable of supporting it, as the limitations of such hardware were not defined.
Support for only one chroma subsampling, 4:2:0.
Sakae Okubo of NTT was the ITU-T coordinator for developing the H.262/MPEG-2 Part 2 video coding standard and the requirements chairman in MPEG for the MPEG-2 set of standards.[27] The majority of patents underlying MPEG-2 technology are owned by three companies: Sony (311 patents), Thomson (198 patents) and Mitsubishi Electric (119 patents).[28] Hyundai Electronics (now SK Hynix) developed the first MPEG-2 SAVI (System/Audio/Video) decoder in 1995.[29]

https://en.wikipedia.org/wiki/MPEG-2

- **H.323 (1996)** 

Recommendation from the ITU Telecommunication Standardization Sector (ITU-T) that defines the protocols to provide audio-visual communication sessions on any packet network.[1] The H.323 standard addresses call signaling and control, multimedia transport and control, and bandwidth control for point-to-point and multi-point conferences.[2]
It is widely implemented[3] by **voice and videoconferencing equipment manufacturers**, is used within various **Internet real-time applications** such as GnuGK and NetMeeting and is widely deployed worldwide by service providers and enterprises for both voice and video services over IP networks.

https://en.wikipedia.org/wiki/H.323

- **H.263 (1996)**

The H.263 standard was first designed to be utilized in H.324 based systems (PSTN and other **circuit-switched network videoconferencing and videotelephony)**, but it also found use in H.323 (RTP/IP-based videoconferencing), H.320 (ISDN-based videoconferencing, where it became the most widely used video compression standard),[4] RTSP (streaming media) and SIP (IP-based videoconferencing) solutions.

https://en.wikipedia.org/wiki/H.263

#### Instant messaging

- **XMPP (1999)**
 
Open communication protocol designed for **instant messaging (IM), presence information, and contact list maintenance**. enables the near-real-time exchange of structured data between two or more network entities. Widely in use.

https://en.wikipedia.org/wiki/XMPP

#### Machine-to-machine

- **CORBA - Common Object Request Broker Architecture (1991)**

The Common Object Request Broker Architecture (CORBA) is a standard defined by the Object Management Group (OMG) designed to facilitate the communication of systems that are deployed on diverse platforms. CORBA enables collaboration between systems on different operating systems, programming languages, and computing hardware. CORBA uses an object-oriented model although the systems that use the CORBA do not have to be object-oriented. CORBA is an example of the distributed object paradigm.

CORBA enables communication between software written in different languages and running on different computers. Implementation details from specific operating systems, programming languages, and hardware platforms are all removed from the responsibility of developers who use CORBA. CORBA normalizes the method-call semantics between application objects residing either in the same address-space (application) or in remote address-spaces (same host, or remote host on a network). Version 1.0 was released in October 1991.

https://en.wikipedia.org/wiki/Common_Object_Request_Broker_Architecture

- **XML (1998) - Extensible Markup Language**

A markup language and file format for storing, transmitting, and reconstructing arbitrary data. It defines a set of rules for encoding documents in a format that is both human-readable and machine-readable. The World Wide Web Consortium's XML 1.0 Specification[2] of 1998[3] and several other related specifications[4]—all of them free open standards—define XML.[5]

https://en.wikipedia.org/wiki/XML

- **MQTT (1999)**

Lightweight, **publish-subscribe, machine to machine network protocol**. It is designed for connections with remote locations that have devices with resource constraints or limited network bandwidth. Widely in use.

https://en.wikipedia.org/wiki/MQTT

#### Files

- **CIFS (1996) - Microsoft**

In 1996, Microsoft published a version of SMB 1.0[4] with minor modifications under the Common Internet File System (CIFS /sɪfs/) moniker. CIFS was compatible with even the earliest incarnation of SMB, including LAN Manager's.[4] It supports symbolic links, hard links, and larger file size, but none of the features of SMB 2.0 and later.[4][5] Microsoft's proposal, however, remained an Internet Draft and never achieved standard status.[6] Microsoft has since discontinued use of the CIFS moniker but continues developing SMB and making subsequent specifications publicly available.

https://en.wikipedia.org/wiki/Server_Message_Block

- **Rsync (1999)**

Utility for **efficiently transferring and synchronizing files** between a computer and a storage drive and across networked computers by comparing the modification times and sizes of files. Detailed in the creator's PhD Thesis.

https://en.wikipedia.org/wiki/Rsync

#### Remote access
- **SSH - Secure Shell (1995): remote login and command-line execution**

The Secure Shell Protocol (SSH) is a cryptographic network protocol for operating network services securely over an unsecured network.[1] Its most notable applications are remote login and command-line execution.
SSH applications are based on a client–server architecture, connecting an SSH client instance with an SSH server
SSH was first designed in 1995 by Finnish computer scientist Tatu Ylönen. Subsequent development of the protocol suite proceeded in several developer groups, producing several variants of implementation. The protocol specification distinguishes two major versions, referred to as SSH-1 and SSH-2. The most commonly implemented software stack is **OpenSSH**, released in **1999** as open-source software by the OpenBSD developers. 

https://en.wikipedia.org/wiki/Secure_Shell

- **VNC - Virtual Network Computing (1999)** 

**Remote desktop protocol**. Still widely used. Insecure (not encrypted by default).

https://en.wikipedia.org/wiki/Virtual_Network_Computing

## Programming languages and frameworks
**[`^        back to top        ^`](#)**

- **OpenGL (1991) - Silicon Graphics**

OpenGL (Open Graphics Library[3]) is a cross-language, cross-platform application programming interface (API) for rendering 2D and 3D vector graphics. The API is typically used to interact with a graphics processing unit (GPU), to achieve hardware-accelerated rendering.

Silicon Graphics, Inc. (SGI) began developing OpenGL in 1991 and released it on June 30, 1992;[4][5] applications use it extensively in the fields of computer-aided design (CAD), virtual reality, scientific visualization, information visualization, flight simulation, and video games. Since 2006, OpenGL has been managed by the non-profit technology consortium Khronos Group.[6]

https://en.wikipedia.org/wiki/OpenGL

- **DirectX (1995)**

Microsoft DirectX is a collection of application programming interfaces (APIs) for handling tasks related to multimedia, especially game programming and video, on Microsoft platforms. Originally, the names of these APIs all began with "Direct", such as Direct3D, DirectDraw, DirectMusic, DirectPlay, DirectSound, and so forth. The name DirectX was coined as a shorthand term for all of these APIs (the X standing in for the particular API names) and soon became the name of the collection. When Microsoft later set out to develop a gaming console, the X was used as the basis of the name Xbox to indicate that the console was based on DirectX technology.[3] The X initial has been carried forward in the naming of APIs designed for the Xbox such as XInput and the Cross-platform Audio Creation Tool (XACT), while the DirectX pattern has been continued for Windows APIs such as Direct2D and DirectWrite.

Direct3D (the 3D graphics API within DirectX) is widely used in the development of video games for Microsoft Windows and the Xbox line of consoles. Direct3D is also used by other software applications for visualization and graphics tasks such as CAD/CAM engineering. As Direct3D is the most widely publicized component of DirectX, it is common to see the names "DirectX" and "Direct3D" used interchangeably.

The DirectX software development kit (SDK) consists of runtime libraries in redistributable binary form, along with accompanying documentation and headers for use in coding. Originally, the runtimes were only installed by games or explicitly by the user. Windows 95 did not launch with DirectX, but DirectX was included with Windows 95 OEM Service Release 2.[4] Windows 98 and Windows NT 4.0 both shipped with DirectX, as has every version of Windows released since. The SDK is available as a free download. While the runtimes are proprietary, closed-source software, source code is provided for most of the SDK samples. Starting with the release of Windows 8 Developer Preview, DirectX SDK has been integrated into Windows SDK.[5]

https://en.wikipedia.org/wiki/DirectX

- **Direct3D (1996) - Microsoft**

Direct3D is a graphics application programming interface (API) for Microsoft Windows. Part of DirectX, Direct3D is used to render three-dimensional graphics in applications where performance is important, such as games. Direct3D uses hardware acceleration if it is available on the graphics card, allowing for hardware acceleration of the entire 3D rendering pipeline or even only partial acceleration. Direct3D exposes the advanced graphics capabilities of 3D graphics hardware, including Z-buffering,[1] W-buffering,[2] stencil buffering, spatial anti-aliasing, alpha blending, color blending, mipmapping, texture blending,[3][4] clipping, culling, atmospheric effects, perspective-correct texture mapping, programmable HLSL shaders[5] and effects.[6] Integration with other DirectX technologies enables Direct3D to deliver such features as video mapping, hardware 3D rendering in 2D overlay planes, and even sprites, providing the use of 2D and 3D graphics in interactive media ties.

https://en.wikipedia.org/wiki/Direct3D

- **Unreal Engine (1998) - Unreal**

Unreal Engine (UE) is a 3D computer graphics game engine developed by Epic Games, first showcased in the 1998 first-person shooter game Unreal. Initially developed for PC first-person shooters, it has since been used in a variety of genres of games and has seen adoption by other industries, most notably the film and television industry. Written in C++, the Unreal Engine features a high degree of portability, supporting a wide range of desktop, mobile, console and virtual reality platforms.

https://en.wikipedia.org/wiki/Unreal_Engine

### Automation
- **LonWork (1999)** 

LonWorks or Local Operating Network is an open standard (ISO/IEC 14908) for networking platforms specifically created to address the needs of control applications. The platform is built on a protocol created by Echelon Corporation for networking devices over media such as twisted pair, powerlines, fibre optics , and RF. It is used for the automation of various functions within buildings such as lighting and HVAC; see building automation.
The technology has its origins with chip designs, power line and twisted pair, signaling technology, routers, network management software, and other products from Echelon Corporation. In 1999 the communications protocol (then known as LonTalk) was submitted to ANSI and accepted as a standard for control networking (ANSI/CEA-709.1-B). Echelon's power line and twisted pair signaling technology was also submitted to ANSI for standardization and accepted. Since then, ANSI/CEA-709.1 has been accepted as the basis for IEEE 1473-L (in-train controls), AAR electro-pneumatic braking systems for freight trains, IFSF (European petrol station control), SEMI (semiconductor equipment manufacturing), and in 2005 as EN 14908 (European building automation standard). The protocol is also one of several data link/physical layers of the BACnet ASHRAE/ANSI standard for building automation.
China ratified the technology as a national controls standard, GB/Z 20177.1-2006 and as a building and intelligent community standard, GB/T 20299.4-2006; and in 2007 CECED, the European Committee of Domestic Equipment Manufacturers, adopted the protocol as part of its Household Appliances Control and Monitoring – Application Interworking Specification (AIS) standards.
During 2008 ISO and IEC have granted the communications protocol, twisted pair signaling technology, power line signaling technology, and Internet Protocol (IP) compatibility standard numbers ISO/IEC 14908-1, -2, -3, and -4.[1]

https://en.wikipedia.org/wiki/LonWorks

## Navigation
**[`^        back to top        ^`](#)**

**GPS is operational, military use, miniaturization and shift to dual-use**

The Gulf War from 1990 to 1991 was the first conflict in which the military widely used GPS.[58]

In 1991, a project to create a miniature GPS receiver successfully ended, replacing the previous 16 kg (35 lb) military receivers with a 1.25 kg (2.8 lb) handheld receiver.[26]

In 1992, the 2nd Space Wing, which originally managed the system, was inactivated and replaced by the 50th Space Wing.

By December 1993, GPS achieved initial operational capability (IOC), with a full constellation (24 satellites) available and providing the Standard Positioning Service (SPS).[59]

Full Operational Capability (FOC) was declared by Air Force Space Command (AFSPC) in April 1995, signifying full availability of the military's secure Precise Positioning Service (PPS).[59]

In 1996, recognizing the importance of GPS to civilian users as well as military users, U.S. President Bill Clinton issued a policy directive[60] declaring GPS a dual-use system and establishing an Interagency GPS Executive Board to manage it as a national asset.

In 1998, United States Vice President Al Gore announced plans to upgrade GPS with two new civilian signals for enhanced user accuracy and reliability, particularly with respect to aviation safety, and in 2000 the United States Congress authorized the effort, referring to it as GPS III.

https://en.wikipedia.org/wiki/Global_Positioning_System

# 1850 - 1949

**In short:**
- [Science](#science) : early fax, liquid crystals discovery, electroluminescence discovery and first LED, first concepts and prototypes of digital switching, flat-panel plasma idea, satelitte idea, Williams tube (RAM), first static (non-moving) magnetic memory, trackball, transistor invention
- [Electronics](#electronics) : microphone, triode vacuum tube, point-to-point construction
- [Energy](#energy) : power grid, electric light bulbs, development of batteries
- [Telecommunications](#telecommunications) : coaxial cable, analog phone, electromechanical automatic telephone exchange, radiofax, business telephone systems, telephone multiplexing
- [Networking](#networking) : global telegraph networks, multiplexers, early modem
- [Cryptography](#cryptography) : early cryptography (ENIGMA)
- [Computers](#computers) :
  * Form factor : Colossus, ENIAC
  * OS : fixed programs vs. stored programs
  * Peripherals : punched card reader, IBM 405 alphabetic bookkeeping and accounting machine
  * Storage :  punched tape
  * Uses : Census, Nuclear Weapon, Monte Carlo simulations in Science
- [Consumer Electronics](#consumer-electronics) :
  * Multimedia : Phonograph - gramophone - vinyl records, radios, real-to-real tape recording, black and white TV
  * Screens : CRT discovery and development
  * Broadcast :
- [Standards and protocols](#standards-and-protocols) : International Telecommunication Union (ITU), NTSC standard (for TV)
- [Programming languages and frameworks](#programming-languages-and-frameworks): concept of modern computer : Turing completeness
- [Navigation](#navigation) : Radar

## Science
**[`^        back to top        ^`](#)**

- **Early fax (1843)**

Scottish inventor Alexander Bain worked on **chemical mechanical fax type devices** and in 1846 was able to reproduce graphic signs in laboratory experiments. He received British patent 9745 on May 27, 1843 for his "Electric Printing Telegraph"

https://en.wikipedia.org/wiki/Fax

- **Liquid crystals discovery (1888-1922)**

In 1888,[38] Friedrich Reinitzer (1858–1927) discovered the liquid crystalline nature of cholesterol extracted from carrots (that is, two melting points and generation of colors) and published his findings at a meeting of the Vienna Chemical Society on May 3, 1888 (F. Reinitzer: Beiträge zur Kenntniss des Cholesterins, Monatshefte für Chemie (Wien) 9, 421–441 (1888)).[39] In 1904, Otto Lehmann published his work "Flüssige Kristalle" (Liquid Crystals). In 1911, Charles Mauguin first experimented with liquid crystals confined between plates in thin layers.

In 1922, Georges Friedel described the structure and properties of liquid crystals and classified them in three types (nematics, smectics and cholesterics). In 1927, Vsevolod Frederiks devised the electrically switched light valve, called the Fréedericksz transition, the essential effect of all LCD technology. In 1936, the Marconi Wireless Telegraph company patented the first practical application of the technology, "The Liquid Crystal Light Valve". In 1962, the first major English language publication Molecular Structure and Properties of Liquid Crystals was published by Dr. George W. Gray.[40] In 1962, Richard Williams of RCA found that liquid crystals had some interesting electro-optic characteristics and he realized an electro-optical effect by generating stripe-patterns in a thin layer of liquid crystal material by the application of a voltage. This effect is based on an electro-hydrodynamic instability forming what are now called "Williams domains" inside the liquid crystal.[41]

https://en.wikipedia.org/wiki/Liquid-crystal_display

- **Electroluminescence discovery and first LED (1907-1927)**

Electroluminescence as a phenomenon was discovered in 1907 by the English experimenter H. J. Round of Marconi Labs, using a crystal of silicon carbide and a cat's-whisker detector.[9][10] Russian inventor Oleg Losev reported creation of the first LED in 1927.[11] His research was distributed in Soviet, German and British scientific journals, but no practical use was made of the discovery for several decades.[12][13]

In 1936, Georges Destriau observed that electroluminescence could be produced when zinc sulphide (ZnS) powder is suspended in an insulator and an alternating electrical field is applied to it. In his publications, Destriau often referred to luminescence as Losev-Light. Destriau worked in the laboratories of Madame Marie Curie, also an early pioneer in the field of luminescence with research on radium.[14][15]

Hungarian Zoltán Bay together with György Szigeti pre-empted LED lighting in Hungary in 1939 by patenting a lighting device based on SiC, with an option on boron carbide, that emitted white, yellowish white, or greenish white depending on impurities present.[16]

https://en.wikipedia.org/wiki/Light-emitting_diode

- **First concepts and prototypes of digital switching (1930s)**

First concepts of digital switching and transmission were developed by various labs in the United States and in Europe starting in the 1930s.[citation needed] The first prototype digital switch was developed by Bell Labs as part of the ESSEX project while the first true digital exchange to be combined with digital transmission systems was designed by LCT (Laboratoire Central de Telecommunications) in Paris.

https://en.wikipedia.org/wiki/Telephone_exchange#Early_automatic_exchanges

- **Flat-panel plasma display system idea (1936)**

Kálmán Tihanyi, a Hungarian engineer, described a proposed flat-panel plasma display system in a 1936 paper.

https://en.wikipedia.org/wiki/Plasma_display

- **Satelitte idea (1945)**

In 1945 British science fiction writer Arthur C. Clarke proposed a worldwide communications system which would function by means of three satellites equally spaced apart in earth orbit.[39][40] This was published in the October 1945 issue of the Wireless World magazine and won him the Franklin Institute's Stuart Ballantine Medal in 1963.[41][42]

https://en.wikipedia.org/wiki/Satellite_television

- **Trackball (1947)**

The trackball, a related pointing device, was invented in 1946 by Ralph Benjamin as part of a post-World War II-era fire-control radar plotting system called the Comprehensive Display System (CDS). Benjamin was then working for the British Royal Navy Scientific Service. Benjamin's project used analog computers to calculate the future position of target aircraft based on several initial input points provided by a user with a joystick. Benjamin felt that a more elegant input device was needed and invented what they called a "roller ball" for this purpose.[8][9]

The device was patented in 1947,[9] but only a prototype using a metal ball rolling on two rubber-coated wheels was ever built, and the device was kept as a military secret.[8]

https://en.wikipedia.org/wiki/Computer_mouse

- **Williams tube - first practical form of random-access memory (RAM) (1947) - University of Manchester in England**:

https://en.wikipedia.org/wiki/Random-access_memory#History

https://en.wikipedia.org/wiki/Williams_tube

- **First static (non-moving) magnetic memory (1947) - George Devol**

Robotics pioneer George Devol filed a patent[3] for the first static (non-moving) magnetic memory on 3 April 1946. Devol's magnetic memory was further refined via 5 additional patents[4][5][6][7][8] and ultimately used in the first Industrial Robot. Frederick Viehe applied for various patents on the use of transformers for building digital logic circuits in place of relay logic beginning in 1947. A fully developed core system was patented in 1947, and later purchased by IBM in 1956.[9] This development was little-known, however, and the mainstream development of core is normally associated with three independent teams.

https://en.wikipedia.org/wiki/Magnetic-core_memory

- **Transistor (1947) - Bell Labs**

While the device was constructed a week earlier, Brattain's notes describe the first demonstration to higher-ups at Bell
Labs on the afternoon of 23 December 1947, often given as the birthdate of the transistor. What is now known as the "p–n–p point-contact germanium transistor" operated as a speech amplifier with a power gain of 18 in that trial. John Bardeen, Walter Houser Brattain, and William Bradford Shockley were awarded the 1956 Nobel Prize in physics for their work.

https://en.wikipedia.org/wiki/Semiconductor_device

## Electronics
**[`^        back to top        ^`](#)**

- **Microphone**

- **Triode vacuum tubes (1907)**

The 19th century saw increasing research with evacuated tubes, such as the Geissler and Crookes tubes. The many scientists and inventors who experimented with such tubes include Thomas Edison, Eugen Goldstein, Nikola Tesla, and Johann Wilhelm Hittorf. With the exception of early light bulbs, such tubes were only used in scientific research or as novelties. The groundwork laid by these scientists and inventors, however, was critical to the development of subsequent vacuum tube technology.

Although thermionic emission was originally reported in 1873 by Frederick Guthrie,[11] it was Thomas Edison's apparently independent discovery of the phenomenon in 1883 that became well known. Although Edison was aware of the unidirectional property of current flow between the filament and the anode, his interest (and patent[12]) concentrated on the sensitivity of the anode current to the current through the filament (and thus filament temperature). It was years later that John Ambrose Fleming applied the rectifying property of the Edison effect to detection of radio signals, as an improvement over the magnetic detector.[13]

Amplification by vacuum tube became practical only with **Lee de Forest's 1907 invention of the three-terminal "audion" tube, a crude form of what was to become the triode**.[14] Being essentially the first electronic amplifier,[15] such tubes were instrumental in long-distance telephony (such as the first coast-to-coast telephone line in the US) and public address systems, and introduced a far superior and versatile technology for use in radio transmitters and receivers. The electronics revolution of the 20th century arguably began with the invention of the triode vacuum tube.

Vacuum tubes used as switches made electronic computing possible for the first time, but the cost and relatively short mean time to failure of tubes were limiting factors.[50] "The common wisdom was that valves—which, like light bulbs, contained a hot glowing filament—could never be used satisfactorily in large numbers, for they were unreliable, and in a large installation too many would fail in too short a time".[51] Tommy Flowers, who later designed Colossus, "discovered that, so long as valves were switched on and left on, they could operate reliably for very long periods, especially if their 'heaters' were run on a reduced current".[51] In 1934 Flowers built a successful experimental installation using over 3,000 tubes in small independent modules; when a tube failed, it was possible to switch off one module and keep the others going, thereby reducing the risk of another tube failure being caused; this installation was accepted by the Post Office (who operated telephone exchanges). Flowers was also a pioneer of using tubes as very fast (compared to electromechanical devices) electronic switches. Later work confirmed that tube unreliability was not as serious an issue as generally believed; the 1946 ENIAC, with over 17,000 tubes, had a tube failure (which took 15 minutes to locate) on average every two days. The quality of the tubes was a factor, and the diversion of skilled people during the Second World War lowered the general quality of tubes.[52] During the war Colossus was instrumental in breaking German codes. After the war, development continued with tube-based computers including, military computers ENIAC and Whirlwind, the Ferranti Mark 1 (one of the first commercially available electronic computers), and UNIVAC I, also available commercially.

Advances using subminiature tubes included the Jaincomp series of machines produced by the Jacobs Instrument Company of Bethesda, Maryland. Models such as its Jaincomp-B employed just 300 such tubes in a desktop-sized unit that offered performance to rival many of the then room-sized machines.[53]

- **Point-to-point construction**

Point-to-point construction is a non-automated method of construction of electronics circuits widely used before the use of printed circuit boards (PCBs) and automated assembly gradually became widespread following their introduction in the 1950s. Circuits using thermionic valves (vacuum tubes) were relatively large, relatively simple (the number of large, hot, expensive devices which needed replacing was minimised), and used large sockets, all of which made the PCB less obviously advantageous than with later complex semiconductor circuits. Point-to-point construction is still widespread in power electronics where components are bulky and serviceability is a consideration, and to construct prototype equipment with few or heavy electronic components. A common practice, especially in older point-to-point construction, is to use the leads of components such as resistors and capacitors to bridge as much of the distance between connections as possible, reducing the need to add additional wire between the components.

https://en.wikipedia.org/wiki/Point-to-point_construction

## Energy
**[`^        back to top        ^`](#)**

- **Electric light bulbs**

- **Power grid**

- **Development of batteries**

## Telecommunications
**[`^        back to top        ^`](#)**

- **Coaxial cable (1880) - Oliver Heaviside**

Coaxial cable, or coax (pronounced /ˈkoʊ.æks/) is a type of electrical cable consisting of an inner conductor surrounded by a concentric conducting shield, with the two separated by a dielectric (insulating material); many coaxial cables also have a protective outer sheath or jacket. The term coaxial refers to the inner conductor and the outer shield sharing a geometric axis.

Coaxial cable is a type of transmission line, used to carry high-frequency electrical signals with low losses. It is used in such applications as telephone trunk lines, broadband internet networking cables, high-speed computer data busses, cable television signals, and connecting radio transmitters and receivers to their antennas. It differs from other shielded cables because the dimensions of the cable and connectors are controlled to give a precise, constant conductor spacing, which is needed for it to function efficiently as a transmission line.

In his 1880 British patent, Oliver Heaviside showed how coaxial cable could eliminate signal interference between parallel cables.
Coaxial cable was used in the first (1858) and following transatlantic cable installations, but its theory was not described until 1880 by English physicist, engineer, and mathematician Oliver Heaviside, who patented the design in that year (British patent No. 1,407).[1]

Short coaxial cables are commonly used to connect home video equipment, in ham radio setups, and in NIM. While formerly common for implementing computer networks, in particular Ethernet ("thick" 10BASE5 and "thin" 10BASE2), twisted pair cables have replaced them in most applications except in the growing consumer cable modem market for broadband Internet access.

Long distance coaxial cable was used in the 20th century to connect radio networks, television networks, and Long Distance telephone networks though this has largely been superseded by later methods (fibre optics, T1/E1, satellite).

https://en.wikipedia.org/wiki/Coaxial_cable

- **Plain old telephone service (POTS) - Analog phone**

Plain ordinary telephone system,[1] is a retronym for voice-grade telephone service employing analog signal transmission over copper loops. POTS was the standard service offering from telephone companies from 1876 until 1988

https://en.wikipedia.org/wiki/Plain_old_telephone_service

- **Electromechanical automatic telephone exchange (1888)**

The electromechanical automatic telephone exchange, invented by Almon Strowger in 1888, gradually replaced manual switchboards in central telephone exchanges around the world. In 1919, the Bell System in Canada also adopted automatic switching as its future technology, after years of reliance on manual systems.

Nevertheless, many manual branch exchanges remained operational into the second half of the 20th century in many enterprises. Later electronic devices and computer technology gave the operator access to an abundance of features. A private branch exchange (PBX) in a business usually has an attendant console, or an auto-attendant function, which bypasses the operator.

https://en.wikipedia.org/wiki/Telephone_switchboard

- **Radiofax (late 1940s)**

By the late 1940s, **radiofax** receivers were sufficiently miniaturized to be fitted beneath the dashboard of Western Union's "Telecar" telegram delivery vehicles.
https://en.wikipedia.org/wiki/Fax

- **Business Telephone system : Key Telephone System (KTS) and Private Branch eXchange (PBX)**

A business telephone system is a multiline telephone system typically used in business environments, encompassing systems ranging in technology from the key telephone system (KTS) to the private branch exchange (PBX).

A business telephone system differs from an installation of several telephones with multiple central office (CO) lines in that the CO lines used are directly controllable in key telephone systems from multiple telephone stations, and that such a system often provides additional features related to call handling. Business telephone systems are often broadly classified into key telephone systems, and private branch exchanges, but many hybrid systems exist.

A **key telephone system was originally distinguished from a private branch exchange in that it did not require an operator or attendant at the switchboard to establish connections between the central office trunks and stations, or between stations**. Technologically, private branch exchanges share lineage with central office telephone systems, and in larger or more complex systems, may rival a central office system in capacity and features. With a key telephone system, a station user could control the connections directly using line buttons, which indicated the status of lines with built-in lamps.

The wiring plans evolved into modular hardware building blocks with a variety of functionality and services in the 1A key telephone system developed in the Bell System in the 1930s.[2]

The term **PBX** originated when switchboard operators managed company switchboards manually using cord circuits. 

A PBX is a telephone exchange or switching system that serves a private organization and permits sharing of central office trunks between internally installed telephones, and provides intercommunication between those internal telephones within the organization without the use of external lines.[4] The central office lines provide connections to the public switched telephone network (PSTN) and the concentration aspect of a PBX permits the shared use of these lines between all stations in the organization. Its intercommunication ability allows two or more stations to directly connect while not using the public switched telephone network. This method reduces the number of lines needed from the organization to the public switched telephone network.

Each device connected to the PBX, such as a telephone, a fax machine, or a computer modem, is referred to as an extension and has a designated extension telephone number that may or may not be mapped automatically to the numbering plan of the central office and the telephone number block allocated to the PBX.

Initially, PBX systems offered the primary advantage of cost savings for internal phone calls: handling the circuit switching locally reduced charges for telephone service via central-office lines. As PBX systems gained popularity, they began to feature services not available in the public network, such as hunt groups, call forwarding, and extension dialing. From the 1960s, a simulated PBX, known as Centrex, provided similar features from the central telephone exchange.

A PBX differs from a key telephone system (KTS) in that users of a key system manually select their own outgoing lines on special telephone sets that control buttons for this purpose, while PBXs select the outgoing line automatically. The telephone sets connected to a PBX do not normally have special keys for central-office line control, but it is not uncommon for key systems to be connected to a PBX to extend its services.

A PBX, in contrast to a key system, employs an organizational numbering plan for its stations. In addition, a dial plan determines whether additional digit sequences must be prefixed when dialing to obtain access to a central office trunk. Modern number-analysis systems permit users to dial internal and external telephone numbers without special codes to distinguish the intended destination.

Many manufacturers provided manually operated private branch exchange systems in various sizes and features.

https://en.wikipedia.org/wiki/Business_telephone_system#Private_branch_exchange

- **Telephone multiplexing (1910)**

Multiplexing originated in telegraphy in the 1870s, and is now widely applied in communications. In telephony, George Owen Squier is credited with the development of telephone carrier multiplexing in 1910.

https://en.wikipedia.org/wiki/Multiplexing

## Networking ##
**[`^        back to top        ^`](#)**

- **Global telegraph networks (1866+)**

Getting a cable across the Atlantic Ocean proved much more difficult. The Atlantic Telegraph Company, formed in London in 1856, had several failed attempts. A cable laid in 1858 worked poorly for a few days (sometimes taking all day to send a message despite the use of the highly sensitive mirror galvanometer developed by William Thomson (the future Lord Kelvin) before being destroyed by applying too high a voltage. Its failure and slow speed of transmission prompted Thomson and Oliver Heaviside to find better mathematical descriptions of long transmission lines.[47] The company finally succeeded in 1866 with an improved cable laid by SS Great Eastern, the largest ship of its day, designed by Isambard Kingdom Brunel.[48][47]

An overland telegraph from Britain to India was first connected in 1866 but was unreliable so a submarine telegraph cable was connected in 1870.[49] Several telegraph companies were combined to form the Eastern Telegraph Company in 1872. Australia was first linked to the rest of the world in October 1872 by a submarine telegraph cable at Darwin.[50]

From the 1850s until well into the 20th century, British submarine cable systems dominated the world system. This was set out as a formal strategic goal, which became known as the All Red Line.[51] In 1896, there were thirty cable-laying ships in the world and twenty-four of them were owned by British companies. In 1892, British companies owned and operated two-thirds of the world's cables and by 1923, their share was still 42.7 percent.[52] During World War I, Britain's telegraph communications were almost completely uninterrupted while it was able to quickly cut Germany's cables worldwide.[51]

https://en.wikipedia.org/wiki/Telegraphy

- **Multiplexers (1920s)**

Modems grew out of the need to connect teleprinters over ordinary phone lines instead of the more expensive leased lines which had previously been used for current loop–based teleprinters and automated telegraphs. The earliest devices that satisfy the definition of a modem may be the multiplexers used by news wire services in the 1920s.[1]

https://en.wikipedia.org/wiki/Modem

- **SIGSALY - early modem (1941)**

In 1941, the Allies developed a voice encryption system called SIGSALY which used a vocoder to digitize speech, then encrypted the speech with one-time pad and encoded the digital data as tones using frequency shift keying. This was also a digital modulation technique, making this an early modem.[2]

https://en.wikipedia.org/wiki/Modem

## Cryptography
**[`^        back to top        ^`](#)**

- **Enigma**

The Enigma machine is a cipher device developed and used in the early- to mid-20th century to protect commercial, diplomatic, and military communication. It was employed extensively by Nazi Germany during World War II, in all branches of the German military. The Enigma machine was considered so secure that it was used to encipher the most top-secret messages.[1]

The Enigma has an electromechanical rotor mechanism that scrambles the 26 letters of the alphabet. In typical use, one person enters text on the Enigma's keyboard and another person writes down which of the 26 lights above the keyboard illuminated at each key press. If plain text is entered, the illuminated letters are the ciphertext. Entering ciphertext transforms it back into readable plaintext. The rotor mechanism changes the electrical connections between the keys and the lights with each keypress.

The security of the system depends on machine settings that were generally changed daily, based on secret key lists distributed in advance, and on other settings that were changed for each message. The receiving station would have to know and use the exact settings employed by the transmitting station to successfully decrypt a message.

While Nazi Germany introduced a series of improvements to the Enigma over the years, and these hampered decryption efforts, they did not prevent Poland from cracking the machine as early as December 1932 and reading messages prior to and into the war. Poland's sharing of her achievements enabled the western Allies to exploit Enigma-enciphered messages as a major source of intelligence.[2] Many commentators say the flow of Ultra communications intelligence from the decrypting of Enigma, Lorenz, and other ciphers shortened the war substantially and may even have altered its outcome.[3]

https://en.wikipedia.org/wiki/Enigma_machine

- **Early cryptography**

By World War II, mechanical and electromechanical cipher machines were in wide use, although—where such machines were impractical—code books and manual systems continued in use. Great advances were made in both cipher design and cryptanalysis, all in secrecy. Information about this period has begun to be declassified as the official British 50-year secrecy period has come to an end, as US archives have slowly opened, and as assorted memoirs and articles have appeared.

Claude E. Shannon is considered by many to be the father of mathematical cryptography. Shannon worked for several years at Bell Labs, and during his time there, he produced an article entitled "A mathematical theory of cryptography". This article was written in 1945 and eventually was published in the Bell System Technical Journal in 1949.[31] It is commonly accepted that this paper was the starting point for development of modern cryptography. Shannon was inspired during the war to address "[t]he problems of cryptography [because] secrecy systems furnish an interesting application of communication theory". Shannon identified the two main goals of cryptography: secrecy and authenticity. His focus was on exploring secrecy and thirty-five years later, G.J. Simmons would address the issue of authenticity. Shannon wrote a further article entitled "A mathematical theory of communication" which highlights one of the most significant aspects of his work: cryptography's transition from art to science.

https://en.wikipedia.org/wiki/History_of_cryptography

## Computers
**[`^        back to top        ^`](#)**

### Form factor

- **IBM (1911)**  

IBM was founded in 1911 in Endicott, New York, as the Computing-Tabulating-Recording Company (CTR) and was renamed "International Business Machines" in 1924.

https://en.wikipedia.org/wiki/IBM

- **Colossus (1943-1960)**

Colossus was the world's first electronic digital programmable computer.[20] It used a large number of valves (vacuum tubes). It had paper-tape input and was capable of being configured to perform a variety of boolean logical operations on its data, but it was not Turing-complete. Nine Mk II Colossi were built (The Mk I was converted to a Mk II making ten machines in total). Colossus Mark I contained 1,500 thermionic valves (tubes), but Mark II with 2,400 valves, was both five times faster and simpler to operate than Mark I, greatly speeding the decoding process.[36][37]

https://en.wikipedia.org/wiki/Computer

Colossus was a set of computers developed by British codebreakers in the years 1943–1945[1] to help in the cryptanalysis of the Lorenz cipher. Colossus used thermionic valves (vacuum tubes) to perform Boolean and counting operations. Colossus is thus regarded[2] as the world's first programmable, electronic, digital computer, although it was programmed by switches and plugs and not by a stored program.[3]

Colossus was designed by General Post Office (GPO) research telephone engineer Tommy Flowers[1] to solve a problem posed by mathematician Max Newman at the Government Code and Cypher School (GC&CS) at Bletchley Park. Alan Turing's use of probability in cryptanalysis (see Banburismus) contributed to its design. It has sometimes been erroneously stated that Turing designed Colossus to aid the cryptanalysis of the Enigma.[4] (Turing's machine that helped decode Enigma was the electromechanical Bombe, not Colossus.)[5]

The prototype, Colossus Mark 1, was shown to be working in December 1943 and was in use at Bletchley Park by early 1944.[1] An improved Colossus Mark 2 that used shift registers to quintuple the processing speed, first worked on 1 June 1944, just in time for the Normandy landings on D-Day.[6] Ten Colossi were in use by the end of the war and an eleventh was being commissioned.[6] Bletchley Park's use of these machines allowed the Allies to obtain a vast amount of high-level military intelligence from intercepted radiotelegraphy messages between the German High Command (OKW) and their army commands throughout occupied Europe.

The existence of the Colossus machines was kept secret until the mid-1970s.[7][8] All but two machines were dismantled into such small parts that their use could not be inferred. The two retained machines were eventually dismantled in the 1960s. A functioning rebuild of a Mark 2 Colossus was completed in 2008 by Tony Sale and a team of volunteers; it is on display at The National Museum of Computing on Bletchley Park.[9][10][11]

https://en.wikipedia.org/wiki/Colossus_computer

- **ENIAC (1945) - United States Army's Ballistic Research Laboratory (which later became a part of the Army Research Laboratory)** 

The ENIAC[38] (Electronic Numerical Integrator and Computer) was the first electronic programmable computer built in the U.S. Although the ENIAC was similar to the Colossus, it was much faster, more flexible, and it was Turing-complete. Like the Colossus, a "program" on the ENIAC was defined by the states of its patch cables and switches, a far cry from the stored program electronic machines that came later. Once a program was written, it had to be mechanically set into the machine with manual resetting of plugs and switches. The programmers of the ENIAC were six women, often known collectively as the "ENIAC girls".[39][40]

It combined the high speed of electronics with the ability to be programmed for many complex problems. It could add or subtract 5000 times a second, a thousand times faster than any other machine. It also had modules to multiply, divide, and square root. High speed memory was limited to 20 words (about 80 bytes). Built under the direction of John Mauchly and J. Presper Eckert at the University of Pennsylvania, ENIAC's development and construction lasted from 1943 to full operation at the end of 1945. The machine was huge, weighing 30 tons, using 200 kilowatts of electric power and contained over 18,000 vacuum tubes, 1,500 relays, and hundreds of thousands of resistors, capacitors, and inductors.[41]

https://en.wikipedia.org/wiki/Computer

Electronic Numerical Integrator and Computer was the first programmable, electronic, general-purpose digital computer, completed in 1945.[3][4] There were other computers that had these features, but the ENIAC had all of them in one package. It was Turing-complete and able to solve "a large class of numerical problems" through reprogramming.[5][6]

ENIAC was designed and primarily used to calculate artillery firing tables for the United States Army's Ballistic Research Laboratory (which later became a part of the Army Research Laboratory),[7][8] its first program was a study of the feasibility of the thermonuclear weapon.[9][10]"
"Related to ENIAC's role in the hydrogen bomb was its role in the Monte Carlo method becoming popular. Scientists involved in the original nuclear bomb development used massive groups of people doing huge numbers of calculations ("computers" in the terminology of the time) to investigate the distance that neutrons would likely travel through various materials. John von Neumann and Stanislaw Ulam realized the speed of ENIAC would allow these calculations to be done much more quickly.[55] The success of this project showed the value of Monte Carlo methods in science.[56]"

https://en.wikipedia.org/wiki/ENIAC

### OS

- **Fixed programs vs. Stored programs**

Early computing machines had fixed programs. Changing its function required the re-wiring and re-structuring of the machine.[31] With the proposal of the stored-program computer this changed. A stored-program computer includes by design an instruction set and can store in memory a set of instructions (a program) that details the computation. The theoretical basis for the stored-program computer was laid by Alan Turing in his 1936 paper. In 1945, Turing joined the National Physical Laboratory and began work on developing an electronic stored-program digital computer. His 1945 report "Proposed Electronic Calculator" was the first specification for such a device. John von Neumann at the University of Pennsylvania also circulated his First Draft of a Report on the EDVAC in 1945.[20]

The Manchester Baby was the world's first stored-program computer. It was built at the University of Manchester in England by Frederic C. Williams, Tom Kilburn and Geoff Tootill, and ran its first program on 21 June 1948.[44] It was designed as a testbed for the Williams tube, the first random-access digital storage device.[45] Although the computer was considered "small and primitive" by the standards of its time, it was the first working machine to contain all of the elements essential to a modern electronic computer.[46] As soon as the Baby had demonstrated the feasibility of its design, a project was initiated at the university to develop it into a more usable computer, the Manchester Mark 1. Grace Hopper was the first person to develop a compiler for programming language.[2]

The Mark 1 in turn quickly became the prototype for the Ferranti Mark 1, the world's first commercially available general-purpose computer.[47] Built by Ferranti, it was delivered to the University of Manchester in February 1951. At least seven of these later machines were delivered between 1953 and 1957, one of them to Shell labs in Amsterdam.[48] In October 1947, the directors of British catering company J. Lyons & Company decided to take an active role in promoting the commercial development of computers. The LEO I computer became operational in April 1951[49] and ran the world's first regular routine office computer job.

https://en.wikipedia.org/wiki/Difference_engine

### Peripherals

- **Use of punched card reader**

By the end of its operation in 1956, ENIAC contained 18,000 vacuum tubes, 7,200 crystal diodes, 1,500 relays, 70,000 resistors, 10,000 capacitors, and approximately 5,000,000 hand-soldered joints. It weighed more than 30 short tons (27 t), was roughly 8 ft × 3 ft × 100 ft (2 m × 1 m × 30 m) in size, occupied 1,800 sq ft (170 m2) and consumed 150 kW of electricity.[20][21] This power requirement led to the rumor that whenever the computer was switched on, lights in Philadelphia dimmed.[22] Input was possible from an IBM card reader and an IBM card punch was used for output. These cards could be used to produce printed output offline using an IBM accounting machine, such as the IBM 405. While ENIAC had no system to store memory in its inception, these punch cards could be used for external memory storage.[23] 

https://en.wikipedia.org/wiki/ENIAC

- **IBM 405 alphabetic bookkeeping and accounting machine (1936)**

The IBM 405 alphabetic bookkeeping and accounting machine (later known as the 405 electric punched card accounting machine) was a combined adding, subtracting and printing machine that printed complete reports from punched accounting machine cards. It could be used to list both alphabetical and numerical details from individual accounting machine cards or to print classifications and to accumulate and print totals, net totals and accumulated net totals. The machine was equipped with an automatic plugboard, similar in principle to a telephone switchboard, by means of which any desired arrangement of data could be obtained from the punched cards. It could list cards at the rate of 80 cards a minute and were accumulated without listing at either 80 or 150 cards per minute as specified. Introduced in 1934, the Type 405 was marketed by IBM until May 1949.

This unusual 1951 view of a 405, not only reveals its some of its internal components, but also marks the reconditioning and reassembly of the 100th IBM 405 by IBM’s manufacturing facility in Rio de Janeiro, Brazil. Pictured here are the assemblers who performed the work. (VV4006)

### Storage

- **Punched tape**

Punched tape or perforated paper tape is a form of data storage that consists of a long strip of paper in which holes are punched. It developed from and was subsequently used alongside punched cards, differing in that the tape is continuous.

Punched cards, and chains of punched cards, were used for control of looms in the 18th century. Use for telegraphy systems started in 1842. Punched tape was used throughout the 19th and for much of the 20th centuries for programmable looms, teleprinter communication, for input to computers of the 1950s and 1960s, and later as a storage medium for minicomputers and CNC machine tools.

https://en.wikipedia.org/wiki/Punched_tape

### Uses
- Census
- Nuclear Weapon
- Monte Carlo simulations in Science

## Consumer Electronics
**[`^        back to top        ^`](#)**

### Multimedia
- **Phonograph - gramophone (1887)**

A phonograph, in its later forms also called a gramophone (as a trademark since 1887, as a generic name in the UK since 1910) or since the 1940s called a record player, or more recently a turntable,[a] is a device for the mechanical and analogue recording and reproduction of sound. The sound vibration waveforms are recorded as corresponding physical deviations of a spiral groove engraved, etched, incised, or impressed into the surface of a rotating cylinder or disc, called a "record". To recreate the sound, the surface is similarly rotated while a playback stylus traces the groove and is therefore vibrated by it, very faintly reproducing the recorded sound. In early acoustic phonographs, the stylus vibrated a diaphragm which produced sound waves which were coupled to the open air through a flaring horn, or directly to the listener's ears through stethoscope-type earphones.

The phonograph was invented in 1877 by Thomas Edison.[1][2][3][4] Alexander Graham Bell's Volta Laboratory made several improvements in the 1880s and introduced the graphophone, including the use of wax-coated cardboard cylinders and a cutting stylus that moved from side to side in a zigzag groove around the record. In the 1890s, Emile Berliner initiated the transition from phonograph cylinders to flat discs with a spiral groove running from the periphery to near the center, coining the term gramophone for disc record players, which is predominantly used in many languages. Later improvements through the years included modifications to the turntable and its drive system, the stylus or needle, pickup system, and the sound and equalization systems.

The disc phonograph record was the dominant commercial audio recording format throughout most of the 20th century. 

https://en.wikipedia.org/wiki/Phonograph

- **radios**


- **Vinyl records (1930s)**

In the 1930s, vinyl (originally known as vinylite) was introduced as a record material for radio transcription discs, and for radio commercials. At that time, virtually no discs for home use were made from this material. Vinyl was used for the popular 78-rpm V-discs issued to US soldiers during World War II. This significantly reduced breakage during transport. The first commercial vinylite record was the set of five 12" discs "Prince Igor" (Asch Records album S-800, dubbed from Soviet masters in 1945). Victor began selling some home-use vinyl 78s in late 1945; but most 78s were made of a shellac compound until the 78-rpm format was completely phased out. (Shellac records were heavier and more brittle.) 33s and 45s were, however, made exclusively of vinyl, with the exception of some 45s manufactured out of polystyrene.[53]

https://en.wikipedia.org/wiki/Phonograph

- **Reel-to-reel audio tape recording**

Reel-to-reel audio tape recording, also called open-reel recording, is magnetic tape audio recording in which the recording tape is spooled between reels. To prepare for use, the supply reel (or feed reel) containing the tape is placed on a spindle or hub. The end of the tape is manually pulled from the reel, threaded through mechanical guides and over a tape head assembly, and attached by friction to the hub of the second, initially empty takeup reel. Reel-to-reel systems use tape that is 1⁄4, 1⁄2, 1, or 2 inches (6.35, 12.70, 25.40, or 50.80 mm) wide, which normally moves at 3+3⁄4, 7+1⁄2, 15 or 30 inches per second (9.525, 19.05, 38.10 or 76.20 cm/s). All standard tape speeds are derived as a binary submultiple of 30 inches per second.

Reel-to-reel preceded the development of the compact cassette with tape 0.15 inches (3.8 mm) wide moving at 1+7⁄8 inches per second (4.8 cm/s). By writing the same audio signal across more tape, reel-to-reel systems give much greater fidelity at the cost of much larger tapes. In spite of the relative inconvenience and generally more expensive media, reel-to-reel systems developed in the early 1940s remained popular in audiophile settings into the 1980s and have reestablished a specialist niche in the 21st century.

Studer, Stellavox, Tascam, and Denon produced reel-to-reel tape recorders into the 1990s, but as of 2017, only Mechlabor[1] continues to manufacture analog reel-to-reel recorders. As of 2020, there were two companies manufacturing magnetic recording tape: ATR Services of York, Pennsylvania, and Recording the Masters in Avranches, France.[2]

Reel-to-reel tape was used in early tape drives for data storage on mainframe computers and in video tape recorders. Magnetic tape was also used to record data signals from analytical instruments, beginning with the hydrogen bomb testing of the early 1950s.

The reel-to-reel format was used in first magnetic recording system, wire recording and then in the earliest tape recorders, including the pioneering German-British Blattnerphone (1928) machines of the late 1920s which used steel tape,[3] and the German Magnetophon machines of the 1930s. Originally, this format had no name, since all forms of magnetic tape recorders used it. The name arose only with the need to distinguish it from the several kinds of tape cartridges or cassettes such as the endless loop cartridge developed for radio station commercials and spot announcements in 1954, the full size cassette, developed by RCA in 1958 for home use, as well as the compact cassette developed by Philips in 1962, originally for dictation.

The earliest machines produced distortion during the recording process which German engineers significantly reduced during the Nazi Germany era by applying a DC bias signal to the tape. In 1939, one machine was found to make consistently better recordings than other ostensibly identical models, and when it was taken apart a minor flaw was noticed. Instead of DC, it was introducing an AC bias signal to the tape,[citation needed] and this was quickly adapted to new models using a high-frequency AC bias that has remained a part of audio tape recording to this day. The quality was so greatly improved that recordings surpassed the quality of most radio transmitters, and such recordings were used by Adolf Hitler to make broadcasts that appeared to be live while he was safely away in another city.

American audio engineer Jack Mullin was a member of the U.S. Army Signal Corps during World War II. His unit was assigned to investigate German radio and electronics activities, and in the course of his duties, a British Army counterpart mentioned the Magnetophons being used by the allied radio station in Bad Nauheim near Frankfurt. He acquired two Magnetophon recorders and 50 reels of I.G. Farben recording tape and shipped them home. Over the next two years, he worked to develop the machines for commercial use, hoping to interest the Hollywood film studios in using magnetic tape for movie soundtrack recording.

Mullin gave a demonstration of his recorders at MGM Studios in Hollywood in 1947, which led to a meeting with Bing Crosby, who immediately saw the potential of Mullin's recorders to pre-record his radio shows. Crosby invested $50,000 in a local electronics company, Ampex, to enable Mullin to develop a commercial production model of the tape recorder. Using Mullin's tape recorders, and with Mullin as his chief engineer, Crosby became the first American performer to master commercial recordings on tape and the first to regularly pre-record his radio programs on the medium.

Ampex and Mullin subsequently developed commercial stereo and multitrack audio recorders, based on the system originally invented by Ross Snyder of Ampex Corporation for their high-speed scientific instrument data recorders. Les Paul had been given one of the first Ampex Model 200 tape decks by Crosby in 1948, and ten years later ordered one of the first Ampex eight-track "Sel Sync" machines for multitracking.[a] Ampex engineers, who included Ray Dolby on their staff at the time, went on to develop the first practical videotape recorders in the early 1950s to pre-record Crosby's TV shows.

7-inch reel of 1⁄4-inch-wide (6.4 mm) recording tape, typical of non-professional use in the 1950s–70s. Studios generally used 101⁄2 inch reels on PET film backings.
Inexpensive reel-to-reel tape recorders were widely used for voice recording in the home and in schools, along with dedicated models expressly made for business dictation. When the Philips compact cassette was introduced in 1963 it gradually took over and cassettes eventually displaced reel-to-reel recorders for consumer use. However, the narrow tracks and slow recording speeds used in cassettes compromised fidelity and so Ampex produced pre-recorded reel-to-reel tapes for consumers of popular and classical music from the mid-1950s to the mid-'70s, as did Columbia House from 1960 to 1984.

Following the example set by Bing Crosby, large reel-to-reel tape recorders rapidly became the main recording format used by audiophiles and professional recording studios until the late 1980s when digital audio recording techniques began to allow the use of other types of media (such as Digital Audio Tape (DAT) cassettes and hard disks).

https://en.wikipedia.org/wiki/Reel-to-reel_audio_tape_recording

### Screens

- **CRT - cathode-ray tube (1890+)**

A cathode-ray tube (CRT) is a vacuum tube containing one or more electron guns, which emit electron beams that are manipulated to display images on a phosphorescent screen.[2] The images may represent electrical waveforms (oscilloscope), pictures (television set, computer monitor), radar targets, or other phenomena. A CRT on a television set is commonly called a picture tube. CRTs have also been used as memory devices, in which case the screen is not intended to be visible to an observer. The term cathode ray was used to describe electron beams when they were first discovered, before it was understood that what was emitted from the cathode was a beam of electrons.

In CRT television sets and computer monitors, the entire front area of the tube is scanned repeatedly and systematically in a fixed pattern called a raster. In color devices, an image is produced by controlling the intensity of each of three electron beams, one for each additive primary color (red, green, and blue) with a video signal as a reference.[3] In modern CRT monitors and televisions the beams are bent by magnetic deflection, using a deflection yoke. Electrostatic deflection is commonly used in oscilloscopes.[3]

Cathode rays were discovered by Julius Plücker and Johann Wilhelm Hittorf.[14] Hittorf observed that some unknown rays were emitted from the cathode (negative electrode) which could cast shadows on the glowing wall of the tube, indicating the rays were traveling in straight lines. In 1890, Arthur Schuster demonstrated cathode rays could be deflected by electric fields, and William Crookes showed they could be deflected by magnetic fields. In 1897, J. J. Thomson succeeded in measuring the charge-mass-ratio of cathode rays, showing that they consisted of negatively charged particles smaller than atoms, the first "subatomic particles", which had already been named electrons by Irish physicist George Johnstone Stoney in 1891. The earliest version of the CRT was known as the "Braun tube", invented by the German physicist Ferdinand Braun in 1897.[15] It was a cold-cathode diode, a modification of the Crookes tube with a phosphor-coated screen. Braun was the first to conceive the use of a CRT as a display device.[16]

In 1908, Alan Archibald Campbell-Swinton, fellow of the Royal Society (UK), published a letter in the scientific journal Nature, in which he described how "distant electric vision" could be achieved by using a cathode-ray tube (or "Braun" tube) as both a transmitting and receiving device.[17] He expanded on his vision in a speech given in London in 1911 and reported in The Times[18] and the Journal of the Röntgen Society.[19][20]

The first cathode-ray tube to use a hot cathode was developed by John Bertrand Johnson (who gave his name to the term Johnson noise) and Harry Weiner Weinhart of Western Electric, and became a commercial product in 1922.[21] The introduction of hot cathodes allowed for lower acceleration anode voltages and higher electron beam currents, since the anode now only accelerated the electrons emitted by the hot cathode, and no longer had to have a very high voltage to induce electron emission from the cold cathode.[22]

In 1926, Kenjiro Takayanagi demonstrated a CRT television that received images with a 40-line resolution.[23] By 1927, he improved the resolution to 100 lines, which was unrivaled until 1931.[24] By 1928, he was the first to transmit human faces in half-tones on a CRT display.[25] In 1927, Philo Farnsworth created a television prototype.[26][27][28][29][30] The CRT was named in 1929 by inventor Vladimir K. Zworykin.[25]: 84  RCA was granted a trademark for the term (for its cathode-ray tube) in 1932; it voluntarily released the term to the public domain in 1950.[31]

In the 1930s, Allen B. DuMont made the first CRTs to last 1,000 hours of use, which was one of the factors that led to the widespread adoption of television.[32]

The first commercially made electronic television sets with cathode-ray tubes were manufactured by Telefunken in Germany in 1934.[33][34]

In 1947, the cathode-ray tube amusement device, the earliest known interactive electronic game as well as the first to incorporate a cathode-ray tube screen, was created.[35]

https://en.wikipedia.org/wiki/Cathode-ray_tube

### Broadcast

- **Black and White TV (1931)**

At the Berlin Radio Show in August 1931, Manfred von Ardenne gave a public demonstration of a television system using a CRT for both transmission and reception. However, Ardenne had not developed a camera tube, using the CRT instead as a flying-spot scanner to scan slides and film.[73] Philo Farnsworth gave the world's first public demonstration of an all-electronic television system, using a live camera, at the Franklin Institute of Philadelphia on 25 August 1934, and for ten days afterwards.[74][75] Mexican inventor Guillermo González Camarena also played an important role in early television. His experiments with television (known as telectroescopía at first) began in 1931 and led to a patent for the "trichromatic field sequential system" color television in 1940.[76] In Britain, the EMI engineering team led by Isaac Shoenberg applied in 1932 for a patent for a new device they called "the Emitron",[77][78] which formed the heart of the cameras they designed for the BBC. On 2 November 1936, a 405-line broadcasting service employing the Emitron began at studios in Alexandra Palace, and transmitted from a specially built mast atop one of the Victorian building's towers. It alternated for a short time with Baird's mechanical system in adjoining studios, but was more reliable and visibly superior. This was the world's first regular "high-definition" television service.[79]

The original U.S. iconoscope was noisy, had a high ratio of interference to signal, and ultimately gave disappointing results, especially when compared to the high definition mechanical scanning systems then becoming available.[80][81] The EMI team, under the supervision of Isaac Shoenberg, analyzed how the iconoscope (or Emitron) produces an electronic signal and concluded that its real efficiency was only about 5% of the theoretical maximum.[82][83] They solved this problem by developing, and patenting in 1934, two new camera tubes dubbed super-Emitron and CPS Emitron.[84][85][86] The super-Emitron was between ten and fifteen times more sensitive than the original Emitron and iconoscope tubes and, in some cases, this ratio was considerably greater.[82] It was used for outside broadcasting by the BBC, for the first time, on Armistice Day 1937, when the general public could watch on a television set as the King laid a wreath at the Cenotaph.[87] This was the first time that anyone had broadcast a live street scene from cameras installed on the roof of neighboring buildings, because neither Farnsworth nor RCA would do the same until the 1939 New York World's Fair.

On the other hand, in 1934, Zworykin shared some patent rights with the German licensee company Telefunken.[88] The "image iconoscope" ("Superikonoskop" in Germany) was produced as a result of the collaboration. This tube is essentially identical to the super-Emitron.[citation needed] The production and commercialization of the super-Emitron and image iconoscope in Europe were not affected by the patent war between Zworykin and Farnsworth, because Dieckmann and Hell had priority in Germany for the invention of the image dissector, having submitted a patent application for their Lichtelektrische Bildzerlegerröhre für Fernseher (Photoelectric Image Dissector Tube for Television) in Germany in 1925,[89] two years before Farnsworth did the same in the United States.[90] The image iconoscope (Superikonoskop) became the industrial standard for public broadcasting in Europe from 1936 until 1960, when it was replaced by the vidicon and plumbicon tubes. Indeed, it was the representative of the European tradition in electronic tubes competing against the American tradition represented by the image orthicon.[91][92] The German company Heimann produced the Superikonoskop for the 1936 Berlin Olympic Games,[93][94] later Heimann also produced and commercialized it from 1940 to 1955;[95] finally the Dutch company Philips produced and commercialized the image iconoscope and multicon from 1952 to 1958.[92][96]

U.S. television broadcasting, at the time, consisted of a variety of markets in a wide range of sizes, each competing for programming and dominance with separate technology, until deals were made and standards agreed upon in 1941.[97] RCA, for example, used only Iconoscopes in the New York area, but Farnsworth Image Dissectors in Philadelphia and San Francisco.[98] In September 1939, RCA agreed to pay the Farnsworth Television and Radio Corporation royalties over the next ten years for access to Farnsworth's patents.[99] With this historic agreement in place, RCA integrated much of what was best about the Farnsworth Technology into their systems.[98] In 1941, the United States implemented 525-line television.[100][101] Electrical engineer Benjamin Adler played a prominent role in the development of television.[102][103]

https://en.wikipedia.org/wiki/Television

## Standards and protocols
**[`^        back to top        ^`](#)**

- **Standardization efforts of ITU (1865)** 

The standardization efforts of ITU started in 1865 with the formation of the International Telegraph Union, which later became the International Telecommunication Union (ITU). ITU became a Specialized agency of the United Nations in 1947. The International Telegraph and Telephone Consultative Committee (French: Comité Consultatif International Téléphonique et Télégraphique, CCITT) was created in 1956, and was renamed ITU-T in 1993.[1]

https://en.wikipedia.org/wiki/ITU-T

- **Black and White TV - First NTSC Standard (1941) - NTSC**

The first NTSC standard was developed in 1941 and had no provision for color.
The National Television System Committee was established in 1940 by the United States Federal Communications Commission (FCC) to resolve the conflicts between companies over the introduction of a nationwide analog television system in the United States. In March 1941, the committee issued a technical standard for black-and-white television that built upon a 1936 recommendation made by the Radio Manufacturers Association (RMA). Technical advancements of the vestigial side band technique allowed for the opportunity to increase the image resolution. The NTSC selected 525 scan lines as a compromise between RCA's 441-scan line standard (already being used by RCA's NBC TV network) and Philco's and DuMont's desire to increase the number of scan lines to between 605 and 800.[5] The standard recommended a frame rate of 30 frames (images) per second, consisting of two interlaced fields per frame at 262.5 lines per field and 60 fields per second. Other standards in the final recommendation were an aspect ratio of 4:3, and frequency modulation (FM) for the sound signal (which was quite new at the time).

https://en.wikipedia.org/wiki/NTSC

## Programming languages and frameworks
**[`^        back to top        ^`](#)**

- **Concept of modern computer: Turing completeness (1936)**

The principle of the modern computer was proposed by Alan Turing in his seminal 1936 paper,[42] On Computable Numbers. Turing proposed a simple device that he called "Universal Computing machine" and that is now known as a universal Turing machine. He proved that such a machine is capable of computing anything that is computable by executing instructions (program) stored on tape, allowing the machine to be programmable. The fundamental concept of Turing's design is the stored program, where all the instructions for computing are stored in memory. Von Neumann acknowledged that the central concept of the modern computer was due to this paper.[43] Turing machines are to this day a central object of study in theory of computation. Except for the limitations imposed by their finite memory stores, modern computers are said to be Turing-complete, which is to say, they have algorithm execution capability equivalent to a universal Turing machine.

https://en.wikipedia.org/wiki/Computer

## Navigation
**[`^        back to top        ^`](#)**

- **Radar (1940)**

Radar (radio detection and ranging)[1][2] is a detection system that uses radio waves to determine the distance (ranging), angle, and radial velocity of objects relative to the site. It can be used to detect aircraft, ships, spacecraft, guided missiles, motor vehicles, weather formations, and terrain. A radar system consists of a transmitter producing electromagnetic waves in the radio or microwaves domain, a transmitting antenna, a receiving antenna (often the same antenna is used for transmitting and receiving) and a receiver and processor to determine properties of the objects. Radio waves (pulsed or continuous) from the transmitter reflect off the objects and return to the receiver, giving information about the objects' locations and speeds.

Radar was developed secretly for military use by several countries in the period before and during World War II. A key development was the cavity magnetron in the United Kingdom, which allowed the creation of relatively small systems with sub-meter resolution. The term RADAR was coined in 1940 by the United States Navy as an acronym for "radio detection and ranging".[3][4] The term radar has since entered English and other languages as a common noun, losing all capitalization. The modern uses of radar are highly diverse, including air and terrestrial traffic control, radar astronomy, air-defense systems, anti-missile systems, marine radars to locate landmarks and other ships, aircraft anti-collision systems, ocean surveillance systems, outer space surveillance and rendezvous systems, meteorological precipitation monitoring, altimetry and flight control systems, guided missile target locating systems, self-driving cars, and ground-penetrating radar for geological observations. High tech radar systems are associated with digital signal processing, machine learning and are capable of extracting useful information from very high noise levels.

Other systems similar to radar make use of other parts of the electromagnetic spectrum. One example is lidar, which uses predominantly infrared light from lasers rather than radio waves. With the emergence of driver-less vehicles, radar is expected to assist the automated platform to monitor its environment, thus preventing unwanted incidents.[5]

https://en.wikipedia.org/wiki/Radar

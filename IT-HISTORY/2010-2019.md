# 2010s

**In short:**
- [Inventions](#inventions) : 
- [Electronics](#electronics) :
- [Energy](#energy) : 
- [Telecommunications](#telecommunications) : Phasing out ISDN
- [Networking](#networking) : Energy efficient ethernet / Green Ethernet, 40 GbE /100 GbE (core), 2.5 GbE/5 GbE (home/business), NFC deployment, Terabyte ethernet research (200 GbE, 400 GbE standards)
- [Cryptography](#cryptography) : 
- [Computers](#computers) :
  * [Form factor](#form-factor) : 
  * [OS](#os) : 
  * [Peripherals](#peripherals) : 
  * [Storage](#storage) :  
  * [Uses](#uses) :
- [Consumer Electronics](#consumer-electronics) :
  * [Gadgets](#gadgets) :
  * [Multimedia](#multimedia) : 
  * [Screens](#screens) : 
  * [Broadcast](#broadcast) : 
  * [Video games](#video-games) : Microsoft Xbox One, Sony PlayStation 4
- [Standards and protocols](#standards-and-protocols) : Broadband via electric power lines (IEEE Std 1901-2010), energy efficient ethernet, 40 GbE -> 400 GbE, HTTP/2, new wave of file compression (Snappy, Zstd)
- [Programming languages and frameworks](#programming-languages-and-frameworks): Microsoft .NET framework, Vulkan, Microsoft .NET core
- [Navigation](#navigation) : U.S. GPS modernization, Europe's Galileo goes live

## Inventions
**[`^        back to top        ^`](#)**
## Electronics
**[`^        back to top        ^`](#)**
## Energy
**[`^        back to top        ^`](#)**
## Telecommunications
**[`^        back to top        ^`](#)**

- **Phasing out ISDN (2010s-2020s)**

In 2013, Verizon announced it would no longer take orders for ISDN service in the Northeastern United States.[9]

In early 2015, BT announced their intention to retire the UK's ISDN infrastructure by 2025.[27]

On November 2, 2010, NTT announced plans to migrate their backend from PSTN to the IP network from around 2020 to around 2025. For this migration, ISDN services will be retired, and fiber optic services are recommended as an alternative.[26]

https://en.wikipedia.org/wiki/Integrated_Services_Digital_Network

As of 2015 ISDN is being phased out by most major telecommunication carriers throughout Europe in favour of all-IP networks, with some expecting complete migration by 2025.

https://en.wikipedia.org/wiki/Business_telephone_system#Private_branch_exchange

## Networking
**[`^        back to top        ^`](#)**

### Ethernet

- **Energy Efficient ethernet (2008-2010)**

The power reduction is accomplished in a few ways. In Fast Ethernet and faster links, constant and significant energy is used by the physical layer as transmitters are active regardless of whether data is being sent. If they could be put into sleep mode when no data is being sent, that energy could be saved.[8] When the controlling software or firmware decides that no data needs to be sent, it can issue a low-power idle (LPI) request to the Ethernet controller physical layer PHY. The PHY will then send LPI symbols for a specified time onto the link, and then disable its transmitter. Refresh signals are sent periodically to maintain link signaling integrity. When there is data to transmit, a normal IDLE signal is sent for a predetermined period of time. The data link is considered to be always operational, as the receive signal circuit remains active even when the transmit path is in sleep mode.[9]

Green Ethernet technology was a superset of the 802.3az standard. In addition to the link load power savings of Energy-Efficient Ethernet, Green Ethernet works in one of two ways. First, it detects link status, allowing each port on the switch to power down into a standby mode when a connected device, such as a computer, is not active. Second, it detects cable length and adjusts the power used for transmission accordingly. Standard switches provide enough power to send a signal up to 100 meters (330 ft).[10] However, this is often unnecessary in the SOHO environment, where 5 to 10 meters (16 to 33 ft) of cabling are typical between rooms. Moreover, small data centers can also benefit from this approach since the majority of cabling is confined to a single room with a few meters of cabling among servers and switches. In addition to the pure power saving benefits of Green Ethernet, backing off the transmit power on shorter cable runs reduces alien crosstalk, and improves the overall performance of the cabling system.

Green Ethernet also encompasses the use of more efficient circuitry in Ethernet chips, and the use of offload engines on Ethernet interface cards intended for network servers.[6] In April 2008, the term was used for switches, and, in July 2008, used with wireless routers which featured user-selectable off periods for Wi-Fi to further reduce energy consumption.[11]

Green Ethernet was first employed on home products. However, low port counts mean that significant energy savings are not going to be made using this technology only in the home. Turning off existing devices when they are idle is likely to provide a more immediate saving.[12] Projected power savings of up to 80 percent were estimated using Green Ethernet switches,[13] translating into a longer product life due to reduced heat dissipation.[14]

https://en.wikipedia.org/wiki/Energy-Efficient_Ethernet

- **40GbE / 100GbE - 40 Gigabit Ethernet / 100 Gigabit Ethernet**

40 Gigabit Ethernet (40GbE) and 100 Gigabit Ethernet (100GbE) are groups of computer networking technologies for transmitting Ethernet frames at rates of 40 and 100 gigabits per second (Gbit/s), respectively. These technologies offer significantly higher speeds than 10 Gigabit Ethernet. The technology was first defined by the IEEE 802.3ba-2010 standard[1] and later by the 802.3bg-2011, 802.3bj-2014,[2] 802.3bm-2015,[3] and 802.3cd-2018 standards.

https://en.wikipedia.org/wiki/100_Gigabit_Ethernet

- **to Terabit Ethernet**

Terabit Ethernet or TbE is Ethernet with speeds above 100 Gigabit Ethernet. 400 Gigabit Ethernet (400G, 400GbE) and 200 Gigabit Ethernet (200G, 200GbE)[1] standards developed by the IEEE P802.3bs Task Force using broadly similar technology to 100 Gigabit Ethernet[2][3] were approved on December 6, 2017.[4][5] In 2016, several networking equipment suppliers were already offering proprietary solutions for 200G and 400G.[5]

The Ethernet Alliance's 2020 technology roadmap expects speeds of 800 Gbit/s and 1.6 Tbit/s to become IEEE standard after 2020, possibly between 2023 and 2030.[6][7] Doubling to 800 GbE is expected to occur after 112 Gbit/s SerDes become available. The Optical Internetworking Forum (OIF) has already announced five new projects at 112 Gbit/s which would also make 4th generation (single-lane) 100 GbE links possible.[8] The IEEE P802.3df Task Force started work in January 2022 to standardize 800 Gbit/s and 1.6 Tbit/s Ethernet. [9]

Facebook and Google, among other companies, have expressed a need for TbE.[10] While a speed of 400 Gbit/s is achievable with existing technology, 1 Tbit/s (1000 Gbit/s) would require different technology.[2][11] Accordingly, at the IEEE Industry Connections Higher Speed Ethernet Consensus group meeting in September 2012, 400 GbE was chosen as the next generation goal.[2] Additional 200GbE objectives were added in January 2016.

The University of California, Santa Barbara (UCSB) attracted help from Agilent Technologies, Google, Intel, Rockwell Collins, and Verizon Communications to help with research into next generation Ethernet.[12]

As of early 2016, chassis/modular based core router platforms from Cisco, Juniper and other major manufacturers support 400 Gbit/s full duplex data rates per slot. One, two and four port 100GbE and one port 400GbE line cards are presently available. As of early 2019, 200GbE line cards became available after 802.3cd standard ratification.[13][14]

200G Ethernet uses PAM4 signaling which allows 2 bits to be transmitted per clock cycle, but at a higher implementation cost.[15]

https://en.wikipedia.org/wiki/Terabit_Ethernet

### NFC

- **NFC deployment (2010-2015)**

A patent licensing program for NFC is under deployment by France Brevets, a patent fund created in 2011

2010: Innovision released a suite of designs and patents for low cost, mass-market mobile phones and other devices.[33]

2010: Nokia C7: First NFC-capable smartphone released.[34] NFC feature was enabled by software update in early 2011.[35]

2010: Samsung Nexus S: First Android NFC phone shown[36][37]

May 21, 2010: Nice, France launches, with "Cityzi", the "Nice City of contactless mobile" project, the first in Europe to provide inhabitants with NFC bank cards and mobile phones (like Samsung Player One S5230), and a "bouquet of services" covering transportation (tramways and bus), tourism and student's services[38][39][40]

2011: Google I/O "How to NFC" demonstrates NFC to initiate a game and to share a contact, URL, app or video.[41]

2011: NFC support becomes part of the Symbian mobile operating system with the release of Symbian Anna version.[42]

2011: Research In Motion devices are the first ones certified by MasterCard Worldwide for their PayPass service[43]

2012: UK restaurant chain EAT. and Everything Everywhere (Orange Mobile Network Operator), partner on the UK's first nationwide NFC-enabled smartposter campaign. A 
dedicated mobile phone app is triggered when the NFC-enabled mobile phone comes into contact with the smartposter.[44]

2012: Sony introduced NFC "Smart Tags" to change modes and profiles on a Sony smartphone at close range, included with the Sony Xperia P Smartphone released the same year.[45]

2013: Samsung and VISA announce their partnership to develop mobile payments.

2013: IBM scientists, in an effort to curb fraud and security breaches, develop an NFC-based mobile authentication security technology. This technology works on similar principles to dual-factor authentication security.[46]

October 2014: Dinube becomes the first non-card payment network [47][48] to introduce NFC contactless payments natively on a mobile device, i.e. no need for an external case attached or NFC 'sticker' nor for a card. Based on Host card emulation with its own application identifier (AID),[49] contactless payment was available on Android KitKat upwards and commercial release commenced in June 2015.[50]

2014: AT&T, Verizon and T-Mobile released Softcard (formerly ISIS mobile wallet). It runs on NFC-enabled Android phones and iPhone 4 and iPhone 5 when an external NFC case is attached. The technology was purchased by Google and the service ended on March 31, 2015.

November 2015: Swatch and Visa Inc. announced a partnership to enable NFC financial transactions using the "Swatch Bellamy" wristwatch. The system is currently online in Asia, through a partnership with China UnionPay and Bank of Communications. The partnership will bring the technology to the US, Brazil, and Switzerland.[51]

November 2015: Google’s Android Pay function was launched, a direct rival to Apple Pay, and its roll-out across the US commenced.[52]

https://en.wikipedia.org/wiki/Near-field_communication


## Cryptography
**[`^        back to top        ^`](#)**
## Computers
**[`^        back to top        ^`](#)**
### Form factor
**[`^        back to top        ^`](#)**
### OS
**[`^        back to top        ^`](#)**
### Peripherals
**[`^        back to top        ^`](#)**
### Storage
**[`^        back to top        ^`](#)**
### Uses
**[`^        back to top        ^`](#)**

## Consumer Electronics
**[`^        back to top        ^`](#)**
### Gadgets
**[`^        back to top        ^`](#)**
### Multimedia
**[`^        back to top        ^`](#)**
### Screens
**[`^        back to top        ^`](#)**
### Broadcast
**[`^        back to top        ^`](#)**
### Video games
**[`^        back to top        ^`](#)**

- **XBox One - Shift to x86 and AMD architecture (2013) - Microsoft**

The third console, the Xbox One, was released in November 2013 and has sold 51 million units.

https://en.wikipedia.org/wiki/Xbox

Moving away from its predecessor's PowerPC-based architecture, the Xbox One marks a shift back to the x86 architecture used in the original Xbox; it features an AMD Accelerated Processing Unit (APU) built around the x86-64 instruction set. Xbox One's controller was redesigned over the Xbox 360's, with a redesigned body, D-pad, and triggers capable of delivering directional haptic feedback. The console places an increased emphasis on cloud computing, as well as social networking features and the ability to record and share video clips or screenshots from gameplay or livestream directly to streaming services such as Mixer and Twitch. Games can also be played off-console via a local area network on supported Windows 10 devices. The console can play Blu-ray Disc, and overlay live television programming from an existing set-top box or a digital tuner for digital terrestrial television with an enhanced program guide. The console optionally included a redesigned Kinect sensor, marketed as the "Kinect 2.0", providing improved motion tracking and voice recognition.
Blu-ray, DVD, CD, Digital distribution

https://en.wikipedia.org/wiki/Xbox_One

- **Sony PlayStation 4 (2013) - Sony**

Sony's next console, the PlayStation 4, was released in 2013, selling a million units within a day, becoming the fastest selling console in history

https://en.wikipedia.org/wiki/PlayStation

The PlayStation 4 (PS4) is a home video game console developed by Sony Computer Entertainment. Announced as the successor to the PlayStation 3 in February 2013, it was launched on November 15, 2013, in North America, November 29, 2013 in Europe, South America and Australia, and on February 22, 2014 in Japan. A console of the eighth generation, it competes with Microsoft's Xbox One and Nintendo's Wii U and Switch.

Moving away from the more complex Cell microarchitecture of its predecessor, the console features an AMD Accelerated Processing Unit (APU) built upon the x86-64 architecture, which can theoretically peak at 1.84 teraflops; AMD stated that it was the "most powerful" APU it had developed to date. The PlayStation 4 places an increased emphasis on social interaction and integration with other devices and services, including the ability to play games off-console on PlayStation Vita and other supported devices ("Remote Play"), the ability to stream gameplay online or to friends, with them controlling gameplay remotely ("Share Play"). The console's controller was also redesigned and improved over the PlayStation 3, with improved buttons and analog sticks, and an integrated touchpad among other changes. The console also supports HDR10 High-dynamic-range video and playback of 4K resolution multimedia.

The PlayStation 4 was released to critical acclaim, with critics praising Sony for acknowledging its consumers' needs, embracing independent game development, and for not imposing the restrictive digital rights management schemes like those originally announced by Microsoft for the Xbox One. Critics and third-party studios, before its launch, also praised the capabilities of the PlayStation 4 in comparison to its competitors; developers described the performance difference between the console and Xbox One as "significant" and "obvious". Heightened demand also helped Sony top global console sales. By October 2019, PS4 became the second-best-selling home game console of all time, behind the PlayStation 2.

Its read-only optical drive is capable of reading Blu-ray Discs at speeds of up to three times that of its predecessor.[56][62] The console features a hardware on-the-fly zlib decompression module.[60] The original PS4 model supports up to 1080p and 1080i video standards,[63] while the Pro model supports 4K resolution.[64] The console includes a 500 gigabyte hard drive for additional storage,[65] which can be upgraded by the user.[66] System Software 4.50, which was released on March 9, 2017,[67] enabled the use of external USB hard drives up to 8 TB for additional storage.[68]

The PlayStation 4 features Wi-Fi and Ethernet connectivity, Bluetooth, and two USB 3.0 ports.[23][56] An auxiliary port is also included for connection to the PlayStation Camera, a motion detection digital camera device first introduced on the PS3.[23] A mono headset, which can be plugged into the DualShock 4, is bundled with the system.[69] Audio/video output options include HDMI TV and optical S/PDIF audio.[23] The console does not have an analog audio/video output.[70]

The PS4 features a "Rest mode" feature. This places the console in a low-power state, while allowing users to immediately resume their game or app once the console is awoken. The console also is able to download content such as game and OS updates while it is in this state.[71][72]

**PlayStation VR is a virtual reality** system for PlayStation 4; it consists of a headset, which features a 1080p display panel, LED lights on the headset that are used by PlayStation Camera to track its motion, and a control box that processes 3D audio effects, as well as video output to the external display (either simulcasting the player's VR perspective, or providing an asymmetrical secondary perspective). PlayStation VR can also be used with PlayStation Move motion controllers.[90][91]

https://en.wikipedia.org/wiki/PlayStation_4

## Standards and protocols
**[`^        back to top        ^`](#)**

### Hardware layer

- **IEEE Std 1901-2010 - Broadband via electric power lines (2010)**

a standard for high speed (up to 500 Mbit/s at the physical layer) communication devices via electric power lines, often called broadband over power lines (BPL).[1] The standard uses transmission frequencies below 100 MHz. This standard is usable by all classes of BPL devices, including BPL devices used for the connection (<1500m to the premises) to Internet access services as well as BPL devices used within buildings for local area networks, smart energy applications, transportation platforms (vehicle), and other data distribution applications (<100m between devices).[2]

https://en.wikipedia.org/wiki/IEEE_1901

- **802.3az	-	Energy-Efficient Ethernet (2010)**

In computer networking, Energy-Efficient Ethernet (EEE) is a set of enhancements to twisted-pair, twinaxial, backplane, and optical fiber Ethernet physical-layer variants that reduce power consumption during periods of low data activity.[1] The intention is to reduce power consumption by 50% or more, while retaining full compatibility with existing equipment.[2]

The Institute of Electrical and Electronics Engineers (IEEE), through the IEEE 802.3az task force, developed the standard. The first study group had its call for interest in November 2006, and the official standards task force was authorized in May 2007.[3] The IEEE ratified the final standard in September 2010.[4] Some companies introduced technology to reduce the power required for Ethernet before the standard was ratified, using the name Green Ethernet.

Some energy-efficient switch integrated circuits were developed before the IEEE 802.3az Energy-Efficient Ethernet standard was finalized.[5][6]

https://en.wikipedia.org/wiki/Energy-Efficient_Ethernet

- **40GbE / 100 GbE (2010-2018)**

  * 802.3ba	(2010-06):	40 Gbit/s and 100 Gbit/s Ethernet. 40 Gbit/s over 1 m backplane, 10 m Cu cable assembly (4×25 Gbit or 10×10 Gbit lanes) and 100 m of MMF and 100 Gbit/s up to 10 m of Cu cable assembly, 100 m of MMF or 40 km of SMF respectively
  * 802.3bg	(2011-03):	Provide a 40 Gbit/s PMD which is optically compatible with existing carrier SMF 40 Gbit/s client interfaces (OTU3/STM-256/OC-768/40G POS).
  * 802.3bj	(2014-06):	Define a 4-lane 100 Gbit/s backplane PHY for operation over links consistent with copper traces on "improved FR-4" (as defined by IEEE P802.3ap or better materials to be defined by the Task Force) with lengths up to at least 1 m and a 4-lane 100 Gbit/s PHY for operation over links consistent with copper twinaxial cables with lengths up to at least 5 m.
  * 802.3bm	(2015-02):	100G/40G Ethernet for optical fiber
  * 802.3cd	(2018-12):	Media Access Control Parameters for 50 Gbit/s and Physical Layers and Management Parameters for 50, 100, and 200 Gbit/s Operation

https://en.wikipedia.org/wiki/IEEE_802.3

- **802.3bz	- 2.5GBASE-T and 5GBASE-T (2013-2016)**

2.5 Gigabit and 5 Gigabit Ethernet over Cat-5e/Cat-6 twisted pair.

IEEE 802.3bz, NBASE-T and MGBASE-T are standards for Ethernet over twisted pair at speeds of 2.5 and 5 Gbit/s. These use the same cabling as the ubiquitous Gigabit Ethernet, yet offer higher speeds. The resulting standards are named 2.5GBASE-T and 5GBASE-T.[1][2][3]

NBASE-T refers to Ethernet equipment that can automatically negotiate to operate at speeds of 100 Mbit/s, 1, 2.5, 5, or 10 Gbit/s, depending on the quality of the cable and the capabilities of the equipment at the other end of the cable.

As faster Wi-Fi protocols such as IEEE 802.11ac were developed, there was significant demand for cheap uplinks faster than 1000BASE-T. These speeds became relevant around 2014 as it became clear that it would not be possible to run 10GBASE-T over already widely deployed Cat5e cable. IEEE 802.3bz also supports power over Ethernet, which had previously not been available at 10GBASE-T.

As early as 2013, the Intel Avoton server processors integrated 2.5 Gbit/s Ethernet ports.

Whilst Broadcom had announced a series of 2.5 Gbit/s transceiver ICs,[10] 2.5 Gbit/s switch hardware was not widely commercially available at that point. Many early 10GBASE-T switches, particularly those with SFP+ interfaces, do not support the intermediate speeds.

In October 2014, the NBASE-T Alliance was founded,[11][12] initially comprising Cisco, Aquantia, Freescale, and Xilinx. By December 2015, it contained more than 45 companies, and aimed to have its specification compatible with 802.3bz.[13] The competing MGBASE-T Alliance, stating the same faster Gigabit Ethernet objectives, was founded in December 2014.[14] In contrast to NBASE-T, the MGBASE-T said that their specifications would be open source.[15] IEEE 802.3's "2.5G/5GBASE-T Task Force" started working on the 2.5GBASE-T and 5GBASE-T standards in March 2015.[16] The two NBASE-T and MGBASE-T Alliances ended up collaborating.[17] with the forming of the IEEE 802.3bz Task Force under the patronage of the Ethernet Alliance in June 2015.

On September 23, 2016, the IEEE-SA Standards Board approved IEEE Std 802.3bz-2016.[18]

https://en.wikipedia.org/wiki/2.5GBASE-T_and_5GBASE-T

- **Terabit Ethernet road**

200 Gbit/s over single-mode fiber and 400 Gbit/s over optical physical media.

https://en.wikipedia.org/wiki/IEEE_802.3

The IEEE formed the "IEEE 802.3 Industry Connections Ethernet Bandwidth Assessment Ad Hoc", to investigate the business needs for short and long term bandwidth requirements.[16][17][18]

IEEE 802.3's "400 Gb/s Ethernet Study Group" started working on the 400 Gbit/s generation standard in March 2013.[19] Results from the study group were published and approved on March 27, 2014. Subsequently, the IEEE 802.3bs Task Force[20] started working to provide physical layer specifications for several link distances.[21]

The IEEE 802.3bs standard was approved on December 6, 2017[4] and is available online.[22]
802.3bs	2017-12	200GbE (200 Gbit/s) over single-mode fiber and 400GbE (400 Gbit/s) over optical physical media

The IEEE 802.3cd standard was approved on December 5, 2018.
802.3cd	2018-12	Media Access Control Parameters for 50 Gbit/s and Physical Layers and Management Parameters for 50, 100, and 200 Gbit/s Operation

The IEEE 802.3cn standard was approved on December 20, 2019.
802.3cn	2019-11	50 Gbit/s (40 km), 100 Gbit/s (80 km), 200 Gbit/s (four λ, 40 km), and 400 Gbit/s (eight λ, 40 km and single λ, 80 km over DWDM) over Single-Mode Fiber and DWDM

https://en.wikipedia.org/wiki/Terabit_Ethernet

### Application layer

- **HTTP/2 (2015)**

HTTP/2 (originally named HTTP/2.0) is a major revision of the HTTP network protocol used by the World Wide Web. It was derived from the earlier experimental SPDY protocol, originally developed by Google.[1][2] HTTP/2 was developed by the HTTP Working Group (also called httpbis, where "bis" means "twice") of the Internet Engineering Task Force (IETF).[3][4][5] HTTP/2 is the first new version of HTTP since HTTP/1.1, which was standardized in RFC 2068 in 1997. The Working Group presented HTTP/2 to the Internet Engineering Steering Group (IESG) for consideration as a Proposed Standard in December 2014,[6][7] and IESG approved it to publish as Proposed Standard on February 17, 2015 (and was updated in February 2020 in regard to TLS 1.3).[8][9] The HTTP/2 specification was published as RFC 7540 on May 14, 2015.[10]

The standardization effort was supported by Chrome, Opera, Firefox,[11] Internet Explorer 11, Safari, Amazon Silk, and Edge browsers.[12] Most major browsers had added HTTP/2 support by the end of 2015.[13] About 97% of web browsers used have the capability.[14] As of October 2021, 47% (after topping out at just over 50%) of the top 10 million websites supported HTTP/2.[15]

https://en.wikipedia.org/wiki/HTTP/2

### File compression

- **Snappy - High speed compression/decompression but lower compression (2011) - Google**

Snappy (previously known as Zippy) is a fast data compression and decompression library written in C++ by Google based on ideas from LZ77 and open-sourced in 2011.[2][3] It does not aim for maximum compression, or compatibility with any other compression library; instead, it aims for very high speeds and reasonable compression. Compression speed is 250 MB/s and decompression speed is 500 MB/s using a single core of a circa 2011 "Westmere" 2.26 GHz Core i7 processor running in 64-bit mode. The compression ratio is 20–100% lower than gzip.[4]

Snappy is widely used in Google projects like Bigtable, MapReduce and in compressing data for Google's internal RPC systems. It can be used in open-source projects like MariaDB ColumnStore,[5] Cassandra, Couchbase, Hadoop, LevelDB, MongoDB, RocksDB, Lucene, Spark, and InfluxDB.[6] Decompression is tested to detect any errors in the compressed stream. Snappy does not use inline assembler (except some optimizations[7]) and is portable.

https://en.wikipedia.org/wiki/Snappy_(compression)

- **Zstandard, zstd - (2015) - Facebook**
Zstandard, commonly known by the name of its reference implementation zstd, is a lossless data compression algorithm developed by Yann Collet at Facebook. Zstd is the reference implementation in C. Version 1 of this implementation was released as open-source software on 31 August 2016.[3][4]

Zstandard was designed to give a compression ratio comparable to that of the DEFLATE algorithm (developed in 1991 and used in the original ZIP and gzip programs), but faster, especially for decompression. It is tunable with compression levels ranging from negative 7 (fastest)[5] to 22 (slowest in compression speed, but best compression ratio).

The Linux kernel has included Zstandard since November 2017 (version 4.14) as a compression method for the btrfs and squashfs filesystems.[16][17][18]

In 2017, Allan Jude integrated Zstandard into the FreeBSD kernel,[19] and it was subsequently integrated as a compressor option for core dumps (both user programs and kernel panics). It was also used to create a proof-of-concept OpenZFS compression method[7] which was integrated in 2020.[20]

The AWS Redshift and RocksDB databases include support for field compression using Zstandard.[21]

https://en.wikipedia.org/wiki/Zstd

## Programming languages and frameworks
**[`^        back to top        ^`](#)**

- **Microsoft .NET framework (2000-2019) - Microsoft**

In November 2014, Microsoft also produced an update to its patent grants, which further extends the scope beyond its prior pledges. Prior projects like Mono existed in a legal grey area because Microsoft's earlier grants applied only to the technology in "covered specifications", including strictly the 4th editions each of ECMA-334 and ECMA-335. The new patent promise, however, places no ceiling on the specification version, and even extends to any .NET runtime technologies documented on MSDN that have not been formally specified by the ECMA group, if a project chooses to implement them. This allows Mono and other projects to maintain feature parity with modern .NET features that have been introduced since the 4th edition was published without being at risk of patent litigation over the implementation of those features. The new grant does maintain the restriction that any implementation must maintain minimum compliance with the mandatory parts of the CLI specification.[11]

On March 31, 2016, Microsoft announced at Microsoft Build that they will completely relicense Mono under an MIT License even in scenarios where formerly a commercial license was needed.[12] Microsoft also supplemented its prior patent promise for Mono, stating that they will not assert any "applicable patents" against parties that are "using, selling, offering for sale, importing, or distributing Mono."[13][14] It was announced that the Mono Project was contributed to the .NET Foundation. These developments followed the acquisition of Xamarin, which began in February 2016 and was finished on March 18, 2016.[15]

In April 2019, Microsoft released .NET Framework 4.8, the last version of the framework as a proprietary offering. Only monthly security and reliability bug fixes to that version have been released since then. No further changes to that version are planned.[3]

https://en.wikipedia.org/wiki/.NET_Framework

- **Vulkan - OpenGL successor (2015) - Khronos, AMD, DICE**

Vulkan is a low-overhead, cross-platform API, open standard for 3D graphics and computing.[16][17][18] Vulkan targets high-performance real-time 3D graphics applications, such as video games and interactive media. Vulkan is intended to offer higher performance and more efficient CPU and GPU usage compared to older OpenGL and Direct3D 11 APIs. It provides a considerably lower-level API for the application than the older APIs, making Vulkan comparable to Apple's Metal API and Microsoft's Direct3D 12. In addition to its lower CPU usage, Vulkan is designed to allow developers to better distribute work among multiple CPU cores.[19]

Vulkan was first announced by the non-profit Khronos Group at GDC 2015.[14][20][21] The Vulkan API was initially referred to as the "next generation OpenGL initiative", or "OpenGL next"[22] by Khronos, but use of those names was discontinued when Vulkan was announced.[23]

Vulkan is derived from and built upon components of AMD's Mantle API, which was donated by AMD to Khronos with the intent of giving Khronos a foundation on which to begin developing a low-level API that they could standardize across the industry.[14]

Vulkan is not backwards compatible with OpenGL,[24][18][note 1] although there exists within Mesa an implementation of OpenGL/GLES that runs on top of Vulkan, called Zink.[25]

https://en.wikipedia.org/wiki/Vulkan

- **Microsoft .NET core (2016-2019)**

.NET (pronounced as "dot net"; previously named .NET Core) is a free and open-source, managed computer software framework for Windows, Linux, and macOS operating systems.[3] It is a cross-platform[4] successor to .NET Framework.[5] The project is primarily developed by Microsoft employees by way of the .NET Foundation, and released under the MIT License.[2]

On November 12, 2014, Microsoft announced .NET Core, in an effort to include cross-platform support for .NET, including Linux and macOS, source for the .NET Core CoreCLR implementation, source for the "entire [...] library stack" for .NET Core, and the adoption of a conventional ("bazaar"-like) open-source development model under the stewardship of the .NET Foundation. Miguel de Icaza describes .NET Core as a "redesigned version of .NET that is based on the simplified version of the class libraries",[6] and Microsoft's Immo Landwerth explained that .NET Core would be "the foundation of all future .NET platforms". At the time of the announcement, the initial release of the .NET Core project had been seeded with a subset of the libraries' source code and coincided with the relicensing of Microsoft's existing .NET reference source away from the restrictions of the Ms-RSL. Landwerth acknowledged the disadvantages of the formerly selected shared license, explaining that it made codename Rotor "a non-starter" as a community-developed open source project because it did not meet the criteria of an Open Source Initiative (OSI) approved license.[7][8][9]

.NET Core 1.0 was released on June 27, 2016,[10] along with Microsoft Visual Studio 2015 Update 3, which enables .NET Core development.[11] .NET Core 1.0.4 and .NET Core 1.1.1 were released along with .NET Core Tools 1.0 and Visual Studio 2017 on March 7, 2017.[12]

.NET Core 2.0 was released on August 14, 2017, along with Visual Studio 2017 15.3, ASP.NET Core 2.0, and Entity Framework Core 2.0.[13] .NET Core 2.1 was released on May 30, 2018.[14] NET Core 2.2 was released on December 4, 2018.[15]

.NET Core 3 was released on September 23, 2019.[16] .NET Core 3 adds support for Windows desktop application development[17] and significant performance improvements throughout the base library.

https://en.wikipedia.org/wiki/.NET

## Navigation
**[`^        back to top        ^`](#)**

- **U.S. GPS modernization**
On January 11, 2010, an update of ground control systems caused a software incompatibility with 8,000 to 10,000 military receivers manufactured by a division of Trimble Navigation Limited of Sunnyvale, Calif.[citation needed][67]

On February 25, 2010,[68] the U.S. Air Force awarded the contract[citation needed] to develop the GPS Next Generation Operational Control System (OCX) to improve accuracy and availability of GPS navigation signals, and serve as a critical part of GPS modernization.

https://en.wikipedia.org/wiki/Global_Positioning_System

- **Europe's Galileo goes live (2016)**

Galileo is a global navigation satellite system (GNSS) that went live in 2016,[5] created by the European Union through the European Space Agency (ESA), operated by the European Union Agency for the Space Programme (EUSPA),[6] headquartered in Prague, Czech Republic,[7] with two ground operations centres in Fucino, Italy, and Oberpfaffenhofen, Germany. The €10 billion project[4][8] is named after the Italian astronomer Galileo Galilei. One of the aims of Galileo is to provide an independent high-precision positioning system so European political and military authorities do not have to rely on the US GPS, or the Russian GLONASS systems, which could be disabled or degraded by their operators at any time.[9] The use of basic (lower-precision) Galileo services is free and open to everyone. A fully encrypted higher-precision service is available for free to government-authorized users.[10][11] Galileo is intended to provide horizontal and vertical position measurements within 1-metre (3 ft 3 in) precision, and better positioning services at higher latitudes than other positioning systems. Galileo is also to provide a new global search and rescue (SAR) function as part of the MEOSAR system.

https://github.com/dheurtev/dheurtev/edit/main/IT-HISTORY/2010-2019.md











